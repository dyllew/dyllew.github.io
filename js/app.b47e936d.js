(function(e){function t(t){for(var a,o,r=t[0],c=t[1],l=t[2],u=0,h=[];u<r.length;u++)o=r[u],Object.prototype.hasOwnProperty.call(s,o)&&s[o]&&h.push(s[o][0]),s[o]=0;for(a in c)Object.prototype.hasOwnProperty.call(c,a)&&(e[a]=c[a]);d&&d(t);while(h.length)h.shift()();return n.push.apply(n,l||[]),i()}function i(){for(var e,t=0;t<n.length;t++){for(var i=n[t],a=!0,r=1;r<i.length;r++){var c=i[r];0!==s[c]&&(a=!1)}a&&(n.splice(t--,1),e=o(o.s=i[0]))}return e}var a={},s={app:0},n=[];function o(t){if(a[t])return a[t].exports;var i=a[t]={i:t,l:!1,exports:{}};return e[t].call(i.exports,i,i.exports,o),i.l=!0,i.exports}o.m=e,o.c=a,o.d=function(e,t,i){o.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:i})},o.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},o.t=function(e,t){if(1&t&&(e=o(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var i=Object.create(null);if(o.r(i),Object.defineProperty(i,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var a in e)o.d(i,a,function(t){return e[t]}.bind(null,a));return i},o.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return o.d(t,"a",t),t},o.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},o.p="/";var r=window["webpackJsonp"]=window["webpackJsonp"]||[],c=r.push.bind(r);r.push=t,r=r.slice();for(var l=0;l<r.length;l++)t(r[l]);var d=c;n.push([0,"chunk-vendors"]),i()})({0:function(e,t,i){e.exports=i("56d7")},"0052":function(e,t,i){},"034f":function(e,t,i){"use strict";i("85ec")},"04cf":function(e,t,i){},"04fc":function(e,t,i){"use strict";i("f702")},"06be":function(e,t){throw new Error("Module parse failed: Unexpected token (1:0)\nYou may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders\n(Source code omitted for this binary file)")},"089e":function(e,t,i){},"0bc4":function(e,t,i){},"0c01":function(e,t,i){"use strict";i("184d")},"184d":function(e,t,i){},1913:function(e,t,i){var a={"./6_864_Project.pdf":"1a9a","./Dylan_Lewis_Resume.pdf":"8050","./FrequencyPlot.png":"339e","./IDS131_Final_Report.pdf":"06be","./IDS131_Poster.pdf":"b720","./NER.png":"7d1a","./RelativeWordFreqDiffFlorida.png":"f061","./RelativeWordFrequencyDiff.png":"3ea6","./boomerang-home.jpg":"5e93","./create-account.png":"e1a7","./dylan-n-leo.jpg":"c9e4","./fare-surge-graph-pred.png":"84e6","./feelings.jpg":"c207","./final-project-overview.png":"d8cb","./int-dev-gray-lit.pdf":"4cdb","./int-dev-results.png":"269c","./join-communities.png":"a21f","./leo_n_me.jpg":"ee29","./linkedin-profpic.jpg":"cbeb","./negative-positive.jpg":"3bc0","./ner-res-tools.png":"2981","./ner-results.png":"332f","./network_cosine_similarity.png":"afd1","./network_tfidf_wordclouds.png":"64e1","./networks_and_years_cosine_similarity.png":"cad8","./pika-gif.gif":"9faf","./portrait.jpg":"4906","./project-collage.png":"8b08","./reptile.png":"a2c3","./resume.png":"a297","./taxi-fare-and-surge-pred.png":"f124","./taxi-proj-thumbnail.png":"e75b","./tfidf-networks.png":"9271","./trump-campaign.png":"89e4","./years_cosine_similarity.png":"878d"};function s(e){var t=n(e);return i(t)}function n(e){if(!i.o(a,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return a[e]}s.keys=function(){return Object.keys(a)},s.resolve=n,e.exports=s,s.id="1913"},"1a9a":function(e,t){throw new Error("Module parse failed: Unexpected token (1:0)\nYou may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders\n(Source code omitted for this binary file)")},"269c":function(e,t,i){e.exports=i.p+"img/int-dev-results.d88be6ab.png"},2981:function(e,t,i){e.exports=i.p+"img/ner-res-tools.ffa2482a.png"},"2a4a":function(e,t,i){"use strict";i("77ef")},"2db4":function(e,t,i){"use strict";i("38a8")},"2db8":function(e,t,i){"use strict";i("d67d")},"332f":function(e,t,i){e.exports=i.p+"img/ner-results.0168e441.png"},"339e":function(e,t,i){e.exports=i.p+"img/FrequencyPlot.970f0c80.png"},"38a8":function(e,t,i){},"3bc0":function(e,t,i){e.exports=i.p+"img/negative-positive.6d580dd8.jpg"},"3ea6":function(e,t,i){e.exports=i.p+"img/RelativeWordFrequencyDiff.ea5b86c8.png"},4906:function(e,t,i){e.exports=i.p+"img/portrait.b2c89646.jpg"},"4cdb":function(e,t){throw new Error("Module parse failed: Unexpected token (1:0)\nYou may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders\n(Source code omitted for this binary file)")},"54e2":function(e,t,i){"use strict";i("0052")},"56d7":function(e,t,i){"use strict";i.r(t);i("e260"),i("e6cf"),i("cca6"),i("a79d");var a=i("2b0e"),s=i("5f5b"),n=i("b1e0"),o=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"container-fluid p-3 min-vh-100",attrs:{id:"app"}},[i("Header"),"/"!==this.$route.path&&"/404"!==this.$route.path?i("NavBar"):e._e(),i("router-view")],1)},r=[],c=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"row justify-content-end"},[i("div",{staticClass:"col-12 col-md-4 col-lg-4",attrs:{id:"website-title"}},[i("h1",{attrs:{id:"name animate__fadeInDown"},on:{click:e.goHome}},[e._v(" Dylan Lewis ")])]),e._m(0)])},l=[function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"col-md-4 my-auto",attrs:{id:"logos-col"}},[i("div",{staticClass:"d-flex flex-row justify-content-center justify-content-md-end"},[i("a",{attrs:{href:"mailto: drlewis@mit.edu"}},[i("i",{staticClass:"fa fa-envelope-o fa-3x"}),i("i",{staticClass:"fa fa-envelope-o fa-2x"})]),i("a",{attrs:{href:"https://www.linkedin.com/in/dylan-lewis-2020/",target:"_blank"}},[i("i",{staticClass:"fa fa-linkedin-square fa-3x"}),i("i",{staticClass:"fa fa-linkedin-square fa-2x"})]),i("a",{attrs:{href:"https://github.com/dyllew/",target:"_blank"}},[i("i",{staticClass:"fa fa-github fa-3x"}),i("i",{staticClass:"fa fa-github fa-2x"})])])])}],d={name:"Header",methods:{goHome:function(){this.$router.push("/")}}},u=d,h=(i("ec0b"),i("2877")),p=Object(h["a"])(u,c,l,!1,null,"4b615310",null),m=p.exports,f=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"row pt-2 justify-content-center"},[i("div",{staticClass:"col-md-12",attrs:{id:"nav-bar"}},[i("router-link",{staticClass:"router-link",attrs:{to:"/about"}},[e._v("About Me")]),e._v(" | "),i("router-link",{staticClass:"router-link",attrs:{to:"/projects"}},[e._v("Projects")]),e._v(" | "),i("router-link",{staticClass:"router-link",attrs:{to:"/artwork"}},[e._v("Artwork")]),e._v(" | "),i("router-link",{staticClass:"router-link",attrs:{to:"/resume"}},[e._v("Resume")])],1)])},g=[],v={name:"NavBar"},y=v,w=(i("d6c0"),Object(h["a"])(y,f,g,!1,null,"d904e86c",null)),b=w.exports,C={name:"App",components:{Header:m,NavBar:b}},_=C,x=(i("034f"),Object(h["a"])(_,o,r,!1,null,null,null)),k=x.exports,j=i("8c4f"),S=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row pt-4 align-items-md-start justify-content-around"},[a("div",{staticClass:"col-6 pt-4 col-md-3 pt-md-5",attrs:{id:"about"}},[a("div",{staticClass:"img-container"},[a("h4",[e._v("About Me")]),a("div",{staticClass:"img-holder",on:{click:e.goToAbout}},[a("img",{staticClass:"rounded img-fluid upper-img",attrs:{src:i("c9e4")}})])])]),a("div",{staticClass:"col-6 pt-4 col-md-3 pt-md-5",attrs:{id:"resume"}},[a("div",{staticClass:"img-container"},[a("h4",[e._v("Resume")]),a("div",{staticClass:"img-holder",on:{click:e.goToResume}},[a("img",{staticClass:"rounded img-fluid upper-img",attrs:{src:i("a297")}})])])]),a("div",{staticClass:"col-md-4",attrs:{id:"artwork-and-projs"}},[a("div",{staticClass:"img-container"},[a("h4",[e._v("Projects")]),a("div",{staticClass:"img-holder",on:{click:e.goToProjects}},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("8b08")}})])]),a("div",{staticClass:"img-container mt-4"},[a("h4",[e._v("Artwork")]),a("div",{staticClass:"img-holder",on:{click:e.goToArtwork}},[a("img",{staticClass:"rounded img-fluid lower-img",attrs:{src:i("4906")}})])])]),a("div",{staticClass:"col-5 pt-5 pt-md-0 col-md-2",attrs:{id:"artwork"}},[a("div",{staticClass:"img-container"},[a("h4",[e._v("Artwork")]),a("div",{staticClass:"img-holder",on:{click:e.goToArtwork}},[a("img",{staticClass:"rounded img-fluid lower-img",attrs:{src:i("4906")}})])])]),a("div",{staticClass:"col-6 pt-5 pt-md-0 col-md-4",attrs:{id:"projects"}},[a("div",{staticClass:"img-container"},[a("h4",[e._v("Projects")]),a("div",{staticClass:"img-holder",on:{click:e.goToProjects}},[a("img",{staticClass:"rounded img-fluid lower-img",attrs:{src:i("8b08")}})])])])])},N=[],T={name:"Home",data:function(){return{windowWidth:window.innerWidth}},methods:{goToAbout:function(){this.$router.push("/about")},goToProjects:function(){this.$router.push("/projects")},goToArtwork:function(){this.$router.push("/artwork")},goToResume:function(){this.$router.push("/resume")}}},P=T,E=(i("2db8"),Object(h["a"])(P,S,N,!1,null,"6eb776f2",null)),I=E.exports,F=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},M=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row pt-3 pt-lg-5 justify-content-center align-items-center",attrs:{id:"home-container"}},[a("div",{staticClass:"col-6 col-md-5 col-lg-5 col-xl-3 mr-xl-5"},[a("img",{staticClass:"rounded img-fluid",attrs:{id:"leo-and-dylan-pic",src:i("ee29"),alt:"Leo and Dylan"}})]),a("div",{staticClass:"col-10 col-md-6 col-lg-5 col-xl-5",attrs:{id:"about-description"}},[a("p",{attrs:{id:"intro-paragraph"}},[e._v(" Hey there! I'm a Masters student at MIT studying Computer Science, specifically Artificial Intelligence. My research focuses on machine learning tools for assisting crisis managers during climate crises using crowdsourced climate crisis data. But more importantly, I am a proud dad to my son, Leo 🐕 ")]),a("p",[e._v(" I'm interested in Software Engineering, Data Science & Machine Learning, and Web Development! You can contact me through"),a("a",{attrs:{href:"mailto: drlewis@mit.edu"}},[e._v("email,")]),e._v("add me on"),a("a",{attrs:{href:"https://www.linkedin.com/in/dylan-lewis-2020/",target:"_blank"}},[e._v("LinkedIn,")]),e._v("or checkout my"),a("a",{attrs:{href:"https://github.com/dyllew/",target:"_blank"}},[e._v("GitHub!")])]),a("p",[e._v(" In my freetime, I love to explore nature, make and experiment with different forms of art, develop new skills, and go on adventures with my pup! ")])])])}],D={name:"About"},L=D,R=(i("eac1"),Object(h["a"])(L,F,M,!1,null,"67f905e6",null)),A=R.exports,O=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"projects row align-items-center justify-content-center"},e._l(e.projects,(function(t){return i("div",{key:t.link,staticClass:"col-12 col-md-4 col-lg-4 pt-3"},[i("div",{staticClass:"card border-info bg-transparent align-items-center"},[i("h5",{staticClass:"card-header"},[e._v(e._s(t.title))]),i("img",{staticClass:"card-img-top",class:t.src.size_class?t.src.size_class:"",attrs:{id:t.id,src:e.getImgUrl(t.src.img_name),alt:"Card image cap"}}),i("div",{staticClass:"card-body"},[i("p",{staticClass:"card-text"},[e._v(e._s(t.desc))]),t.projectWebsite?i("div",{attrs:{id:t.projectWebsite.id}},[i("a",{staticClass:"btn btn-light col-5",attrs:{href:t.projectWebsite.url,target:"_blank"}},[e._v(e._s(t.projectWebsite.buttonText))]),i("span"),i("a",{staticClass:"btn btn-primary text-light col-5",on:{click:function(i){return e.goToProjectPage(t.link)}}},[e._v("See Project Details")])]):i("div",{attrs:{id:"button-holder"}},[i("a",{staticClass:"btn btn-primary text-light",on:{click:function(i){return e.goToProjectPage(t.link)}}},[e._v("See Project Details")])])])])])})),0)},W=[],G={name:"Projects",data:function(){return{projects:[{id:"ml-for-crowdsourced-crisis-data",link:"/projects/ml-for-crowdsourced-crisis-data",src:{img_name:"pika-gif.gif",size_class:"w-75"},title:"Automating Crowdsourced Crisis Report Assessment for Enhanced Crisis Awareness and Response",desc:"Masters thesis on constructing labeled crowdsourced crisis datasets and developing machine learning models to assist crisis managers in gaining situational awareness from crowdsourced crisis data for enhanced crisis response."},{id:"nlp-for-int-dev-gray-lit",link:"/projects/nlp-for-int-dev-gray-lit",src:{img_name:"int-dev-results.png"},title:"Information Extraction and Unsupervised Methods for Streamlining Evidence Synthesis in International Development Gray Literature",desc:"NLP project which investigates Named Entity Recognition (NER) and K-means Clustering on a corpus of 244 documents of International Development literature papers for streamlining evidence synthesis process on international development gray literature.",projectWebsite:{id:"button-holder",buttonText:"Presentation PDF",url:"./assets/int-dev-gray-lit.pdf"}},{id:"climate-change-news",link:"/projects/climate-change-news",src:{img_name:"final-project-overview.png"},title:"Evolution of the U.S. TV News Narrative on Climate Change",desc:"Data Science & NLP project in Python that investigated the evolution of climate change coverage frequency & content between popular U.S. TV News Networks CNN, Fox News, and MSNBC over July 2009-January 2020.",projectWebsite:{id:"button-holder",buttonText:"Poster PDF",url:"./assets/IDS131_Poster.pdf"}},{id:"taxi-pred-img",link:"/projects/gnns-taxi-prediction",src:{img_name:"fare-surge-graph-pred.png"},title:"Graph Neural Networks for NYC Taxi Fare & Demand Surge Prediction",desc:"Machine Learning project in Python which evaluated graph neural networks (GNNs) for the tasks of NYC taxi fare and demand surge prediction."},{id:"trump-img",link:"/projects/trump-speech-analysis",src:{img_name:"FrequencyPlot.png",size_class:"w-75"},title:"Trump Campaign Speech Analysis",desc:"Data Science project in R which investigated how Donald Trump's 2016 campaign speeches may have influenced public sentiment on a regional level."},{id:"boomerang-img",link:"/projects/boomerang",src:{img_name:"boomerang-home.jpg"},title:"Boomerang",desc:"Boomerang is a full-stack web application where users can efficiently and reliably borrow items from others within their communities.",projectWebsite:{id:"button-holder",buttonText:"Go to the Boomerang website",url:"https://team-aesthetech-boomerang.herokuapp.com/"}}]}},methods:{goToProjectPage:function(e){this.$router.push(e)},getImgUrl:function(e){return i("1913")("./"+e)}}},q=G,$=(i("0c01"),Object(h["a"])(q,O,W,!1,null,"226bdef0",null)),z=$.exports,U=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},B=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"artwork row align-items-center justify-content-center justify-content-xl-around"},[a("div",{staticClass:"col-8 pt-3 pt-md-0 col-md-4"},[a("h4",{staticClass:"header"},[e._v("Ethereality")]),a("img",{staticClass:"rounded img-fluid",attrs:{src:i("4906")}})]),a("div",{staticClass:"col-8 pt-4 pt-md-2 col-md-4"},[a("h4",{staticClass:"header"},[e._v("Phantom Dragon")]),a("img",{staticClass:"rounded img-fluid",attrs:{src:i("a2c3")}})])])}],H={name:"Artwork"},J=H,Y=(i("f3bd"),Object(h["a"])(J,U,B,!1,null,null,null)),V=Y.exports,K=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},Q=[function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"resume row align-items-center justify-content-center"},[i("div",{staticClass:"col-12 mt-4",attrs:{id:"sticky-btn"}},[i("a",{staticClass:"btn btn-primary text-light",attrs:{target:"_blank",href:"./assets/Dylan_Lewis_Resume.pdf"}},[e._v("View PDF in Tab")])]),i("div",{staticClass:"col-12 mt-2"},[i("embed",{staticClass:"pdf",attrs:{src:"./assets/Dylan_Lewis_Resume.pdf"}})])])}],X={name:"Resume"},Z=X,ee=(i("54e2"),Object(h["a"])(Z,K,Q,!1,null,"28d22fa6",null)),te=ee.exports,ie=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},ae=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row align-items-center justify-content-center"},[a("div",{staticClass:"align-items-center col-md-8"},[a("div",{staticClass:"col-12 pt-3"},[a("h3",[e._v("Automating Crowdsourced Crisis Report Assessment for Enhanced Crisis Awareness and Response")])]),a("img",{attrs:{id:"pika-gif",src:i("9faf")}}),a("p",[e._v(" The availability of information in all stages of a crisis is critical for crisis managers to assess and respond to the impact of the crisis. With the increased use of smartphones and social media in recent years, many residents have provided real-time disaster updates that has potential to enhance situational awareness and response for other residents and crisis managers. An effective information system for aggregating these crowd-sourced crisis reports in real-time and thus making them quickly available is the RiskMap platform developed by the Urban Risk Lab at MIT. Though the availability of this data is invaluable, as reports come in, crisis managers must manually sift through and assess all of these reports in addition to other streams of data in order to understand the evolution and impact of the crisis. Analyzing the large volume of reports that come in during crisis results in information overload and time-consuming manual assessment by crisis managers, especially when their resources are constrained and their decisions are time-critical. This severely limits the potential of disaster information systems that utilize crowd-sourced disaster data to enable efficient and effective disaster awareness and response. This work presents a novel system that augments crowdsourced disaster information systems such as RiskMap by utilizing state-of-the-art machine learning methologies (e.g. Deep Learning methods) in an effort to provide crisis managers with an automated analysis of individual crisis reports as well as summarization of the unfolding situation in real-time while also incorporating human intelligence to iteratively improve the system over time. The system presented herein is evaluated using simulated flood crisis events in different cities in Japan including Fukuchiyama, Kyoto. ")])])])}],se={name:"MLForCrowdsourcedCrisisData"},ne=se,oe=(i("fae1"),Object(h["a"])(ne,ie,ae,!1,null,"0a2a6dde",null)),re=oe.exports,ce=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},le=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row align-items-center justify-content-center"},[a("div",{staticClass:"col-8"},[a("h3",[e._v("Information Extraction and Unsupervised Methods for Streamlining Evidence Synthesis in International Development Gray Literature")])]),a("div",{staticClass:"col-md-8"},[a("div",{staticClass:"carousel slide",attrs:{id:"NLPIntLitDevCarousel","data-ride":"carousel","data-interval":"false"}},[a("ol",{staticClass:"carousel-indicators"},[a("li",{staticClass:"active",attrs:{"data-target":"#NLPIntLitDevCarousel","data-slide-to":"0"}}),a("li",{attrs:{"data-target":"#NLPIntLitDevCarousel","data-slide-to":"1"}}),a("li",{attrs:{"data-target":"#NLPIntLitDevCarousel","data-slide-to":"2"}}),a("li",{attrs:{"data-target":"#NLPIntLitDevCarousel","data-slide-to":"3"}}),a("li",{attrs:{"data-target":"#NLPIntLitDevCarousel","data-slide-to":"4"}}),a("li",{attrs:{"data-target":"#NLPIntLitDevCarousel","data-slide-to":"5"}})]),a("div",{staticClass:"carousel-inner"},[a("div",{staticClass:"carousel-item active int-dev-lit-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("269c"),alt:"First slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Project Presentation, Report, and Code")]),a("p",[e._v(" This was a final project for 6.864: Advanced Natural Language Processing. This presentation focuses on introducing the project, the specific parts I worked on, and the main results from our analysis. "),a("br"),e._v(" A brief overview of the motivation, methods, and results is available in this "),a("a",{attrs:{href:"./assets/int-dev-gray-lit.pdf",target:"_blank"}},[e._v("presentation PDF.")]),a("br"),e._v(" The more thorough report of our methodology, visualizations, and findings "),a("a",{attrs:{href:"./assets/6_864_Project.pdf",target:"_blank"}},[e._v("here.")]),a("br"),e._v(" The code for this project was written in Python. "),a("a",{attrs:{href:"https://github.com/dyllew/6.864-fp",target:"_blank"}},[e._v("Here's the GitHub Repo.")])]),a("p",[e._v(" For this project, my main contributions were the supervised methodology/Named Entity Recognition stream discussed in the following slides ")])])]),a("div",{staticClass:"carousel-item int-dev-lit-carousel-item"},[a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Abstract")]),a("p",[e._v(" In fields like international development, decision-makers prioritize making evidence-based decisions for funding and implementing future projects. This aim is made difficult because of the plethora of information being published each year, and the nature of the research corpus as unstructured text or grey literature. To make informed decisions and understand the growing corpus of research available, researchers have turned to evidence synthesis - the process of compiling information and knowledge from many sources and disciplines to inform decisions. However, the manual evidence synthesis process takes extensive time (often 18 months to 3 years) and effort, and may soon be impossible at the world’s increasing rate of research output. To address these problems, we employ natural language processing techniques on a international development literature corpus of 244 documents to extract information from the title and abstract of international development documents, and to automatically cluster documents based on their content. We classify documents by Country of Study using a pretrained transformer Named Entity Recognition model and achieve an accuracy of 91.0%. Using K-Means clustering, we uncover informative and distinctive groupings of the documents which share similar semantic content. These methods reduce the time it takes for manual evidence synthesis for international development grey literature by enabling country of study filtering and clustering documents by semantic similarity. ")])])]),a("div",{staticClass:"carousel-item int-dev-lit-carousel-item"},[a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Named Entity Recognition (NER) for Country of Study (CoS) Classification - Models")]),a("p",[e._v(" The country of study (CoS) associated with each paper is quite pertinent to the international development domain. Our dataset is labeled with the CoS of each paper in our corpus. However, since our dataset is rather small (244 documents), we sought to evaluate whether pretrained NER models which extract a variety of entity types from text, could accurately extract the CoS for the papers in our corpus, which have a variety of text fields. ")]),a("h6",[e._v("Country of Study Extraction and Classification")]),a("p",[e._v(" We create a lower-cased, alphabetically-ordered, list of countries, which we construct using countryinfo "),a("a",{attrs:{href:"https://pypi.org/project/countryinfo/",target:"_blank"}},[e._v("(Link to CountryInfo PyPI page)")]),e._v(", a Python package which contains a large dictionary of countries, their alternative names, and ISO information. We ensure the strings of the countries present in our corpus match their respective string in the alphabetically-sorted list of countries. We note that Myanmar and Kosovo are countries present in our corpus, but are not present in the countryinfo dictionary, so we add them to the final list of alphabetically-sorted countries. Since nationality is a type of named entity that NER models typically extract in addition to countries, using a comprehensive, open-source nationality-country mapping "),a("a",{attrs:{href:"https://github.com/knowitall/chunkedextractor/blob/master/src/main/resources/edu/knowitall/chunkedextractor/demonyms.csv",target:"_blank"}},[e._v("(Demonym-Country Mapping Link)")]),e._v(", we construct a lower-cased, alphabetically-ordered list of nationalities as well as a dictionary mapping nationality to country. We note that we use the words nationality and demonym interchangeably. These lists and dictionary are useful for performing the country of study (CoS) classification using extracted entities from input text or determining if a nationality or country is a substring contained in the input text string. ")]),a("h6",[e._v("Simple Substring Matcher (SSM) Algorithm Baseline & CoS Extraction & Classification")]),a("p",[e._v(" As a baseline to our CoS prediction task, we devise a simple, non-ML, deterministic algorithm, called the Simple Substring Matcher (SSM) Algorithm. This method begins by making the input text lower-cased. To predict a CoS, it then scans through the alphabetically-sorted list of countries and classifies the first country which is a substring in the input text as the CoS. If no country is found as a substring in the text, the method then scans the alphabetically-sorted list of nationalities. If a nationality is found as a substring of the input, the method maps the nationality to the corresponding country and classifies the paper as having that country as the CoS. If neither country nor nationality is found as a substring in the text, the method classifies the paper's CoS as a "),a("i",[e._v("None")]),e._v(" value. We refer to this classification model as the Simple Substring Matcher (SSM) model. ")]),a("h6",[e._v("CoS Extraction & Classification by Pretrained NER Models")]),a("p",[e._v(" Although we utilize different pretrained NER models in our experiments as shown in the next slide, the process for classifying CoS using predicted entities is the same. Each model takes the raw text as input, predicts various non-overlapping entities present in the text into one of several entity categories. For the CoS classification task, we only consider the predicted "),a("b",[e._v("NORP")]),e._v(" (nationalities, or religious, or political groups) entities and the "),a("b",[e._v("GPE")]),e._v(" (countries, cities, states) entities as we assume that these categories are the only ones which would contain the country or relevant demonym associated with the CoS. We now begin our discussion of the classification procedure for the pretrained NER models. First, we make all NORP and GPE entities lower-cased. Next, we map any demonyms present among the NORP entities to their corresponding country. We then combine the resulting unique NORP and GPE entities into an alphabetically-ordered list. We scan this list of NORP and GPE entities checking if any of them exist in the countries list mentioned above, classifying the CoS as the first entity-country match found. If no match is found, we make a final attempt to determine the CoS by providing each of the entities as input to the GeoPy Geocoder "),a("a",{attrs:{href:"https://geopy.readthedocs.io/en/stable/",target:"_blank"}},[e._v("(Link to GeoPy API)")]),e._v(" object, which provides an address-location object if a location is found for the provided entity or no value otherwise. We do this for each entity, and if a location is found for a particular entity, we classify the paper's CoS as the country associated with the found address-location. If no country is found for all the entities, we classify the paper's CoS as "),a("i",[e._v("None")]),e._v(". ")])])]),a("div",{staticClass:"carousel-item int-dev-lit-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("332f"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("NER for Country of Study Classification - Results")]),a("p",[e._v(" In addition to testing different classification models, I experimented with different input strings to see how results change with various text fields and concatenations between them. These various inputs to the models include the title, abstract, intervention description, outcome description, and various concatenations of these text fields. ")]),a("p",[e._v(" All of the pretrained spaCy NER models have 0.0% accuracy when using the just the intervention description, however the SSM model achieves 13.9% accuracy on the intervention description. All models attain an accuracy of 2.9% when using just the outcome description. The title and abstract individually appear to be good input fields for predicting the CoS, however the concatenation of title and abstract appears to be the most informative input, as this is the input that yields the highest performance across all of the models. Overall, we observe that the baseline simple substring checker is a fairly competitive model against the pretrained ML models, outperforming all the ML models on intervention description, performing the same as the ML models on outcome description, and only falling a few percentage points below even the best ML model on the other inputs. With the exception of the title, intervention description, and outcome description, the ML models in increasing order of complexity, do increasingly better on the CoS extraction task, in the following order from least performant to most performant: ESMS, ESMM, ESML, and ESMT. With the exception of the intervention description and output description inputs, we observe that the ESMT model performs best across all other inputs. Furthermore, we see that the concatenated title and abstract input and the ESMT model combination performs the best across all input-model combinations with 91.0% accuracy. We use this top-performing model by accuracy to construct AI-assisted tools which could assist researcher in the evidence in the following slide. ")])])]),a("div",{staticClass:"carousel-item int-dev-lit-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("2981"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Predictions by Pretrained Transformer NER Model for International Development Gray Literature Map and Filter Function")]),a("h6",[e._v("Map of International Development Literature Gray Corpus")]),a("p",[e._v(" Using the CoS predictions from the pretrained NER transformer model on the concatenated title and abstract input, we construct a geographical map of the corpus as shown in the left image. For each paper, which had a non-null prediction by the ESMT model, we place a tooltip at location coordinate associated with the predicted CoS. These location coordinates were pulled using the GeoPy Geocoder object from the GeoPy Python package. We added slight, uniform random jitter to each of the coordinates, so papers with the same predicted CoS don't directly overlap. When a user hovers over the tooltip, they will see the title of the paper associated with that tooltip. The webpage for this map can be downloaded "),a("a",{attrs:{href:"https://drive.google.com/file/d/1Q2P6ouwcDWrnXsq8LMpa4YqCuD7qsbtO/view?usp=sharing",target:"_blank"}},[e._v("here")]),e._v(" for view in a browser. ")]),a("h6",[e._v("Filtering by Predicted CoS")]),a("p",[e._v(" For large corpora of International Development Gray Literature, the utility of the CoS prediction task is most evident by the robust filtering capability it enables. For instance, by concatenating only the title and abstract of papers in the corpus, and using them as input to generate CoS predictions by the pretrained transformer model used in this study, this enables the ability for unlabeled papers in the corpus to be accurately filtered to identify studies which had a specific CoS. This method would greatly reduce the time necessary for manual CoS annotation while also yielding higher accuracy than a simple substring matcher, simplifying a step in the international literature review process with high accuracy. An example of this filtering functionality is shown in the right image for papers in the corpus, which were predicted as having Guatemala as the CoS. The CoS was predicted using the pretrained transformer NER model with the concatenated title and abstract as input. We display the corresponding title and abstract for quick scanning of results for relevancy to research topic. Additionally, we provide the option to filter the corpus for papers which had a predicted CoS as "),a("i",[e._v("None")]),e._v(". ")])])]),a("div",{staticClass:"carousel-item int-dev-lit-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("269c"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Conclusion")]),a("p",[e._v(" The manual evidence synthesis for international development gray literature is a time-consuming process. We have demonstrated that certain components of the evidence synthesis process in international development gray literature such as filtering corpora for papers which have a specific country of study or grouping similar documents together can benefit greatly from the use of methods of information extraction and unsupervised learning. More specifically, we have utilized a pretrained transformer NER model to accurately predict the country of study for the papers present in the corpus used in this study, thus enabling accurate filtering of the corpus for papers with a specific predicted country of study. After tuning to find the optimal number of clusters in K-Means clustering, we uncovered informative and distinctive clusters of documents with similar content in the corpus. The automation of these components in the evidence synthesis process for international development grey literature mitigates the effort and time that is required for manual evidence synthesis. ")])])])])])])])}],de={name:"NLPIntDevGrayLit"},ue=de,he=(i("fe4b"),Object(h["a"])(ue,ce,le,!1,null,"17540e1a",null)),pe=he.exports,me=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},fe=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row align-items-center justify-content-center"},[a("div",{staticClass:"col-12"},[a("h3",[e._v("Graph Neural Networks for NYC Taxi Fare & Demand Surge Prediction")])]),a("div",{staticClass:"col-md-8"},[a("div",{staticClass:"carousel slide",attrs:{id:"taxiCarousel","data-ride":"carousel","data-interval":"false"}},[a("ol",{staticClass:"carousel-indicators"},[a("li",{staticClass:"active",attrs:{"data-target":"#taxiCarousel","data-slide-to":"0"}}),a("li",{attrs:{"data-target":"#taxiCarousel","data-slide-to":"1"}}),a("li",{attrs:{"data-target":"#taxiCarousel","data-slide-to":"2"}})]),a("div",{staticClass:"carousel-inner"},[a("div",{staticClass:"carousel-item active taxi-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("f124"),alt:"First slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Motivation")]),a("p",[e._v(" With the advent of ridesharing apps, the New York City taxi industry must provide accurate predictions for taxi fares and demand surges in order to remain competitive. It is important that it provides riders with accurate estimates for the price of trip fare for quality customer service. It is beneficial for the taxi industry to accurately predict locations that will experience increased demand or surges in taxi demand to effectively allocate drivers and cabs to these areas in a timely manner. In this project, we used a large public dataset provided by the NYC Taxi & Limousine Commission containing yellow taxi trips records for every month from 2015-Present. We specifically utilized data from January 2019-June 2019. ")])])]),a("div",{staticClass:"carousel-item taxi-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("84e6"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Graph Neural Networks for Taxi Fare and Surge Prediction")]),a("p",[e._v(" The Yellow Taxi Trip Records contain data about taxi trips including pickup and dropoff locations, date and time of pickup and dropoff, distance traveled, and the associated fare of the trip. This data has inherent graph structure in which the nodes are the different pickup/dropoff locations and the edges are the directed trips between them. Due to the increasing advances of Graph Neural Networks (GNNs) in recent years and the advent of efficient frameworks like Deep Graph Library (DGL), we evaluated the performance of GNNs against other classical machine learning methods to assess the viability of GNNs as an accurate model which leverages the inherent graph structure in the data used for these tasks. ")])])]),a("div",{staticClass:"carousel-item taxi-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("84e6"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Results")]),a("p",[e._v(" Using the raw yellow taxi trip data from January 2019-June 2019, we contrived two datasets to pose node and regression problems for graphical methods. Using GraphSage GNNs, we explored and benchmarked a new application of GNNs to taxi data against classical ML approaches. For fare prediction, the GNN model performed slightly worse than Linear Regression, Random Forests, and a Fully-Connected Neural Network (FC NN), with the FC NN performing the best, however, it is highly-parameterized. For surge prediction, the GNN performed slightly better than a FC NN. For both taxi prediction tasks, we demonstrated that a less complex GNN model can perform comparably to a highly-parameterized FC NN. ")])])])])])])])}],ge={name:"Taxi"},ve=ge,ye=(i("f45c"),Object(h["a"])(ve,me,fe,!1,null,"84625788",null)),we=ye.exports,be=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},Ce=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row align-items-center justify-content-center"},[a("div",{staticClass:"col-12"},[a("h1",[e._v("Trump Campaign Speech Analysis")])]),a("div",{staticClass:"col-md-8"},[a("div",{staticClass:"carousel slide",attrs:{id:"trumpCarousel","data-ride":"carousel","data-interval":"false"}},[a("ol",{staticClass:"carousel-indicators"},[a("li",{staticClass:"active",attrs:{"data-target":"#trumpCarousel","data-slide-to":"0"}}),a("li",{attrs:{"data-target":"#trumpCarousel","data-slide-to":"1"}}),a("li",{attrs:{"data-target":"#trumpCarousel","data-slide-to":"2"}})]),a("div",{staticClass:"carousel-inner"},[a("div",{staticClass:"carousel-item active trump-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("89e4"),alt:"First slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Main Puzzle")]),a("p",[e._v(" There have been concerns that nationalist, right-wing sentiments have gained momentum over the years of the Trump presidency. Our group wanted to investigate how Donald Trump’s rhetoric may have influenced public sentiment on a regional level. To this end, we analyzed Trump's campaign speeches and the tweets by locals from 4 cities he visited on his campaign and Florida, a swing state. ")])])]),a("div",{staticClass:"carousel-item trump-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("3bc0"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Most Frequent Negative and Positive Words in Trump's Campaign Speeches")]),a("p",[e._v(' Trump\'s positive sentiment words tend to be adjectives with "great" far exceeding the rest. Among words with negative sentiment, there are more meaningful words related to his speech topics such as "investigation", "defense", "deficit", & "press". ')])])]),a("div",{staticClass:"carousel-item trump-carousel-item"},[a("img",{staticClass:"col-12 rounded img-fluid",attrs:{src:i("3ea6")}}),a("img",{staticClass:"col-12 rounded img-fluid pt-4",attrs:{src:i("f061")}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Trump's Most Frequently Used Words Across his Entire Campaign & Across Florida Campaign")]),a("p",[e._v(' In Trump\'s speeches across the entire campaign, his most frequent words, normalized on Romney\'s campaign speeches, include "Hillary", "don\'t" "great", "deal", as well as words related to his election platform such as "border", "wall", "Mexico", "ISIS", "trade", and "China". Words used to thwart Hillary Clinton\'s campaign such as "Hillary", "email", "lies", "corrupt", "crook", and "FBI" in regards to Clinton\'s email scandal appear more frequently in Trump\'s Florida campaign speeches than across all of his campaign speeches, showing that in swing states, Trump strategizes to mention the scandal more frequently to win voters to tip the scale. ')])])])])])])])}],_e={name:"Trump"},xe=_e,ke=(i("2a4a"),Object(h["a"])(xe,be,Ce,!1,null,"6a057a3c",null)),je=ke.exports,Se=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},Ne=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row align-items-center justify-content-center"},[a("div",{staticClass:"col-12"},[a("h3",[e._v("Evolution of the U.S. TV News Narrative on Climate Change")])]),a("div",{staticClass:"col-md-8"},[a("div",{staticClass:"carousel slide",attrs:{id:"ccCarousel","data-ride":"carousel","data-interval":"false"}},[a("ol",{staticClass:"carousel-indicators"},[a("li",{staticClass:"active",attrs:{"data-target":"#ccCarousel","data-slide-to":"0"}}),a("li",{attrs:{"data-target":"#ccCarousel","data-slide-to":"1"}}),a("li",{attrs:{"data-target":"#ccCarousel","data-slide-to":"2"}}),a("li",{attrs:{"data-target":"#ccCarousel","data-slide-to":"3"}}),a("li",{attrs:{"data-target":"#ccCarousel","data-slide-to":"4"}})]),a("div",{staticClass:"carousel-inner"},[a("div",{staticClass:"carousel-item active cc-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("d8cb"),alt:"First slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Project Code, Poster, and Report")]),a("p",[e._v(" This was a final project for IDS.131: Statistics, Computation, and Applications. This presentation focuses on introducing the project, the specific parts I worked on, and the main findings from our analysis. "),a("br"),e._v(" A brief overview of the methods, visualizations, and results is available in this "),a("a",{attrs:{href:"./assets/IDS131_Poster.pdf",target:"_blank"}},[e._v("poster PDF.")]),a("br"),e._v(" The more thorough report of our findings with all visualizations is "),a("a",{attrs:{href:"./assets/IDS131_Final_Report.pdf",target:"_blank"}},[e._v("here.")]),a("br"),e._v(" The code for this project was written in Python. "),a("a",{attrs:{href:"https://github.com/dyllew/ids.131-fp",target:"_blank"}},[e._v("Here's the GitHub Repo.")])])])]),a("div",{staticClass:"carousel-item cc-carousel-item"},[a("div",{staticClass:"carousel-text"},[a("h5",[a("strong",[e._v("Motivation & Research Question")])]),a("p",[e._v(" Print and televised media reporting on climate change influences the public perception of climate change, which in turn affects support for systemic policies to reduce greenhouse gas emissions and for individual actions to mitigate climate change. Over two thirds of Americans get their news often or sometimes from television. In this analysis, we looked at ten years of data from three television stations: CNN, Fox News, and MSNBC to address the following research question: "),a("br"),a("strong",{attrs:{id:"research-question"}},[e._v("How has the frequency and content of top American English-speaking news media coverage of climate change evolved in the past ten years (July 2009-January 2020)-and what environmental and political factors have influenced the trends?")])])])]),a("div",{staticClass:"carousel-item cc-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("64e1"),alt:"First slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Dataset, Exploration, and Preprocessing")]),a("p",[e._v(" The data used for this analysis includes text snippets of 15-seconds of TV news audio transcripts of climate change mentions on CNN, MSNBC, and Fox News from July 2009-January 2020, provided by the "),a("a",{attrs:{href:"https://blog.gdeltproject.org/a-new-dataset-for-exploring-climate-change-narratives-on-television-news-2009-2020/",target:"_blank"}},[e._v("GDELT Project.")]),e._v(" The features of the data points include time of day and date of the mention, the TV news network, the show, and the text snippet of the transcribed audio. This dataset provides the ability to compare the TV networks over time on the subject of climate change in order to answer the research question posed. We followed standard Natural Language Processing (NLP) text preprocessing by removing punctuation and numbers, converting all letters to lower-case (the data was already provided as lowercase), lemmatizing, removing standard English stopwords & corpus-specific stopwords, and tokenizing the data into words. We conducted our analysis with two distinct analysis streams: Frequency Analysis and Content Analysis. Our Frequency Analysis entailed methods of time-series analysis of climate change mentions by the different TV networks over time and dynamic time-warping & STL decomposition. Content Analysis used methods of TF-IDF document embeddings, Cosine Similarity as a proxy for content similarity between documents, and Topic Modeling & Change-Point Detection. The above figure was created as part of an exploratory component of the TF-IDF Embedding analysis, in which we wished to extract the most important words to each of the networks across the entire corpus. ")])])]),a("div",{staticClass:"carousel-item cc-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("cad8"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Content Analysis: TF-IDF Document Embedding & Cosine Similarity")]),a("p",[e._v(" My contribution to this project was primarly focused in the Content Analysis stream, specifically TF-IDF document embeddings & Cosine Similarity between documents. To conduct our content analysis, we needed to featurize the news snippets, or collections of snippets, which form the documents in our corpus. I first formed a document for each TV network in our dataset (e.g. all snippets for CNN), and transformed the documents into a L2-normalized unit vector TF-IDF vector embedding. From this featurization, I formed a document-term matrix, where the rows correspond to the TF-IDF embedding of a document and the column represents a unique word in the corpus (~34,000 words). Thus, entry i, j corresponds to the normalized TF-IDF score of word j in document i (i.e. word j's relative importance for the ith document). I also constructed document-term matrices for documents representing each year of our dataset (e.g. all snippets in 2009) as well as for documents constructed from networks in specific years (e.g. all CNN snippets in 2015). Finally, for each of the document-term matrices mentioned above, I calculated the pairwise cosine similarity between the document embeddings to yield a measure of content similarity between the documents. A heatmap constructed from the computed cosine similarities between the network & year documents is shown above. The main findings from my analysis were that the content of climate mentions in the latter years of the dataset, 2016-2020, are most dissimilar to earlier years in the dataset, 2009-2012. Additionally, in the years 2010 & 2018, the content of MSNBC differed greatly from the other news networks in those years and with other networks and itself in other years. This similarly occurred for CNN in 2012 & 2013. Lastly, with the exception of these years, the similarity of content of climate mentions between CNN and MSNBC, the liberal-leaning networks, has been increasing over the years, although the pairwise content similarity between all of the networks is fairly high over time. ")])])]),a("div",{staticClass:"carousel-item cc-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("d8cb"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Results")]),a("p",[e._v(" Climate change TV news media coverage frequency and content appears to be significantly driven by political events more so than environmental factors. The frequency of climate change mentions follow similar patterns by network, with clear influence of political events such as the 2009 UNCCC, 2015 Paris Agreement, and 2019 Democratic primary debates driving climate news coverage. This is reflected in the content of the climate mentions over time as words describing the political events occurring at the time tend to be the most important words for each of the networks in that specific year coupled with the tendency of different networks in the same year to have high content similarity. Topic analysis also finds that the majority of 15 topics found in topic analysis had significant changes in mean on some of the topics at the time of Donald Trump's inauguration. ")])])])])])])])}],Te={name:"ClimateChangeNews"},Pe=Te,Ee=(i("04fc"),Object(h["a"])(Pe,Se,Ne,!1,null,"6aa3ac06",null)),Ie=Ee.exports,Fe=function(){var e=this,t=e.$createElement;e._self._c;return e._m(0)},Me=[function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"row align-items-center justify-content-center"},[a("div",{staticClass:"col-12"},[a("h1",[e._v("Boomerang")])]),a("div",{staticClass:"col-md-8"},[a("div",{staticClass:"carousel slide",attrs:{id:"boomerangCarousel","data-ride":"carousel","data-interval":"false"}},[a("ol",{staticClass:"carousel-indicators"},[a("li",{staticClass:"active",attrs:{"data-target":"#boomerangCarousel","data-slide-to":"0"}}),a("li",{attrs:{"data-target":"#boomerangCarousel","data-slide-to":"1"}}),a("li",{attrs:{"data-target":"#boomerangCarousel","data-slide-to":"2"}})]),a("div",{staticClass:"carousel-inner"},[a("div",{staticClass:"carousel-item active boomerang-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("5e93"),alt:"First slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Sign Up/Login Page")]),a("p",[e._v("When my group decided on how we wanted to split up the tasks for Boomerang, I decided to design & create the sign up/login page & the create account flow. I thought this would be a good section of the application to practice and enhance my visual design skills and to create a UI that was intuitive. ")])])]),a("div",{staticClass:"carousel-item boomerang-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("e1a7"),alt:"Second slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Create Account Part I")]),a("p",[e._v(" In the sections of Boomerang I built, I created the front-end using Vue.js which is the same front-end framework I used to build this website. The backend was built using Express.js. The fields above checked for user input to ensure that the account username was not already taken and that the each of the fields was in the correct format, notifying the user instantly on submission if their input was invalid. ")])])]),a("div",{staticClass:"carousel-item boomerang-carousel-item"},[a("img",{staticClass:"rounded img-fluid",attrs:{src:i("a21f"),alt:"Third slide"}}),a("div",{staticClass:"carousel-text"},[a("h5",[e._v("Create Account Part II")]),a("p",[e._v(" Account creation for any app is an important user flow as it lets the user understand both the purpose of an app & how they can engage with it completely. For these reasons, I decided to include descriptions of the main concepts of the application (Communities, Channels, etc.) as this would reduce the time it would take for a user to get immersed in the app. ")])])])])])])])}],De={name:"Boomerang"},Le=De,Re=(i("fa95"),Object(h["a"])(Le,Fe,Me,!1,null,"d36bdd1c",null)),Ae=Re.exports,Oe=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"col pt-5 justify-content-center"},[i("h2",[e._v("Uh Oh! Looks like you went to a page that doesn't exist on dyllew.github.io")]),i("router-link",{staticClass:"router-link",attrs:{to:"/"}},[e._v("Click this link to go home.")])],1)},We=[],Ge={name:"NotFoundComponent"},qe=Ge,$e=(i("2db4"),Object(h["a"])(qe,Oe,We,!1,null,"4ffa6c61",null)),ze=$e.exports;a["default"].use(j["a"]);var Ue=[{path:"/",component:I},{path:"/about",component:A},{path:"/projects",component:z},{path:"/projects/boomerang",component:Ae},{path:"/projects/ml-for-crowdsourced-crisis-data",component:re},{path:"/projects/nlp-for-int-dev-gray-lit",component:pe},{path:"/projects/trump-speech-analysis",component:je},{path:"/projects/gnns-taxi-prediction",component:we},{path:"/projects/climate-change-news",component:Ie},{path:"/artwork",component:V},{path:"/resume",component:te},{path:"/404",component:ze},{path:"*",redirect:"/404"}],Be=new j["a"]({mode:"hash",routes:Ue}),He=Be;i("f9e3"),i("2dd8");a["default"].config.productionTip=!1,a["default"].use(s["a"]),a["default"].use(n["a"]),new a["default"]({router:He,render:function(e){return e(k)}}).$mount("#app")},"599d":function(e,t,i){},"5e93":function(e,t,i){e.exports=i.p+"img/boomerang-home.2b52b305.jpg"},"64e1":function(e,t,i){e.exports=i.p+"img/network_tfidf_wordclouds.295ee901.png"},"6e8d":function(e,t,i){},"77ef":function(e,t,i){},"7d1a":function(e,t,i){e.exports=i.p+"img/NER.042f94f2.png"},8050:function(e,t){throw new Error("Module parse failed: Unexpected token (1:0)\nYou may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders\n(Source code omitted for this binary file)")},"84e6":function(e,t,i){e.exports=i.p+"img/fare-surge-graph-pred.16940831.png"},"85ec":function(e,t,i){},"878d":function(e,t,i){e.exports=i.p+"img/years_cosine_similarity.1e4e7357.png"},"89e4":function(e,t,i){e.exports=i.p+"img/trump-campaign.81aaea0e.png"},"8b08":function(e,t,i){e.exports=i.p+"img/project-collage.aecae672.png"},9271:function(e,t,i){e.exports=i.p+"img/tfidf-networks.c48a6bce.png"},"9faf":function(e,t,i){e.exports=i.p+"img/pika-gif.6999dd5c.gif"},a21f:function(e,t,i){e.exports=i.p+"img/join-communities.392bb659.png"},a297:function(e,t,i){e.exports=i.p+"img/resume.584109c7.png"},a2c3:function(e,t,i){e.exports=i.p+"img/reptile.b479d166.png"},afd1:function(e,t,i){e.exports=i.p+"img/network_cosine_similarity.0a83a38c.png"},b1c7:function(e,t,i){},b720:function(e,t){throw new Error("Module parse failed: Unexpected token (1:0)\nYou may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders\n(Source code omitted for this binary file)")},c207:function(e,t,i){e.exports=i.p+"img/feelings.7216f530.jpg"},c9e4:function(e,t,i){e.exports=i.p+"img/dylan-n-leo.621aa4fc.jpg"},cad8:function(e,t,i){e.exports=i.p+"img/networks_and_years_cosine_similarity.3eaf2c24.png"},cbeb:function(e,t,i){e.exports=i.p+"img/linkedin-profpic.00cde042.jpg"},d67d:function(e,t,i){},d6c0:function(e,t,i){"use strict";i("599d")},d8cb:function(e,t,i){e.exports=i.p+"img/final-project-overview.13f71d33.png"},e1a7:function(e,t,i){e.exports=i.p+"img/create-account.b25be796.png"},e75b:function(e,t,i){e.exports=i.p+"img/taxi-proj-thumbnail.6dd3b85f.png"},e9ef:function(e,t,i){},eac1:function(e,t,i){"use strict";i("0bc4")},ec0b:function(e,t,i){"use strict";i("04cf")},ee29:function(e,t,i){e.exports=i.p+"img/leo_n_me.2868644e.jpg"},f061:function(e,t,i){e.exports=i.p+"img/RelativeWordFreqDiffFlorida.80584f3b.png"},f124:function(e,t,i){e.exports=i.p+"img/taxi-fare-and-surge-pred.064e07ad.png"},f2e7:function(e,t,i){},f3bd:function(e,t,i){"use strict";i("f2e7")},f45c:function(e,t,i){"use strict";i("6e8d")},f702:function(e,t,i){},fa95:function(e,t,i){"use strict";i("b1c7")},fae1:function(e,t,i){"use strict";i("e9ef")},fe4b:function(e,t,i){"use strict";i("089e")}});
//# sourceMappingURL=app.b47e936d.js.map