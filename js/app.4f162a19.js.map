{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./src/App.vue?7e02","webpack:///./public/assets/IDS131_Final_Report.pdf","webpack:///./public/assets/text-analysis-module.png","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/ImageAnalysisCarousel.vue?d50c","webpack:///./public/assets/fp-train.png","webpack:///./public/assets sync ^\\.\\/.*$","webpack:///./public/assets/6_864_Project.pdf","webpack:///./public/assets/fp-fc.png","webpack:///./public/assets/int-dev-results.png","webpack:///./public/assets/ner-res-tools.png","webpack:///./src/components/ProjectCard.vue?21e4","webpack:///./src/components/NotFoundComponent.vue?dc5a","webpack:///./src/components/Home.vue?3443","webpack:///./src/components/project-pages/GNNsTaxiPrediction.vue?c570","webpack:///./src/components/Header.vue?5705","webpack:///./public/assets/ner-results.png","webpack:///./public/assets/FrequencyPlot.png","webpack:///./public/assets/negative-positive.jpg","webpack:///./public/assets/RelativeWordFrequencyDiff.png","webpack:///./public/assets/17_835_Poster.pdf","webpack:///./src/components/project-pages/TrumpSpeechAnalysis.vue?f980","webpack:///./src/components/project-pages/ClimateChangeNews.vue?482e","webpack:///./public/assets/portrait.jpg","webpack:///./public/assets/ds-fc.png","webpack:///./public/assets/int-dev-gray-lit.pdf","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/TextAnalysisCarousel.vue?31e3","webpack:///./src/components/Resume.vue?fbd6","webpack:///./src/App.vue?b185","webpack:///./src/components/Header.vue?70d1","webpack:///src/components/Header.vue","webpack:///./src/components/Header.vue?4c35","webpack:///./src/components/Header.vue","webpack:///./src/components/NavBar.vue?c937","webpack:///src/components/NavBar.vue","webpack:///./src/components/NavBar.vue?e8e4","webpack:///./src/components/NavBar.vue","webpack:///src/App.vue","webpack:///./src/App.vue?1160","webpack:///./src/App.vue?bff9","webpack:///./src/components/Home.vue?1e14","webpack:///src/components/Home.vue","webpack:///./src/components/Home.vue?705d","webpack:///./src/components/Home.vue","webpack:///./src/components/About.vue?90db","webpack:///src/components/About.vue","webpack:///./src/components/About.vue?f71c","webpack:///./src/components/About.vue","webpack:///./src/components/Projects.vue?d662","webpack:///./src/components/ProjectCard.vue?92fd","webpack:///./src/constants.js","webpack:///src/components/ProjectCard.vue","webpack:///./src/components/ProjectCard.vue?df61","webpack:///./src/components/ProjectCard.vue","webpack:///src/components/Projects.vue","webpack:///./src/components/Projects.vue?e76a","webpack:///./src/components/Projects.vue","webpack:///./src/components/Artwork.vue?cecf","webpack:///src/components/Artwork.vue","webpack:///./src/components/Artwork.vue?f604","webpack:///./src/components/Artwork.vue?b935","webpack:///./src/components/Resume.vue?0f48","webpack:///src/components/Resume.vue","webpack:///./src/components/Resume.vue?960c","webpack:///./src/components/Resume.vue","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/MLForCrowdsourcedCrisisData.vue?eaa0","webpack:///src/components/project-pages/ml-for-crowdsourced-crisis-data/MLForCrowdsourcedCrisisData.vue","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/MLForCrowdsourcedCrisisData.vue?6e85","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/MLForCrowdsourcedCrisisData.vue","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/ImageAnalysisCarousel.vue?9836","webpack:///src/components/project-pages/ml-for-crowdsourced-crisis-data/ImageAnalysisCarousel.vue","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/ImageAnalysisCarousel.vue?0ff0","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/ImageAnalysisCarousel.vue","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/TextAnalysisCarousel.vue?6994","webpack:///src/components/project-pages/ml-for-crowdsourced-crisis-data/TextAnalysisCarousel.vue","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/TextAnalysisCarousel.vue?8e4b","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/TextAnalysisCarousel.vue","webpack:///./src/components/project-pages/NLPIntDevGrayLit.vue?da4e","webpack:///src/components/project-pages/NLPIntDevGrayLit.vue","webpack:///./src/components/project-pages/NLPIntDevGrayLit.vue?6524","webpack:///./src/components/project-pages/NLPIntDevGrayLit.vue","webpack:///./src/components/project-pages/GNNsTaxiPrediction.vue?42d5","webpack:///src/components/project-pages/GNNsTaxiPrediction.vue","webpack:///./src/components/project-pages/GNNsTaxiPrediction.vue?b393","webpack:///./src/components/project-pages/GNNsTaxiPrediction.vue","webpack:///./src/components/project-pages/TrumpSpeechAnalysis.vue?62d0","webpack:///src/components/project-pages/TrumpSpeechAnalysis.vue","webpack:///./src/components/project-pages/TrumpSpeechAnalysis.vue?ec8f","webpack:///./src/components/project-pages/TrumpSpeechAnalysis.vue","webpack:///./src/components/project-pages/ClimateChangeNews.vue?3998","webpack:///src/components/project-pages/ClimateChangeNews.vue","webpack:///./src/components/project-pages/ClimateChangeNews.vue?de66","webpack:///./src/components/project-pages/ClimateChangeNews.vue","webpack:///./src/components/project-pages/Boomerang.vue?0200","webpack:///src/components/project-pages/Boomerang.vue","webpack:///./src/components/project-pages/Boomerang.vue?f111","webpack:///./src/components/project-pages/Boomerang.vue","webpack:///./src/components/NotFoundComponent.vue?7a6e","webpack:///src/components/NotFoundComponent.vue","webpack:///./src/components/NotFoundComponent.vue?7b7a","webpack:///./src/components/NotFoundComponent.vue","webpack:///./src/router.js","webpack:///./src/main.js","webpack:///./public/assets/iaa.png","webpack:///./public/assets/boomerang-home.jpg","webpack:///./public/assets/test-set-eval.png","webpack:///./public/assets/network_tfidf_wordclouds.png","webpack:///./public/assets/in-fc.png","webpack:///./public/assets/image-analysis-module-modified.png","webpack:///./public/assets/NER.png","webpack:///./public/assets/Dylan_Lewis_Resume.pdf","webpack:///./public/assets/fare-surge-graph-pred.png","webpack:///./public/assets/years_cosine_similarity.png","webpack:///./public/assets/trump-campaign.png","webpack:///./public/assets/project-collage.png","webpack:///./public/assets/tfidf-networks.png","webpack:///./public/assets/hc-fc.png","webpack:///./public/assets/ds-train.png","webpack:///./public/assets/pika-gif.gif","webpack:///./public/assets/join-communities.png","webpack:///./public/assets/resume.png","webpack:///./public/assets/reptile.png","webpack:///./public/assets/masters-thesis-overview.png","webpack:///./public/assets/network_cosine_similarity.png","webpack:///./public/assets/IDS131_Poster.pdf","webpack:///./public/assets/in-train.png","webpack:///./src/components/project-pages/ml-for-crowdsourced-crisis-data/MLForCrowdsourcedCrisisData.vue?7078","webpack:///./public/assets/hc-train.png","webpack:///./public/assets/feelings.jpg","webpack:///./public/assets/dylan-n-leo.jpg","webpack:///./public/assets/networks_and_years_cosine_similarity.png","webpack:///./public/assets/linkedin-profpic.jpg","webpack:///./src/components/About.vue?c59f","webpack:///./src/components/project-pages/Boomerang.vue?d210","webpack:///./src/components/NavBar.vue?7897","webpack:///./public/assets/image-analysis-module.png","webpack:///./public/assets/final-project-overview.png","webpack:///./public/assets/create-account.png","webpack:///./public/assets/taxi-proj-thumbnail.png","webpack:///./src/components/project-pages/NLPIntDevGrayLit.vue?cbb5","webpack:///./public/assets/leo_n_me.jpg","webpack:///./public/assets/RelativeWordFreqDiffFlorida.png","webpack:///./public/assets/taxi-fare-and-surge-pred.png","webpack:///./src/components/Artwork.vue?73f1"],"names":["webpackJsonpCallback","data","moduleId","chunkId","chunkIds","moreModules","executeModules","i","resolves","length","Object","prototype","hasOwnProperty","call","installedChunks","push","modules","parentJsonpFunction","shift","deferredModules","apply","checkDeferredModules","result","deferredModule","fulfilled","j","depId","splice","__webpack_require__","s","installedModules","exports","module","l","m","c","d","name","getter","o","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","p","jsonpArray","window","oldJsonpFunction","slice","map","webpackContext","req","id","webpackContextResolve","e","Error","code","keys","resolve","render","_vm","this","_h","$createElement","_c","_self","staticClass","attrs","$route","path","_e","staticRenderFns","on","goHome","_v","_m","methods","component","components","Header","NavBar","goToAbout","goToResume","goToProjects","goToArtwork","windowWidth","innerWidth","$router","_l","project","link","_s","title","class","src","sizeClass","getImgURL","imgFilename","desc","projectWebsite","url","btnText","$event","goToProjectPage","projectBtnText","MAIN_PROJECTS","ML_MODULES","scrollUpFunc","scrollTo","ProjectCard","scrollUp","Vue","use","VueRouter","router","Home","About","Projects","Boomerang","MLForCrowdsourcedCrisisData","ImageAnalysisCarousel","TextAnalysisCarousel","NLPIntDevGrayLit","TrumpSpeechAnalysis","GNNsTaxiPrediction","ClimateChangeNews","Artwork","Resume","NotFoundComponent","redirect","vueRouter","routes","config","productionTip","BootstrapVue","IconsPlugin","h","App","$mount"],"mappings":"aACE,SAASA,EAAqBC,GAQ7B,IAPA,IAMIC,EAAUC,EANVC,EAAWH,EAAK,GAChBI,EAAcJ,EAAK,GACnBK,EAAiBL,EAAK,GAIHM,EAAI,EAAGC,EAAW,GACpCD,EAAIH,EAASK,OAAQF,IACzBJ,EAAUC,EAASG,GAChBG,OAAOC,UAAUC,eAAeC,KAAKC,EAAiBX,IAAYW,EAAgBX,IACpFK,EAASO,KAAKD,EAAgBX,GAAS,IAExCW,EAAgBX,GAAW,EAE5B,IAAID,KAAYG,EACZK,OAAOC,UAAUC,eAAeC,KAAKR,EAAaH,KACpDc,EAAQd,GAAYG,EAAYH,IAG/Be,GAAqBA,EAAoBhB,GAE5C,MAAMO,EAASC,OACdD,EAASU,OAATV,GAOD,OAHAW,EAAgBJ,KAAKK,MAAMD,EAAiBb,GAAkB,IAGvDe,IAER,SAASA,IAER,IADA,IAAIC,EACIf,EAAI,EAAGA,EAAIY,EAAgBV,OAAQF,IAAK,CAG/C,IAFA,IAAIgB,EAAiBJ,EAAgBZ,GACjCiB,GAAY,EACRC,EAAI,EAAGA,EAAIF,EAAed,OAAQgB,IAAK,CAC9C,IAAIC,EAAQH,EAAeE,GACG,IAA3BX,EAAgBY,KAAcF,GAAY,GAE3CA,IACFL,EAAgBQ,OAAOpB,IAAK,GAC5Be,EAASM,EAAoBA,EAAoBC,EAAIN,EAAe,KAItE,OAAOD,EAIR,IAAIQ,EAAmB,GAKnBhB,EAAkB,CACrB,IAAO,GAGJK,EAAkB,GAGtB,SAASS,EAAoB1B,GAG5B,GAAG4B,EAAiB5B,GACnB,OAAO4B,EAAiB5B,GAAU6B,QAGnC,IAAIC,EAASF,EAAiB5B,GAAY,CACzCK,EAAGL,EACH+B,GAAG,EACHF,QAAS,IAUV,OANAf,EAAQd,GAAUW,KAAKmB,EAAOD,QAASC,EAAQA,EAAOD,QAASH,GAG/DI,EAAOC,GAAI,EAGJD,EAAOD,QAKfH,EAAoBM,EAAIlB,EAGxBY,EAAoBO,EAAIL,EAGxBF,EAAoBQ,EAAI,SAASL,EAASM,EAAMC,GAC3CV,EAAoBW,EAAER,EAASM,IAClC3B,OAAO8B,eAAeT,EAASM,EAAM,CAAEI,YAAY,EAAMC,IAAKJ,KAKhEV,EAAoBe,EAAI,SAASZ,GACX,qBAAXa,QAA0BA,OAAOC,aAC1CnC,OAAO8B,eAAeT,EAASa,OAAOC,YAAa,CAAEC,MAAO,WAE7DpC,OAAO8B,eAAeT,EAAS,aAAc,CAAEe,OAAO,KAQvDlB,EAAoBmB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQlB,EAAoBkB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,kBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKxC,OAAOyC,OAAO,MAGvB,GAFAvB,EAAoBe,EAAEO,GACtBxC,OAAO8B,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOlB,EAAoBQ,EAAEc,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRtB,EAAoB0B,EAAI,SAAStB,GAChC,IAAIM,EAASN,GAAUA,EAAOiB,WAC7B,WAAwB,OAAOjB,EAAO,YACtC,WAA8B,OAAOA,GAEtC,OADAJ,EAAoBQ,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRV,EAAoBW,EAAI,SAASgB,EAAQC,GAAY,OAAO9C,OAAOC,UAAUC,eAAeC,KAAK0C,EAAQC,IAGzG5B,EAAoB6B,EAAI,IAExB,IAAIC,EAAaC,OAAO,gBAAkBA,OAAO,iBAAmB,GAChEC,EAAmBF,EAAW3C,KAAKsC,KAAKK,GAC5CA,EAAW3C,KAAOf,EAClB0D,EAAaA,EAAWG,QACxB,IAAI,IAAItD,EAAI,EAAGA,EAAImD,EAAWjD,OAAQF,IAAKP,EAAqB0D,EAAWnD,IAC3E,IAAIU,EAAsB2C,EAI1BzC,EAAgBJ,KAAK,CAAC,EAAE,kBAEjBM,K,sGCvJT,yBAAwb,EAAG,G,gDCA3bW,EAAOD,QAAU,IAA0B,wC,uBCA3CC,EAAOD,QAAU,IAA0B,yC,oCCA3C,yBAAwhB,EAAG,G,uBCA3hBC,EAAOD,QAAU,IAA0B,6B,qBCA3C,IAAI+B,EAAM,CACT,sBAAuB,OACvB,sBAAuB,OACvB,2BAA4B,OAC5B,sBAAuB,OACvB,4BAA6B,OAC7B,sBAAuB,OACvB,YAAa,OACb,oCAAqC,OACrC,kCAAmC,OACnC,uBAAwB,OACxB,uBAAwB,OACxB,cAAe,OACf,iBAAkB,OAClB,oBAAqB,OACrB,8BAA+B,OAC/B,iBAAkB,OAClB,+BAAgC,OAChC,cAAe,OACf,iBAAkB,OAClB,cAAe,OACf,iBAAkB,OAClB,YAAa,OACb,uCAAwC,OACxC,8BAA+B,OAC/B,cAAe,OACf,iBAAkB,OAClB,yBAA0B,OAC1B,wBAAyB,OACzB,yBAA0B,OAC1B,iBAAkB,OAClB,yBAA0B,OAC1B,gCAAiC,OACjC,0BAA2B,OAC3B,sBAAuB,OACvB,oBAAqB,OACrB,kCAAmC,OACnC,iCAAkC,OAClC,6CAA8C,OAC9C,iBAAkB,OAClB,iBAAkB,OAClB,wBAAyB,OACzB,gBAAiB,OACjB,eAAgB,OAChB,iCAAkC,OAClC,4BAA6B,OAC7B,sBAAuB,OACvB,6BAA8B,OAC9B,uBAAwB,OACxB,uBAAwB,OACxB,gCAAiC,QAIlC,SAASC,EAAeC,GACvB,IAAIC,EAAKC,EAAsBF,GAC/B,OAAOpC,EAAoBqC,GAE5B,SAASC,EAAsBF,GAC9B,IAAIpC,EAAoBW,EAAEuB,EAAKE,GAAM,CACpC,IAAIG,EAAI,IAAIC,MAAM,uBAAyBJ,EAAM,KAEjD,MADAG,EAAEE,KAAO,mBACHF,EAEP,OAAOL,EAAIE,GAEZD,EAAeO,KAAO,WACrB,OAAO5D,OAAO4D,KAAKR,IAEpBC,EAAeQ,QAAUL,EACzBlC,EAAOD,QAAUgC,EACjBA,EAAeE,GAAK,Q,uBCvEpBjC,EAAOD,QAAU,IAA0B,wC,uBCA3CC,EAAOD,QAAU,IAA0B,0B,uBCA3CC,EAAOD,QAAU,IAA0B,oC,qBCA3CC,EAAOD,QAAU,IAA0B,kC,oCCA3C,yBAA0e,EAAG,G,oCCA7e,yBAAgf,EAAG,G,oCCAnf,yBAAme,EAAG,G,oCCAte,yBAAmgB,EAAG,G,kCCAtgB,yBAAqe,EAAG,G,uBCAxeC,EAAOD,QAAU,IAA0B,gC,uBCA3CC,EAAOD,QAAU,IAA0B,kC,gDCA3CC,EAAOD,QAAU,IAA0B,sC,gDCA3CC,EAAOD,QAAU,IAA0B,8C,qBCA3CC,EAAOD,QAAU,IAA0B,wC,kCCA3C,yBAAogB,EAAG,G,kCCAvgB,yBAAkgB,EAAG,G,qBCArgBC,EAAOD,QAAU,IAA0B,6B,gDCA3CC,EAAOD,QAAU,IAA0B,0B,uBCA3CC,EAAOD,QAAU,IAA0B,wC,oCCA3C,yBAAuhB,EAAG,G,oCCA1hB,yBAAqe,EAAG,G,0GCApeyC,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iCAAiCC,MAAM,CAAC,GAAK,QAAQ,CAACH,EAAG,UAAgC,MAArBH,KAAKO,OAAOC,MAAqC,SAArBR,KAAKO,OAAOC,KAAiBL,EAAG,UAAUJ,EAAIU,KAAKN,EAAG,gBAAgB,IACxRO,EAAkB,GCDlB,EAAS,WAAa,IAAIX,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,2BAA2B,CAACF,EAAG,MAAM,CAACE,YAAY,2BAA2BC,MAAM,CAAC,GAAK,kBAAkB,CAACH,EAAG,KAAK,CAACG,MAAM,CAAC,GAAK,4BAA4BK,GAAG,CAAC,MAAQZ,EAAIa,SAAS,CAACb,EAAIc,GAAG,qBAAqBd,EAAIe,GAAG,MAC5U,EAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,mBAAmBC,MAAM,CAAC,GAAK,cAAc,CAACH,EAAG,MAAM,CAACE,YAAY,iEAAiE,CAACF,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,gCAAgC,CAACH,EAAG,IAAI,CAACE,YAAY,2BAA2BF,EAAG,IAAI,CAACE,YAAY,6BAA6BF,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,sCAAsC,OAAS,WAAW,CAACH,EAAG,IAAI,CAACE,YAAY,gCAAgCF,EAAG,IAAI,CAACE,YAAY,kCAAkCF,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,6BAA6B,OAAS,WAAW,CAACH,EAAG,IAAI,CAACE,YAAY,uBAAuBF,EAAG,IAAI,CAACE,YAAY,+BCwB/tB,GACE1C,KAAM,SACNoD,QAAS,CACP,SACE,KAAN,qBC7BgV,I,wBCQ5UC,EAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIa,EAAAA,E,QCnBX,EAAS,WAAa,IAAIjB,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,mCAAmC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,GAAK,YAAY,CAACH,EAAG,cAAc,CAACE,YAAY,cAAcC,MAAM,CAAC,GAAK,WAAW,CAACP,EAAIc,GAAG,cAAcd,EAAIc,GAAG,OAAOV,EAAG,cAAc,CAACE,YAAY,cAAcC,MAAM,CAAC,GAAK,cAAc,CAACP,EAAIc,GAAG,cAAcd,EAAIc,GAAG,OAAOV,EAAG,cAAc,CAACE,YAAY,cAAcC,MAAM,CAAC,GAAK,aAAa,CAACP,EAAIc,GAAG,aAAad,EAAIc,GAAG,OAAOV,EAAG,cAAc,CAACE,YAAY,cAAcC,MAAM,CAAC,GAAK,YAAY,CAACP,EAAIc,GAAG,aAAa,MACnmB,EAAkB,GCWtB,GACElD,KAAM,UCbwU,ICQ5U,G,UAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,OAIa,I,QCPf,GACEA,KAAM,MACNsD,WAAY,CACVC,OAAJ,EACIC,OAAJ,IChB8T,ICQ1T,G,UAAY,eACd,EACArB,EACAY,GACA,EACA,KACA,KACA,OAIa,I,oBCnBX,EAAS,WAAa,IAAIX,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,wDAAwD,CAACF,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,GAAK,UAAU,CAACH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,cAAcV,EAAG,MAAM,CAACE,YAAY,aAAaM,GAAG,CAAC,MAAQZ,EAAIqB,YAAY,CAACjB,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,IAAM,EAAQ,iBAAgDH,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,GAAK,WAAW,CAACH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,YAAYV,EAAG,MAAM,CAACE,YAAY,aAAaM,GAAG,CAAC,MAAQZ,EAAIsB,aAAa,CAAClB,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,IAAM,EAAQ,iBAA2CH,EAAG,MAAM,CAACE,YAAY,WAAWC,MAAM,CAAC,GAAK,sBAAsB,CAACH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,cAAcV,EAAG,MAAM,CAACE,YAAY,aAAaM,GAAG,CAAC,MAAQZ,EAAIuB,eAAe,CAACnB,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,eAAkDH,EAAG,MAAM,CAACE,YAAY,sBAAsB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,aAAaV,EAAG,MAAM,CAACE,YAAY,aAAaM,GAAG,CAAC,MAAQZ,EAAIwB,cAAc,CAACpB,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,IAAM,EAAQ,iBAA6CH,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,GAAK,YAAY,CAACH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,aAAaV,EAAG,MAAM,CAACE,YAAY,aAAaM,GAAG,CAAC,MAAQZ,EAAIwB,cAAc,CAACpB,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,IAAM,EAAQ,iBAA6CH,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,GAAK,aAAa,CAACH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,cAAcV,EAAG,MAAM,CAACE,YAAY,aAAaM,GAAG,CAAC,MAAQZ,EAAIuB,eAAe,CAACnB,EAAG,MAAM,CAACE,YAAY,8BAA8BC,MAAM,CAAC,IAAM,EAAQ,oBACp+D,EAAkB,GCsEtB,GACE3C,KAAM,OACN,OACE,MAAO,CACL6D,YAAavC,OAAOwC,aAGxBV,QAAS,CACP,YACEf,KAAK0B,QAAQrF,KAAK,WAEpB,eACE2D,KAAK0B,QAAQrF,KAAK,cAEpB,cACE2D,KAAK0B,QAAQrF,KAAK,aAEpB,aACE2D,KAAK0B,QAAQrF,KAAK,cCzFsT,ICQ1U,G,UAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,OAIa,I,QCnBX,EAAS,WAAa,IAAI0D,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,EAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,6DAA6DC,MAAM,CAAC,GAAK,mBAAmB,CAACH,EAAG,MAAM,CAACE,YAAY,4CAA4C,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,GAAK,oBAAoB,IAAM,EAAQ,QAAoC,IAAM,qBAAqBH,EAAG,MAAM,CAACE,YAAY,oCAAoCC,MAAM,CAAC,GAAK,sBAAsB,CAACH,EAAG,IAAI,CAACG,MAAM,CAAC,GAAK,oBAAoB,CAACP,EAAIc,GAAG,kSAAkSV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,+CAA+C,CAACP,EAAIc,GAAG,WAAWd,EAAIc,GAAG,6CAA6CV,EAAG,IAAI,CAACJ,EAAIc,GAAG,6HAA6HV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,gCAAgC,CAACP,EAAIc,GAAG,YAAYd,EAAIc,GAAG,aAAaV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,sCAAsC,OAAS,WAAW,CAACP,EAAIc,GAAG,eAAed,EAAIc,GAAG,kBAAkBV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,6BAA6B,OAAS,WAAW,CAACP,EAAIc,GAAG,aAAad,EAAIc,GAAG,yFAAyFV,EAAG,IAAI,CAACJ,EAAIc,GAAG,6PC8BviD,GACElD,KAAM,SChCuU,ICQ3U,G,UAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,OAIa,I,QCnBX,EAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiDN,EAAI4B,GAAI5B,EAAY,UAAE,SAAS6B,GAAS,OAAOzB,EAAG,MAAM,CAACzB,IAAIkD,EAAQC,KAAKxB,YAAY,iCAAiC,CAACF,EAAG,cAAc,CAACG,MAAM,CAAC,QAAUsB,MAAY,MAAK,IAC/U,EAAkB,GCDlB,EAAS,WAAa,IAAI7B,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,sDAAsD,CAACF,EAAG,KAAK,CAACE,YAAY,eAAe,CAACN,EAAIc,GAAGd,EAAI+B,GAAG/B,EAAI6B,QAAQG,UAAU5B,EAAG,MAAM,CAACE,YAAY,eAAe2B,MAAMjC,EAAI6B,QAAQK,IAAIC,UAAYnC,EAAI6B,QAAQK,IAAIC,UAAY,GAAG5B,MAAM,CAAC,GAAKP,EAAI6B,QAAQrC,GAAG,IAAMQ,EAAIoC,UAAUpC,EAAI6B,QAAQK,IAAIG,aAAa,IAAM,mBAAmBjC,EAAG,MAAM,CAACE,YAAY,aAAa,CAACF,EAAG,IAAI,CAACE,YAAY,aAAa,CAACN,EAAIc,GAAGd,EAAI+B,GAAG/B,EAAI6B,QAAQS,SAAUtC,EAAI6B,QAAsB,eAAEzB,EAAG,MAAM,CAACG,MAAM,CAAC,GAAKP,EAAI6B,QAAQU,eAAe/C,KAAK,CAACY,EAAG,IAAI,CAACE,YAAY,sBAAsBC,MAAM,CAAC,KAAOP,EAAI6B,QAAQU,eAAeC,IAAI,OAAS,WAAW,CAACxC,EAAIc,GAAGd,EAAI+B,GAAG/B,EAAI6B,QAAQU,eAAeE,YAAYrC,EAAG,QAAQA,EAAG,IAAI,CAACE,YAAY,mCAAmCM,GAAG,CAAC,MAAQ,SAAS8B,GAAQ,OAAO1C,EAAI2C,gBAAgB3C,EAAI6B,QAAQC,SAAS,CAAC9B,EAAIc,GAAGd,EAAI+B,GAAG/B,EAAI4C,qBAAqBxC,EAAG,MAAM,CAACG,MAAM,CAAC,GAAK,kBAAkB,CAACH,EAAG,IAAI,CAACE,YAAY,6BAA6BM,GAAG,CAAC,MAAQ,SAAS8B,GAAQ,OAAO1C,EAAI2C,gBAAgB3C,EAAI6B,QAAQC,SAAS,CAAC9B,EAAIc,GAAG,gCACjoC,EAAkB,GCDf,MAAM+B,EAAgB,CACzB,CACIrD,GAAI,kCACJsC,KAAM,4CACNI,IAAK,CAACG,YAAa,+BACnBL,MAAO,2GACPM,KAAM,qPACNC,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,sBACTD,IAAK,gDAGb,CACIhD,GAAI,2BACJsC,KAAM,qCACNI,IAAK,CAACG,YAAa,uBACnBL,MAAO,mIACPM,KAAM,6PACNC,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,mBACTD,IAAK,kCAGb,CACIhD,GAAI,sBACJsC,KAAM,gCACNI,IAAK,CAACG,YAAa,8BACnBL,MAAO,4DACPM,KAAM,kNACNC,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,aACTD,IAAK,+BAGb,CACIhD,GAAI,gBACJsC,KAAM,iCACNI,IAAK,CAACG,YAAa,6BACnBL,MAAO,oEACPM,KAAM,kJAEV,CACI9C,GAAI,YACJsC,KAAM,kCACNI,IAAK,CAACG,YAAa,oBAAqBF,UAAW,QACnDH,MAAO,iCACPM,KAAM,mJACNC,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,aACTD,IAAK,+BAGb,CACIhD,GAAI,gBACJsC,KAAM,sBACNI,IAAK,CAACG,YAAa,sBACnBL,MAAO,YACPM,KAAM,wIACNC,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,8BACTD,IAAK,sDAKJM,EAAa,CACtB,CACItD,GAAI,mBACJsC,KAAM,kEACNI,IAAK,CAACG,YAAa,sCACnBL,MAAO,wBACPM,KAAM,wSACNM,eAAgB,qBAChBL,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,mBACTD,IAAK,gIAGb,CACIhD,GAAI,kBACJsC,KAAM,iEACNI,IAAK,CAACG,YAAa,4BACnBL,MAAO,uBACPM,KAAM,6PACNM,eAAgB,qBAChBL,eAAgB,CACZ/C,GAAI,gBACJiD,QAAS,mBACTD,IAAK,gIAKV,SAASO,IACZ7D,OAAO8D,SAAS,EAAG,GC3EvB,OACE,KAAF,cACE,MAAF,YACE,QAAF,CACI,gBAAJ,GACM,KAAN,gBACM,KAEF,UAAJ,GACM,OAAN,oBAGE,SAAF,CACI,iBACE,OAAN,iFCvCqV,ICQjV,G,UAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,OAIa,I,QCPf,GACEpF,KAAM,WACNsD,WAAY,CACV+B,YAAJ,GAEE,OACE,MAAJ,CACM,SAAN,KCnBkV,ICO9U,EAAY,eACd,EACA,EACA,GACA,EACA,KACA,KACA,MAIa,I,QClBX,EAAS,WAAa,IAAIjD,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,mFAAmF,CAACF,EAAG,MAAM,CAACE,YAAY,+BAA+B,CAACF,EAAG,KAAK,CAACE,YAAY,UAAU,CAACN,EAAIc,GAAG,iBAAiBV,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,aAAyCH,EAAG,MAAM,CAACE,YAAY,+BAA+B,CAACF,EAAG,KAAK,CAACE,YAAY,UAAU,CAACN,EAAIc,GAAG,oBAAoBV,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,iBC2B1lB,IACE3C,KAAM,WC7ByU,MCQ7U,I,UAAY,eACd,GACA,EACA,IACA,EACA,KACA,KACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,wDAAwD,CAACF,EAAG,MAAM,CAACE,YAAY,cAAcC,MAAM,CAAC,GAAK,eAAe,CAACH,EAAG,IAAI,CAACE,YAAY,6BAA6BC,MAAM,CAAC,OAAS,SAAS,KAAO,oCAAoC,CAACP,EAAIc,GAAG,uBAAuBV,EAAG,MAAM,CAACE,YAAY,eAAe,CAACF,EAAG,QAAQ,CAACE,YAAY,MAAMC,MAAM,CAAC,IAAM,2CCY9d,IACE3C,KAAM,UCdwU,MCQ5U,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACN,EAAIe,GAAG,GAAGX,EAAG,MAAM,CAACE,YAAY,aAAa,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,aAAa,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,WAAW,CAAClD,EAAIe,GAAG,KAAKX,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,cAAc9C,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACN,EAAIe,GAAG,GAAGf,EAAIe,GAAG,GAAGf,EAAIe,GAAG,GAAGX,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,kCAAkCd,EAAIc,GAAG,iHAAiHV,EAAG,MAAMJ,EAAIc,GAAG,iDAAiDV,EAAG,MAAMA,EAAG,MAAMA,EAAG,IAAI,CAACJ,EAAIc,GAAG,kRAAkRV,EAAG,MAAM,CAACE,YAAY,sDAAsDN,EAAI4B,GAAI5B,EAAW,SAAE,SAASzC,GAAQ,OAAO6C,EAAG,MAAM,CAACzB,IAAIpB,EAAOuE,KAAKxB,YAAY,gCAAgC,CAACF,EAAG,cAAc,CAACG,MAAM,CAAC,QAAUhD,MAAW,MAAK,cACzpD,GAAkB,CAAC,WAAa,IAAIyC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,SAAS,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,iHAAiH,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,WAAW,CAACF,EAAG,OAAO,CAACE,YAAY,eAAe,CAACN,EAAIc,GAAG,+BAA+B,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,yCAAyC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,GAAK,eAAe,IAAM,EAAQ,QAAyD,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,oEAAoEV,EAAG,IAAI,CAACJ,EAAIc,GAAG,kfAAkfV,EAAG,MAAMA,EAAG,MAAMJ,EAAIc,GAAG,gDAAgDV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,8CAA8C,OAAS,WAAW,CAACP,EAAIc,GAAG,WAAWV,EAAG,MAAMA,EAAG,MAAMJ,EAAIc,GAAG,6EAA6EV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,0FAA0F,OAAS,WAAW,CAACP,EAAIc,GAAG,6BAA6BV,EAAG,MAAMJ,EAAIc,GAAG,gRAAgRV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,oDAAoD,OAAS,WAAW,CAACP,EAAIc,GAAG,sBAAsBd,EAAIc,GAAG,qMAAqMV,EAAG,KAAK,CAACA,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,kDAAkD,OAAS,WAAW,CAACP,EAAIc,GAAG,qBAAqBd,EAAIc,GAAG,sLAAsLV,EAAG,MAAMJ,EAAIc,GAAG,6FAA6F,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,gBAAgBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,uOAAuOV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,qCAAqC,OAAS,WAAW,CAACP,EAAIc,GAAG,aAAad,EAAIc,GAAG,SAASV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,+BAA+B,OAAS,WAAW,CAACP,EAAIc,GAAG,aAAad,EAAIc,GAAG,sfAAsfV,EAAG,IAAI,CAACJ,EAAIc,GAAG,w0CAAw0CV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,yBAAyBV,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,sBAAsB,CAACP,EAAIc,GAAG,qQAAqQ,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,wBAAwBV,EAAG,IAAI,CAACG,MAAM,CAAC,GAAK,kBAAkB,CAACH,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,oDAAoDd,EAAIc,GAAG,0IAA0IV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,oGAAoGd,EAAIc,GAAG,wCAAwCV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,mEAAmEd,EAAIc,GAAG,mDAAmDV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,yEAAyEd,EAAIc,GAAG,0FAA0Fd,EAAIc,GAAG,wSAAwSV,EAAG,KAAK,CAACJ,EAAIc,GAAG,qBAAqBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,wIAAwIV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,kCAAkCd,EAAIc,GAAG,sIAAsIV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,+BAA+Bd,EAAIc,GAAG,oKAAoKV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,wDAAwDd,EAAIc,GAAG,qQAAqQV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,sEAAsEd,EAAIc,GAAG,6fAA6fV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,iEAAiEd,EAAIc,GAAG,iZAAiZd,EAAIc,GAAG,6BAA6BV,EAAG,IAAI,CAACJ,EAAIc,GAAG,sCAAsCd,EAAIc,GAAG,iIAAiIV,EAAG,IAAI,CAACJ,EAAIc,GAAG,sCAAsCd,EAAIc,GAAG,8DCmIz1S,IACElD,KAAM,8BACNsD,WAAY,CACV+B,YAAJ,GAEE,OACE,MAAO,CACL,QAAN,IAGEjC,QAAS,CACP,WACE,OChJ6X,MCQ/X,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIhB,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,SAAS,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,6BAA6BV,EAAG,MAAM,CAACE,YAAY,aAAa,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,aAAa,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,SAASH,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,yCAAyC,CAACF,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,mBAAmB,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,GAAK,wBAAwB,IAAM,EAAQ,QAAuD,IAAM,oBAAoBH,EAAG,MAAM,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,yCAAyCV,EAAG,IAAI,CAACJ,EAAIc,GAAG,wpBAAwpBV,EAAG,MAAMA,EAAG,MAAMJ,EAAIc,GAAG,q/BAAq/BV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,+EAA+EV,EAAG,MAAM,CAACE,YAAY,8BAA8B,CAACF,EAAG,MAAM,CAACE,YAAY,uBAAuB,CAACF,EAAG,IAAI,CAACJ,EAAIc,GAAG,qUAAqUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,oDAAoDV,EAAG,IAAI,CAACJ,EAAIc,GAAG,0GAA0GV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,8DAA8D,CAACP,EAAIc,GAAG,eAAed,EAAIc,GAAG,+JAA+JV,EAAG,KAAK,CAACJ,EAAIc,GAAG,wDAAwDV,EAAG,IAAI,CAACJ,EAAIc,GAAG,yZAA6ZV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,SAAS,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,wCAAwCd,EAAIc,GAAG,mHAAmHV,EAAG,QAAQ,CAACG,MAAM,CAAC,GAAK,aAAa,CAACH,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,eAAeV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,aAAaV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,iBAAiBV,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,eAAeV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,iCAAiCV,EAAG,MAAMJ,EAAIc,GAAG,MAAMV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACP,EAAIc,GAAG,sBAAsBd,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,WAAWV,EAAG,KAAK,CAACJ,EAAIc,GAAG,aAAaV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,kCAAkCV,EAAG,MAAMJ,EAAIc,GAAG,MAAMV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACP,EAAIc,GAAG,sBAAsBd,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,SAASV,EAAG,KAAK,CAACJ,EAAIc,GAAG,YAAYV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,6BAA6BV,EAAG,MAAMJ,EAAIc,GAAG,MAAMV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACP,EAAIc,GAAG,sBAAsBd,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,SAASV,EAAG,KAAK,CAACJ,EAAIc,GAAG,SAASV,EAAG,KAAK,CAACJ,EAAIc,GAAG,WAAWV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,6BAA6BV,EAAG,MAAMJ,EAAIc,GAAG,MAAMV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACP,EAAIc,GAAG,sBAAsBd,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,SAASV,EAAG,KAAK,CAACJ,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,YAAYV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIc,GAAG,WAAWV,EAAG,KAAK,CAACJ,EAAIc,GAAG,UAAUV,EAAG,KAAK,CAACJ,EAAIc,GAAG,WAAWV,EAAG,KAAK,CAACJ,EAAIc,GAAG,uBAAuBV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,yBAAyBV,EAAG,MAAM,CAACE,YAAY,kDAAkD,CAACF,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,aAA+CH,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,aAA+CH,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,aAA+CH,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,eAAiDH,EAAG,IAAI,CAACJ,EAAIc,GAAG,gfAAsfV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,4EAA4EV,EAAG,MAAM,CAACE,YAAY,SAAS,CAACN,EAAIc,GAAG,oJAAoJV,EAAG,MAAM,CAACA,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,OAAO,GAAK,SAAS,CAACP,EAAIc,GAAG,SAASV,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,eAAsDH,EAAG,IAAI,CAACJ,EAAIc,GAAG,kCAAkCV,EAAG,MAAM,CAACA,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,OAAO,GAAK,SAAS,CAACP,EAAIc,GAAG,SAASd,EAAIc,GAAG,6SAA6SV,EAAG,SAAS,CAACJ,EAAIc,GAAG,8FAA8Fd,EAAIc,GAAG,yTAAyTV,EAAG,MAAMA,EAAG,IAAI,CAACA,EAAG,MAAM,CAACG,MAAM,CAAC,GAAK,QAAQ,CAACP,EAAIc,GAAG,0EAA0EV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,uCAAuC,OAAS,WAAW,CAACP,EAAIc,GAAG,uGAAuGd,EAAIc,GAAG,kHAAkHV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,QAAQ,MAAQ,yCAAyC,CAACP,EAAIc,GAAG,eAAeV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,0CAA0CV,EAAG,IAAI,CAACJ,EAAIc,GAAG,0KAA0KV,EAAG,SAAS,CAACJ,EAAIc,GAAG,gBAAgBd,EAAIc,GAAG,+RAA+RV,EAAG,IAAI,CAACA,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIc,GAAG,4GAA4GV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,uKAAuK,OAAS,WAAW,CAACP,EAAIc,GAAG,gBAAgBd,EAAIc,GAAG,iCAAiCV,EAAG,KAAK,CAACJ,EAAIc,GAAG,4CAA4CV,EAAG,SAAS,CAACJ,EAAIc,GAAG,gCAAgCd,EAAIc,GAAG,uBAAuBV,EAAG,KAAK,CAACJ,EAAIc,GAAG,uHAAuHV,EAAG,IAAI,CAACJ,EAAIc,GAAG,2dAA2dV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,wEAAwEV,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,mBAAmB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,iJAAkJV,EAAG,MAAM,CAACA,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,OAAO,GAAK,SAAS,CAACP,EAAIc,GAAG,aAAaV,EAAG,MAAM,CAACE,YAAY,uBAAuB,CAACF,EAAG,IAAI,CAACJ,EAAIc,GAAG,+BAA+BV,EAAG,SAAS,CAACJ,EAAIc,GAAG,qBAAqBd,EAAIc,GAAG,+EAA+EV,EAAG,SAAS,CAACJ,EAAIc,GAAG,2CAA2Cd,EAAIc,GAAG,oEAAoEV,EAAG,MAAMA,EAAG,MAAMJ,EAAIc,GAAG,+DAA+DV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIc,GAAG,+CAA+CV,EAAG,KAAK,CAACJ,EAAIc,GAAG,mDAAmDV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIc,GAAG,0CAA0CV,EAAG,KAAK,CAACJ,EAAIc,GAAG,+DAA+DV,EAAG,KAAK,CAACJ,EAAIc,GAAG,6CAA6Cd,EAAIc,GAAG,4FAA4FV,EAAG,SAAS,CAACJ,EAAIc,GAAG,sJAAsJV,EAAG,MAAMA,EAAG,IAAI,CAACA,EAAG,MAAM,CAACG,MAAM,CAAC,GAAK,QAAQ,CAACP,EAAIc,GAAG,kFAAkFV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACP,EAAIc,GAAG,2GAA2Gd,EAAIc,GAAG,qCAAqCV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,QAAQ,MAAQ,yCAAyC,CAACP,EAAIc,GAAG,aAAaV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,wEAAwEV,EAAG,MAAM,CAACE,YAAY,SAAS,CAACN,EAAIc,GAAG,+DAA+DV,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,eAA4CH,EAAG,MAAMA,EAAG,IAAI,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,mBAAmBd,EAAIc,GAAG,uHAAuHV,EAAG,SAAS,CAACJ,EAAIc,GAAG,6BAA6Bd,EAAIc,GAAG,oLAAsLV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIc,GAAG,oNAAoNV,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIc,GAAG,gTAAgTV,EAAG,KAAK,CAACJ,EAAIc,GAAG,8KAA8KV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,2CAA2CV,EAAG,MAAM,CAACE,YAAY,kDAAkD,CAACF,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,aAA4CH,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,aAA4CH,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,aAA4CH,EAAG,MAAM,CAACE,YAAY,iCAAiC,CAACF,EAAG,MAAM,CAACE,YAAY,YAAYC,MAAM,CAAC,IAAM,EAAQ,eAA8CH,EAAG,IAAI,CAACJ,EAAIc,GAAG,ilBAAilBV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,0BAA0BV,EAAG,MAAM,CAACG,MAAM,CAAC,GAAK,WAAW,IAAM,EAAQ,yBCwTxhiB,IACE3C,KAAM,yBC1TqX,MCQzX,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,SAAS,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,4BAA4BV,EAAG,MAAM,CAACE,YAAY,aAAa,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,aAAa,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,cAAc,gBAAgB,SAASH,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,yCAAyC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,MAAM,CAACG,MAAM,CAAC,GAAK,WAAW,IAAM,EAAQ,QAA0C,IAAM,+BCwB3wB,IACE3C,KAAM,wBC1BoX,MCQxX,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACN,EAAIe,GAAG,GAAGX,EAAG,MAAM,CAACE,YAAY,YAAY,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,uBAAuB,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,wBAAwB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,wBAAwB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,wBAAwB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,wBAAwB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,wBAAwB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,wBAAwB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,cAAclD,EAAIe,GAAG,UAClgC,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,SAAS,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,yIAAyI,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,kDAAkD,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA8C,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,4CAA4CV,EAAG,IAAI,CAACJ,EAAIc,GAAG,6MAA6MV,EAAG,MAAMJ,EAAIc,GAAG,mFAAmFV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,gCAAgC,OAAS,WAAW,CAACP,EAAIc,GAAG,uBAAuBV,EAAG,MAAMJ,EAAIc,GAAG,+EAA+EV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,6BAA6B,OAAS,WAAW,CAACP,EAAIc,GAAG,WAAWV,EAAG,MAAMJ,EAAIc,GAAG,sDAAsDV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,qCAAqC,OAAS,WAAW,CAACP,EAAIc,GAAG,+BAA+BV,EAAG,IAAI,CAACJ,EAAIc,GAAG,qJAAqJV,EAAG,MAAM,CAACE,YAAY,2CAA2C,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,cAAcV,EAAG,IAAI,CAACJ,EAAIc,GAAG,k/CAAk/CV,EAAG,MAAM,CAACE,YAAY,2CAA2C,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,uFAAuFV,EAAG,IAAI,CAACJ,EAAIc,GAAG,icAAicV,EAAG,KAAK,CAACJ,EAAIc,GAAG,oDAAoDV,EAAG,IAAI,CAACJ,EAAIc,GAAG,8GAA8GV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,wCAAwC,OAAS,WAAW,CAACP,EAAIc,GAAG,qCAAqCd,EAAIc,GAAG,omBAAomBV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,2HAA2H,OAAS,WAAW,CAACP,EAAIc,GAAG,oCAAoCd,EAAIc,GAAG,sbAAsbV,EAAG,KAAK,CAACJ,EAAIc,GAAG,yFAAyFV,EAAG,IAAI,CAACJ,EAAIc,GAAG,uxBAAuxBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,UAAUd,EAAIc,GAAG,iGAAiGV,EAAG,KAAK,CAACJ,EAAIc,GAAG,8DAA8DV,EAAG,IAAI,CAACJ,EAAIc,GAAG,2XAA2XV,EAAG,IAAI,CAACJ,EAAIc,GAAG,UAAUd,EAAIc,GAAG,yEAAyEV,EAAG,IAAI,CAACJ,EAAIc,GAAG,SAASd,EAAIc,GAAG,wyBAAwyBV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,0CAA0C,OAAS,WAAW,CAACP,EAAIc,GAAG,yBAAyBd,EAAIc,GAAG,gXAAgXV,EAAG,IAAI,CAACJ,EAAIc,GAAG,UAAUd,EAAIc,GAAG,YAAYV,EAAG,MAAM,CAACE,YAAY,2CAA2C,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA0C,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,uDAAuDV,EAAG,IAAI,CAACJ,EAAIc,GAAG,+VAA+VV,EAAG,IAAI,CAACJ,EAAIc,GAAG,6lDAA6lDV,EAAG,MAAM,CAACE,YAAY,2CAA2C,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA4C,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,2HAA2HV,EAAG,KAAK,CAACJ,EAAIc,GAAG,6DAA6DV,EAAG,IAAI,CAACJ,EAAIc,GAAG,2sBAA2sBV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,qFAAqF,OAAS,WAAW,CAACP,EAAIc,GAAG,UAAUd,EAAIc,GAAG,8BAA8BV,EAAG,KAAK,CAACJ,EAAIc,GAAG,gCAAgCV,EAAG,IAAI,CAACJ,EAAIc,GAAG,krCAAkrCV,EAAG,IAAI,CAACJ,EAAIc,GAAG,UAAUd,EAAIc,GAAG,YAAYV,EAAG,MAAM,CAACE,YAAY,2CAA2C,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA8C,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,gBAAgBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,wkCCkLhkb,IACElD,KAAM,mBACNoD,QAAS,CACP,WACE,OCvLmW,MCQrW,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIhB,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,yEAAyEV,EAAG,MAAM,CAACE,YAAY,YAAY,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,eAAe,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,gBAAgB,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,gBAAgB,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,gBAAgB,gBAAgB,SAASH,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,2CAA2C,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAuD,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,gBAAgBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,iuBAAiuBV,EAAG,MAAM,CAACE,YAAY,oCAAoC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAoD,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,8DAA8DV,EAAG,IAAI,CAACJ,EAAIc,GAAG,ktBAAktBV,EAAG,MAAM,CAACE,YAAY,oCAAoC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAoD,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,aAAaV,EAAG,IAAI,CAACJ,EAAIc,GAAG,6sBC2D7jG,IACElD,KAAM,QC7DmW,MCQvW,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAIK,MAAMD,GAAO,OAAOJ,EAAIe,GAAG,IACnG,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACF,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,sCAAsCV,EAAG,MAAM,CAACE,YAAY,YAAY,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,gBAAgB,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,iBAAiB,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,iBAAiB,gBAAgB,OAAOH,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,iBAAiB,gBAAgB,SAASH,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,4CAA4C,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA6C,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,iBAAiBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,gZAAgZV,EAAG,MAAM,CAACE,YAAY,qCAAqC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAgD,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,4EAA4EV,EAAG,IAAI,CAACJ,EAAIc,GAAG,oQAA6QV,EAAG,MAAM,CAACE,YAAY,qCAAqC,CAACF,EAAG,MAAM,CAACE,YAAY,2BAA2BC,MAAM,CAAC,IAAM,EAAQ,WAA2DH,EAAG,MAAM,CAACE,YAAY,gCAAgCC,MAAM,CAAC,IAAM,EAAQ,WAA6DH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,6FAA6FV,EAAG,IAAI,CAACJ,EAAIc,GAAG,mqBCwD19E,IACElD,KAAM,SC1DoW,MCQxW,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIoC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACN,EAAIe,GAAG,GAAGX,EAAG,MAAM,CAACE,YAAY,YAAY,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,aAAa,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,cAAc,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,cAAclD,EAAIe,GAAG,UAC/1B,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,kEAAkE,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,yCAAyC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAqD,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,sCAAsCV,EAAG,IAAI,CAACJ,EAAIc,GAAG,qNAAqNV,EAAG,MAAMJ,EAAIc,GAAG,uFAAuFV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,6BAA6B,OAAS,WAAW,CAACP,EAAIc,GAAG,iBAAiBV,EAAG,MAAMJ,EAAIc,GAAG,yEAAyEV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mCAAmC,OAAS,WAAW,CAACP,EAAIc,GAAG,WAAWV,EAAG,MAAMJ,EAAIc,GAAG,sDAAsDV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,uCAAuC,OAAS,WAAW,CAACP,EAAIc,GAAG,mCAAmCV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACA,EAAG,SAAS,CAACJ,EAAIc,GAAG,sCAAsCV,EAAG,IAAI,CAACJ,EAAIc,GAAG,qeAAqeV,EAAG,MAAMA,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,sBAAsB,CAACP,EAAIc,GAAG,oPAAoPV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAuD,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,6CAA6CV,EAAG,IAAI,CAACJ,EAAIc,GAAG,2MAA2MV,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,oHAAoH,OAAS,WAAW,CAACP,EAAIc,GAAG,oBAAoBd,EAAIc,GAAG,swCAAswCV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAmE,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,qEAAqEV,EAAG,IAAI,CAACJ,EAAIc,GAAG,ugEAAugEV,EAAG,MAAM,CAACE,YAAY,kCAAkC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAAqD,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,aAAaV,EAAG,IAAI,CAACJ,EAAIc,GAAG,u3BC4H/7N,IACElD,KAAM,oBACNoD,QAAS,CACP,WACE,OCjIoW,MCQtW,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIhB,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,iDAAiD,CAACN,EAAIe,GAAG,GAAGX,EAAG,MAAM,CAACE,YAAY,YAAY,CAACF,EAAG,MAAM,CAACE,YAAY,iBAAiBC,MAAM,CAAC,GAAK,oBAAoB,YAAY,WAAW,gBAAgB,UAAU,CAACH,EAAG,KAAK,CAACE,YAAY,uBAAuB,CAACF,EAAG,KAAK,CAACE,YAAY,SAASC,MAAM,CAAC,cAAc,qBAAqB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,qBAAqB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,YAAY9C,EAAG,KAAK,CAACG,MAAM,CAAC,cAAc,qBAAqB,gBAAgB,KAAKK,GAAG,CAAC,MAAQZ,EAAIkD,cAAclD,EAAIe,GAAG,UACjsB,GAAkB,CAAC,WAAa,IAAIf,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,SAASC,MAAM,CAAC,GAAK,UAAU,CAACH,EAAG,KAAK,CAACJ,EAAIc,GAAG,kBAAkB,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,kBAAkB,CAACF,EAAG,MAAM,CAACE,YAAY,gDAAgD,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA6C,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,wBAAwBV,EAAG,IAAI,CAACJ,EAAIc,GAAG,sTAAsTV,EAAG,MAAM,CAACE,YAAY,yCAAyC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA6C,IAAM,kBAAkBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,2BAA2BV,EAAG,IAAI,CAACJ,EAAIc,GAAG,saAAsaV,EAAG,MAAM,CAACE,YAAY,yCAAyC,CAACF,EAAG,MAAM,CAACE,YAAY,oBAAoBC,MAAM,CAAC,IAAM,EAAQ,QAA+C,IAAM,iBAAiBH,EAAG,MAAM,CAACE,YAAY,iBAAiB,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,4BAA4BV,EAAG,IAAI,CAACJ,EAAIc,GAAG,wXCwDj5D,IACElD,KAAM,YACNoD,QAAS,CACP,WACE,OC7D4V,MCQ9V,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QCnBX,GAAS,WAAa,IAAIhB,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,mCAAmC,CAACF,EAAG,KAAK,CAACJ,EAAIc,GAAG,iFAAiFV,EAAG,cAAc,CAACE,YAAY,cAAcC,MAAM,CAAC,GAAK,MAAM,CAACP,EAAIc,GAAG,kCAAkC,IAC/V,GAAkB,GCOtB,IACElD,KAAM,qBCTmV,MCQvV,I,UAAY,eACd,GACA,GACA,IACA,EACA,KACA,WACA,OAIa,M,QChBfuF,aAAIC,IAAIC,QAmBR,MAAMC,GAAS,CACX,CACI7C,KAAM,IACNQ,UAAWsC,GAEf,CACI9C,KAAM,SACNQ,UAAWuC,GAEf,CACI/C,KAAM,YACNQ,UAAWwC,GAEf,CACIhD,KAAM,sBACNQ,UAAWyC,IAEf,CACIjD,KAAM,4CACNQ,UAAW0C,IAEf,CACIlD,KAAM,kEACNQ,UAAW2C,IAEf,CACInD,KAAM,iEACNQ,UAAW4C,IAEf,CACIpD,KAAM,qCACNQ,UAAW6C,IAEf,CACIrD,KAAM,kCACNQ,UAAW8C,IAEf,CACItD,KAAM,iCACNQ,UAAW+C,IAEf,CACIvD,KAAM,gCACNQ,UAAWgD,IAEf,CACIxD,KAAM,WACNQ,UAAWiD,IAEf,CACIzD,KAAM,UACNQ,UAAWkD,IAEf,CACI1D,KAAM,OACNQ,UAAWmD,IAEf,CACI3D,KAAM,IACN4D,SAAU,SAKZC,GAAY,IAAIjB,OAAU,CAC5B9E,KAAM,OACNgG,OAAQjB,KAGGgB,U,oBCnFfnB,aAAIqB,OAAOC,eAAgB,EAC3BtB,aAAIC,IAAIsB,QACRvB,aAAIC,IAAIuB,QAER,IAAIxB,aAAI,CACNG,UACAvD,OAAQ6E,GAAKA,EAAEC,KACdC,OAAO,S,qBCfVvH,EAAOD,QAAU,IAA0B,wB,yECA3CC,EAAOD,QAAU,IAA0B,mC,uBCA3CC,EAAOD,QAAU,IAA0B,kC,gDCA3CC,EAAOD,QAAU,IAA0B,6C,uBCA3CC,EAAOD,QAAU,IAA0B,0B,yECA3CC,EAAOD,QAAU,IAA0B,mD,uBCA3CC,EAAOD,QAAU,IAA0B,wB,qBCA3CC,EAAOD,QAAU,IAA0B,wC,uBCA3CC,EAAOD,QAAU,IAA0B,0C,uECA3CC,EAAOD,QAAU,IAA0B,4C,uBCA3CC,EAAOD,QAAU,IAA0B,mC,uBCA3CC,EAAOD,QAAU,IAA0B,oC,qBCA3CC,EAAOD,QAAU,IAA0B,mC,qBCA3CC,EAAOD,QAAU,IAA0B,0B,uBCA3CC,EAAOD,QAAU,IAA0B,6B,uBCA3CC,EAAOD,QAAU,IAA0B,6B,qBCA3CC,EAAOD,QAAU,IAA0B,qC,qBCA3CC,EAAOD,QAAU,IAA0B,2B,qBCA3CC,EAAOD,QAAU,IAA0B,4B,qBCA3CC,EAAOD,QAAU,IAA0B,4C,4CCA3CC,EAAOD,QAAU,IAA0B,8C,qBCA3CC,EAAOD,QAAU,IAA0B,wC,4CCA3CC,EAAOD,QAAU,IAA0B,6B,kCCA3C,yBAA8hB,EAAG,G,qBCAjiBC,EAAOD,QAAU,IAA0B,6B,qBCA3CC,EAAOD,QAAU,IAA0B,6B,qBCA3CC,EAAOD,QAAU,IAA0B,gC,qBCA3CC,EAAOD,QAAU,IAA0B,yD,qBCA3CC,EAAOD,QAAU,IAA0B,qC,kCCA3C,yBAAoe,EAAG,G,kCCAve,yBAA0f,EAAG,G,yDCA7f,yBAAqe,EAAG,G,qBCAxeC,EAAOD,QAAU,IAA0B,0C,qBCA3CC,EAAOD,QAAU,IAA0B,2C,qBCA3CC,EAAOD,QAAU,IAA0B,mC,qBCA3CC,EAAOD,QAAU,IAA0B,wC,kCCA3C,yBAAigB,EAAG,G,qBCApgBC,EAAOD,QAAU,IAA0B,6B,qBCA3CC,EAAOD,QAAU,IAA0B,gD,qBCA3CC,EAAOD,QAAU,IAA0B,6C,yDCA3C,yBAA8c,EAAG","file":"js/app.4f162a19.js","sourcesContent":[" \t// install a JSONP callback for chunk loading\n \tfunction webpackJsonpCallback(data) {\n \t\tvar chunkIds = data[0];\n \t\tvar moreModules = data[1];\n \t\tvar executeModules = data[2];\n\n \t\t// add \"moreModules\" to the modules object,\n \t\t// then flag all \"chunkIds\" as loaded and fire callback\n \t\tvar moduleId, chunkId, i = 0, resolves = [];\n \t\tfor(;i < chunkIds.length; i++) {\n \t\t\tchunkId = chunkIds[i];\n \t\t\tif(Object.prototype.hasOwnProperty.call(installedChunks, chunkId) && installedChunks[chunkId]) {\n \t\t\t\tresolves.push(installedChunks[chunkId][0]);\n \t\t\t}\n \t\t\tinstalledChunks[chunkId] = 0;\n \t\t}\n \t\tfor(moduleId in moreModules) {\n \t\t\tif(Object.prototype.hasOwnProperty.call(moreModules, moduleId)) {\n \t\t\t\tmodules[moduleId] = moreModules[moduleId];\n \t\t\t}\n \t\t}\n \t\tif(parentJsonpFunction) parentJsonpFunction(data);\n\n \t\twhile(resolves.length) {\n \t\t\tresolves.shift()();\n \t\t}\n\n \t\t// add entry modules from loaded chunk to deferred list\n \t\tdeferredModules.push.apply(deferredModules, executeModules || []);\n\n \t\t// run deferred modules when all chunks ready\n \t\treturn checkDeferredModules();\n \t};\n \tfunction checkDeferredModules() {\n \t\tvar result;\n \t\tfor(var i = 0; i < deferredModules.length; i++) {\n \t\t\tvar deferredModule = deferredModules[i];\n \t\t\tvar fulfilled = true;\n \t\t\tfor(var j = 1; j < deferredModule.length; j++) {\n \t\t\t\tvar depId = deferredModule[j];\n \t\t\t\tif(installedChunks[depId] !== 0) fulfilled = false;\n \t\t\t}\n \t\t\tif(fulfilled) {\n \t\t\t\tdeferredModules.splice(i--, 1);\n \t\t\t\tresult = __webpack_require__(__webpack_require__.s = deferredModule[0]);\n \t\t\t}\n \t\t}\n\n \t\treturn result;\n \t}\n\n \t// The module cache\n \tvar installedModules = {};\n\n \t// object to store loaded and loading chunks\n \t// undefined = chunk not loaded, null = chunk preloaded/prefetched\n \t// Promise = chunk loading, 0 = chunk loaded\n \tvar installedChunks = {\n \t\t\"app\": 0\n \t};\n\n \tvar deferredModules = [];\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"/\";\n\n \tvar jsonpArray = window[\"webpackJsonp\"] = window[\"webpackJsonp\"] || [];\n \tvar oldJsonpFunction = jsonpArray.push.bind(jsonpArray);\n \tjsonpArray.push = webpackJsonpCallback;\n \tjsonpArray = jsonpArray.slice();\n \tfor(var i = 0; i < jsonpArray.length; i++) webpackJsonpCallback(jsonpArray[i]);\n \tvar parentJsonpFunction = oldJsonpFunction;\n\n\n \t// add entry module to deferred list\n \tdeferredModules.push([0,\"chunk-vendors\"]);\n \t// run deferred modules when ready\n \treturn checkDeferredModules();\n","import mod from \"-!../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=style&index=0&lang=css&\"; export default mod; export * from \"-!../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=style&index=0&lang=css&\"","module.exports = __webpack_public_path__ + \"26b941884f7f4d6a0809608739be75ab.pdf\";","module.exports = __webpack_public_path__ + \"img/text-analysis-module.55d5baf1.png\";","import mod from \"-!../../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ImageAnalysisCarousel.vue?vue&type=style&index=0&id=d010bdf8&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ImageAnalysisCarousel.vue?vue&type=style&index=0&id=d010bdf8&scoped=true&lang=css&\"","module.exports = __webpack_public_path__ + \"img/fp-train.88f043ab.png\";","var map = {\n\t\"./17_835_Poster.pdf\": \"4131\",\n\t\"./6_864_Project.pdf\": \"1a9a\",\n\t\"./Dylan_Lewis_Resume.pdf\": \"8050\",\n\t\"./FrequencyPlot.png\": \"339e\",\n\t\"./IDS131_Final_Report.pdf\": \"06be\",\n\t\"./IDS131_Poster.pdf\": \"b720\",\n\t\"./NER.png\": \"7d1a\",\n\t\"./RelativeWordFreqDiffFlorida.png\": \"f061\",\n\t\"./RelativeWordFrequencyDiff.png\": \"3ea6\",\n\t\"./boomerang-home.jpg\": \"5e93\",\n\t\"./create-account.png\": \"e1a7\",\n\t\"./ds-fc.png\": \"4bd4\",\n\t\"./ds-train.png\": \"964e\",\n\t\"./dylan-n-leo.jpg\": \"c9e4\",\n\t\"./fare-surge-graph-pred.png\": \"84e6\",\n\t\"./feelings.jpg\": \"c207\",\n\t\"./final-project-overview.png\": \"d8cb\",\n\t\"./fp-fc.png\": \"1d5c\",\n\t\"./fp-train.png\": \"166a\",\n\t\"./hc-fc.png\": \"9409\",\n\t\"./hc-train.png\": \"be19\",\n\t\"./iaa.png\": \"5984\",\n\t\"./image-analysis-module-modified.png\": \"7b9c\",\n\t\"./image-analysis-module.png\": \"d730\",\n\t\"./in-fc.png\": \"6a64\",\n\t\"./in-train.png\": \"bb54\",\n\t\"./int-dev-gray-lit.pdf\": \"4cdb\",\n\t\"./int-dev-results.png\": \"269c\",\n\t\"./join-communities.png\": \"a21f\",\n\t\"./leo_n_me.jpg\": \"ee29\",\n\t\"./linkedin-profpic.jpg\": \"cbeb\",\n\t\"./masters-thesis-overview.png\": \"ab31\",\n\t\"./negative-positive.jpg\": \"3bc0\",\n\t\"./ner-res-tools.png\": \"2981\",\n\t\"./ner-results.png\": \"332f\",\n\t\"./network_cosine_similarity.png\": \"afd1\",\n\t\"./network_tfidf_wordclouds.png\": \"64e1\",\n\t\"./networks_and_years_cosine_similarity.png\": \"cad8\",\n\t\"./pika-gif.gif\": \"9faf\",\n\t\"./portrait.jpg\": \"4906\",\n\t\"./project-collage.png\": \"8b08\",\n\t\"./reptile.png\": \"a2c3\",\n\t\"./resume.png\": \"a297\",\n\t\"./taxi-fare-and-surge-pred.png\": \"f124\",\n\t\"./taxi-proj-thumbnail.png\": \"e75b\",\n\t\"./test-set-eval.png\": \"621b\",\n\t\"./text-analysis-module.png\": \"0af6\",\n\t\"./tfidf-networks.png\": \"9271\",\n\t\"./trump-campaign.png\": \"89e4\",\n\t\"./years_cosine_similarity.png\": \"878d\"\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = \"1913\";","module.exports = __webpack_public_path__ + \"6b8bd84b37ff0d5c4d59da59cd2fd588.pdf\";","module.exports = __webpack_public_path__ + \"img/fp-fc.ef341c25.png\";","module.exports = __webpack_public_path__ + \"img/int-dev-results.d88be6ab.png\";","module.exports = __webpack_public_path__ + \"img/ner-res-tools.ffa2482a.png\";","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ProjectCard.vue?vue&type=style&index=0&id=a4e70f92&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ProjectCard.vue?vue&type=style&index=0&id=a4e70f92&scoped=true&lang=css&\"","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NotFoundComponent.vue?vue&type=style&index=0&id=4ffa6c61&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NotFoundComponent.vue?vue&type=style&index=0&id=4ffa6c61&scoped=true&lang=css&\"","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Home.vue?vue&type=style&index=0&id=6eb776f2&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Home.vue?vue&type=style&index=0&id=6eb776f2&scoped=true&lang=css&\"","import mod from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./GNNsTaxiPrediction.vue?vue&type=style&index=0&id=2ba5834e&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./GNNsTaxiPrediction.vue?vue&type=style&index=0&id=2ba5834e&scoped=true&lang=css&\"","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Header.vue?vue&type=style&index=0&id=ea434f30&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Header.vue?vue&type=style&index=0&id=ea434f30&scoped=true&lang=css&\"","module.exports = __webpack_public_path__ + \"img/ner-results.0168e441.png\";","module.exports = __webpack_public_path__ + \"img/FrequencyPlot.970f0c80.png\";","module.exports = __webpack_public_path__ + \"img/negative-positive.6d580dd8.jpg\";","module.exports = __webpack_public_path__ + \"img/RelativeWordFrequencyDiff.ea5b86c8.png\";","module.exports = __webpack_public_path__ + \"37b2baebe5028084933fc1d6ed8b2604.pdf\";","import mod from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TrumpSpeechAnalysis.vue?vue&type=style&index=0&id=3213d2e9&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TrumpSpeechAnalysis.vue?vue&type=style&index=0&id=3213d2e9&scoped=true&lang=css&\"","import mod from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ClimateChangeNews.vue?vue&type=style&index=0&id=506aa114&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ClimateChangeNews.vue?vue&type=style&index=0&id=506aa114&scoped=true&lang=css&\"","module.exports = __webpack_public_path__ + \"img/portrait.b2c89646.jpg\";","module.exports = __webpack_public_path__ + \"img/ds-fc.33490c85.png\";","module.exports = __webpack_public_path__ + \"6e061964729851cc0f11c268e292463e.pdf\";","import mod from \"-!../../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TextAnalysisCarousel.vue?vue&type=style&index=0&id=4dc6ec22&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TextAnalysisCarousel.vue?vue&type=style&index=0&id=4dc6ec22&scoped=true&lang=css&\"","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Resume.vue?vue&type=style&index=0&id=28d22fa6&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Resume.vue?vue&type=style&index=0&id=28d22fa6&scoped=true&lang=css&\"","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"container-fluid p-3 min-vh-100\",attrs:{\"id\":\"app\"}},[_c('Header'),(this.$route.path !== \"/\" && this.$route.path !== \"/404\")?_c('NavBar'):_vm._e(),_c('router-view')],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row justify-content-end\"},[_c('div',{staticClass:\"col-12 col-md-4 col-lg-4\",attrs:{\"id\":\"website-title\"}},[_c('h1',{attrs:{\"id\":\"name animate__fadeInDown\"},on:{\"click\":_vm.goHome}},[_vm._v(\" Dylan Lewis \")])]),_vm._m(0)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"col-md-4 my-auto\",attrs:{\"id\":\"logos-col\"}},[_c('div',{staticClass:\"d-flex flex-row justify-content-center justify-content-md-end\"},[_c('a',{attrs:{\"href\":\"mailto: dylanrl97@gmail.com\"}},[_c('i',{staticClass:\"fa fa-envelope-o fa-3x\"}),_c('i',{staticClass:\"fa fa-envelope-o fa-2x\"})]),_c('a',{attrs:{\"href\":\"https://www.linkedin.com/in/dyllew/\",\"target\":\"_blank\"}},[_c('i',{staticClass:\"fa fa-linkedin-square fa-3x\"}),_c('i',{staticClass:\"fa fa-linkedin-square fa-2x\"})]),_c('a',{attrs:{\"href\":\"https://github.com/dyllew/\",\"target\":\"_blank\"}},[_c('i',{staticClass:\"fa fa-github fa-3x\"}),_c('i',{staticClass:\"fa fa-github fa-2x\"})])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row justify-content-end\">\n        <div id=\"website-title\" class=\"col-12 col-md-4 col-lg-4\">\n            <h1 v-on:click=\"goHome\" id=\"name animate__fadeInDown\"> Dylan Lewis </h1>\n        </div>\n        <div id=\"logos-col\" class=\"col-md-4 my-auto\">\n            <div class=\"d-flex flex-row justify-content-center justify-content-md-end\">\n                <a href=\"mailto: dylanrl97@gmail.com\">\n                    <i class=\"fa fa-envelope-o fa-3x\"></i>\n                    <i class=\"fa fa-envelope-o fa-2x\"></i>\n                </a> \n                <a href=\"https://www.linkedin.com/in/dyllew/\" target=\"_blank\">\n                    <i class=\"fa fa-linkedin-square fa-3x\"></i>\n                    <i class=\"fa fa-linkedin-square fa-2x\"></i>\n                </a>\n                <a href=\"https://github.com/dyllew/\" target=\"_blank\">\n                    <i class=\"fa fa-github fa-3x\"></i>\n                    <i class=\"fa fa-github fa-2x\"></i>\n                </a>\n            </div>\n        </div>\n    </div>    \n</template>\n\n<script>\nexport default {\n  name: 'Header',\n  methods: {\n      goHome() {\n          this.$router.push('/');\n      }\n  }\n}\n</script>\n\n<style scoped>\nh1 {\n    font-size: 50px;\n}\n\nh1:hover {\n    cursor: pointer;\n}\n\na {\n    color: #61DAFB;\n    margin-left: 15px;\n    margin-right: 15px;\n}\n\na:hover {\n    color: white;\n}\n\n@media (max-width: 761px) {\n    .fa-3x {\n        display: none;\n    }\n}\n@media (min-width: 761px) {\n    .fa-2x {\n        display: none;\n    }\n}\n\n@media (min-width: 768px) {\n    #logos-col {\n        justify-content: flex-end; \n    }\n}\n\n</style>","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Header.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Header.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Header.vue?vue&type=template&id=ea434f30&scoped=true&\"\nimport script from \"./Header.vue?vue&type=script&lang=js&\"\nexport * from \"./Header.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Header.vue?vue&type=style&index=0&id=ea434f30&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"ea434f30\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row pt-2 justify-content-center\"},[_c('div',{staticClass:\"col-md-12\",attrs:{\"id\":\"nav-bar\"}},[_c('router-link',{staticClass:\"router-link\",attrs:{\"to\":\"/about\"}},[_vm._v(\"About Me\")]),_vm._v(\" | \"),_c('router-link',{staticClass:\"router-link\",attrs:{\"to\":\"/projects\"}},[_vm._v(\"Projects\")]),_vm._v(\" | \"),_c('router-link',{staticClass:\"router-link\",attrs:{\"to\":\"/artwork\"}},[_vm._v(\"Artwork\")]),_vm._v(\" | \"),_c('router-link',{staticClass:\"router-link\",attrs:{\"to\":\"/resume\"}},[_vm._v(\"Resume\")])],1)])}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row pt-2 justify-content-center\">\n      <div id=\"nav-bar\" class=\"col-md-12\">\n          <router-link class=\"router-link\" to=\"/about\">About Me</router-link> |\n          <router-link class=\"router-link\" to=\"/projects\">Projects</router-link> |\n          <router-link class=\"router-link\" to=\"/artwork\">Artwork</router-link> |\n          <router-link class=\"router-link\" to=\"/resume\">Resume</router-link>\n      </div>\n    </div>  \n</template>\n\n<script>\nexport default {\n  name: 'NavBar'\n}\n</script>\n\n<style scoped>\n\n#nav-bar {\n  font-size: 30px;\n}\n\n@media (max-width: 500px) {\n    #nav-bar {\n      font-size: 16px;\n    }\n}\n\n.router-link {\n  color: #61DAFB;\n}\n\n.router-link:hover {\n  color: whitesmoke;\n}\n\n.router-link-active {\n  color: white;\n  text-decoration: underline;\n}\n\n\n</style>","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NavBar.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NavBar.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./NavBar.vue?vue&type=template&id=d904e86c&scoped=true&\"\nimport script from \"./NavBar.vue?vue&type=script&lang=js&\"\nexport * from \"./NavBar.vue?vue&type=script&lang=js&\"\nimport style0 from \"./NavBar.vue?vue&type=style&index=0&id=d904e86c&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"d904e86c\",\n  null\n  \n)\n\nexport default component.exports","<template>\n  <div id=\"app\" class=\"container-fluid p-3 min-vh-100\">\n    <Header />\n    <NavBar v-if=\"this.$route.path !== `/` && this.$route.path !== `/404`\" />\n    <router-view></router-view>\n  </div>\n</template>\n\n<script>\nimport Header from './components/Header';\nimport NavBar from './components/NavBar';\n\nexport default {\n  name: 'App',\n  components: {\n    Header,\n    NavBar\n  }\n}\n</script>\n\n<style>\n\nhtml {\n  height: 100vh;\n  scroll-behavior: smooth;\n}\n\nbody {\n  min-height: 100vh;\n  margin: 0;\n  padding: 0;\n}\n\n#app {\n  font-family: Courier, Helvetica, Arial, sans-serif;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  text-align: center;\n  color: #61DAFB;\n  background-color: #080707;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n.tooltip {\n  position: relative;\n  display: inline-block;\n  border-bottom: 1px dotted black;\n}\n\n.tooltip .tooltiptext {\n  visibility: hidden;\n  width: 120px;\n  background-color: black;\n  color: #fff;\n  text-align: center;\n  border-radius: 6px;\n  padding: 5px 0;\n  \n  /* Position the tooltip */\n  position: absolute;\n  z-index: 1;\n  bottom: 100%;\n  left: 50%;\n  margin-left: -60px;\n}\n\n.tooltip:hover .tooltiptext {\n  visibility: visible;\n}\n\n@media (max-width: 800px) {\n    .cc-carousel-item img {\n        max-height: 80vw;\n    }\n}\n\n\n</style>\n","import mod from \"-!../node_modules/cache-loader/dist/cjs.js??ref--12-0!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../node_modules/cache-loader/dist/cjs.js??ref--12-0!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./App.vue?vue&type=template&id=1ff4dbda&\"\nimport script from \"./App.vue?vue&type=script&lang=js&\"\nexport * from \"./App.vue?vue&type=script&lang=js&\"\nimport style0 from \"./App.vue?vue&type=style&index=0&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row pt-4 align-items-md-start justify-content-around\"},[_c('div',{staticClass:\"col-6 pt-4 col-md-3 pt-md-5\",attrs:{\"id\":\"about\"}},[_c('div',{staticClass:\"img-container\"},[_c('h4',[_vm._v(\"About Me\")]),_c('div',{staticClass:\"img-holder\",on:{\"click\":_vm.goToAbout}},[_c('img',{staticClass:\"rounded img-fluid upper-img\",attrs:{\"src\":require(\"../../public/assets/dylan-n-leo.jpg\")}})])])]),_c('div',{staticClass:\"col-6 pt-4 col-md-3 pt-md-5\",attrs:{\"id\":\"resume\"}},[_c('div',{staticClass:\"img-container\"},[_c('h4',[_vm._v(\"Resume\")]),_c('div',{staticClass:\"img-holder\",on:{\"click\":_vm.goToResume}},[_c('img',{staticClass:\"rounded img-fluid upper-img\",attrs:{\"src\":require(\"../../public/assets/resume.png\")}})])])]),_c('div',{staticClass:\"col-md-4\",attrs:{\"id\":\"artwork-and-projs\"}},[_c('div',{staticClass:\"img-container\"},[_c('h4',[_vm._v(\"Projects\")]),_c('div',{staticClass:\"img-holder\",on:{\"click\":_vm.goToProjects}},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../public/assets/project-collage.png\")}})])]),_c('div',{staticClass:\"img-container mt-4\"},[_c('h4',[_vm._v(\"Artwork\")]),_c('div',{staticClass:\"img-holder\",on:{\"click\":_vm.goToArtwork}},[_c('img',{staticClass:\"rounded img-fluid lower-img\",attrs:{\"src\":require(\"../../public/assets/portrait.jpg\")}})])])]),_c('div',{staticClass:\"col-5 pt-5 pt-md-0 col-md-2\",attrs:{\"id\":\"artwork\"}},[_c('div',{staticClass:\"img-container\"},[_c('h4',[_vm._v(\"Artwork\")]),_c('div',{staticClass:\"img-holder\",on:{\"click\":_vm.goToArtwork}},[_c('img',{staticClass:\"rounded img-fluid lower-img\",attrs:{\"src\":require(\"../../public/assets/portrait.jpg\")}})])])]),_c('div',{staticClass:\"col-6 pt-5 pt-md-0 col-md-4\",attrs:{\"id\":\"projects\"}},[_c('div',{staticClass:\"img-container\"},[_c('h4',[_vm._v(\"Projects\")]),_c('div',{staticClass:\"img-holder\",on:{\"click\":_vm.goToProjects}},[_c('img',{staticClass:\"rounded img-fluid lower-img\",attrs:{\"src\":require(\"../../public/assets/project-collage.png\")}})])])])])}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"row pt-4 align-items-md-start justify-content-around\">\n    <div id=\"about\" class=\"col-6 pt-4 col-md-3 pt-md-5\">\n      <div class=\"img-container\">\n        <h4>About Me</h4>\n        <div v-on:click=\"goToAbout\" class=\"img-holder\">\n          <img\n            class=\"rounded img-fluid upper-img\"\n            src=\"../../public/assets/dylan-n-leo.jpg\"\n          />\n        </div>\n      </div>\n    </div>\n\n    <div id=\"resume\" class=\"col-6 pt-4 col-md-3 pt-md-5\">\n      <div class=\"img-container\">\n        <h4>Resume</h4>\n        <div v-on:click=\"goToResume\" class=\"img-holder\">\n          <img\n            class=\"rounded img-fluid upper-img\"\n            src=\"../../public/assets/resume.png\"\n          />\n        </div>\n      </div>\n    </div>\n    <div id=\"artwork-and-projs\" class=\"col-md-4\">\n        <div class=\"img-container\">\n          <h4>Projects</h4>\n          <div v-on:click=\"goToProjects\" class=\"img-holder\">\n            <img\n              class=\"rounded img-fluid\"\n              src=\"../../public/assets/project-collage.png\"\n            />\n          </div>\n        </div>\n        <div class=\"img-container mt-4\">\n          <h4>Artwork</h4>\n          <div v-on:click=\"goToArtwork\" class=\"img-holder\">\n            <img\n              class=\"rounded img-fluid lower-img\"\n              src=\"../../public/assets/portrait.jpg\"\n            />\n          </div>\n        </div>\n    </div>\n    <div id=\"artwork\" class=\"col-5 pt-5 pt-md-0 col-md-2\">\n      <div class=\"img-container\">\n        <h4>Artwork</h4>\n        <div v-on:click=\"goToArtwork\" class=\"img-holder\">\n          <img\n            class=\"rounded img-fluid lower-img\"\n            src=\"../../public/assets/portrait.jpg\"\n          />\n        </div>\n      </div>\n    </div>\n    <div id=\"projects\" class=\"col-6 pt-5 pt-md-0 col-md-4\">\n      <div class=\"img-container\">\n        <h4>Projects</h4>\n        <div v-on:click=\"goToProjects\" class=\"img-holder\">\n          <img\n            class=\"rounded img-fluid lower-img\"\n            src=\"../../public/assets/project-collage.png\"\n          />\n        </div>\n      </div>\n    </div>\n  </div>\n</template>\n\n<script>\nexport default {\n  name: \"Home\",\n  data() {\n    return {\n      windowWidth: window.innerWidth,\n    };\n  },\n  methods: {\n    goToAbout() {\n      this.$router.push(\"/about\");\n    },\n    goToProjects() {\n      this.$router.push(\"/projects\");\n    },\n    goToArtwork() {\n      this.$router.push(\"/artwork\");\n    },\n    goToResume() {\n      this.$router.push(\"/resume\");\n    },\n  },\n};\n</script>\n\n<style scoped>\n\nh4 {\n  font-size: 4vw;\n}\n\n#artwork-and-projs {\n    display: none;\n}\n\n.img-container:hover {\n  border: 1px solid #61dafb;\n  border-radius: 2px;\n  cursor: pointer;\n  color: white;\n}\n\n@media (max-width: 750px) {\n  .upper-img {\n    height: 40vw;\n    width: auto;\n  }\n\n  .lower-img {\n    height: 30vw;\n    width: auto;\n  }\n}\n\n@media (min-width: 768px) {\n  h4 {\n  font-size: 2vw;\n  }\n\n  #about {\n    order: 1;\n  }\n\n  #resume {\n    order: 3;\n  }\n\n  #artwork-and-projs {\n      display: inline;\n      order: 2;\n  }\n\n  #projects {\n    display: none;\n  }\n\n  #artwork {\n    display: none;\n  }\n\n    @media (min-width: 1150px) { \n        .upper-img {\n          height: 30vw;\n          width: auto;\n      }\n        .lower-img {\n            height: 15vw;\n        }\n    }\n}\n</style>\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Home.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Home.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Home.vue?vue&type=template&id=6eb776f2&scoped=true&\"\nimport script from \"./Home.vue?vue&type=script&lang=js&\"\nexport * from \"./Home.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Home.vue?vue&type=style&index=0&id=6eb776f2&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"6eb776f2\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row pt-3 pt-lg-5 justify-content-center align-items-center\",attrs:{\"id\":\"home-container\"}},[_c('div',{staticClass:\"col-6 col-md-5 col-lg-5 col-xl-3 mr-xl-5\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"id\":\"leo-and-dylan-pic\",\"src\":require(\"../../public/assets/leo_n_me.jpg\"),\"alt\":\"Leo and Dylan\"}})]),_c('div',{staticClass:\"col-10 col-md-6 col-lg-5 col-xl-5\",attrs:{\"id\":\"about-description\"}},[_c('p',{attrs:{\"id\":\"intro-paragraph\"}},[_vm._v(\" Hey there! I'm a Masters grad from MIT where I studied Computer Science, specifically Artificial Intelligence. My research focused on machine learning tools for assisting crisis managers during climate crises using crowdsourced climate crisis data. You can learn more about my research\"),_c('a',{attrs:{\"href\":\"#/projects/ml-for-crowdsourced-crisis-data\"}},[_vm._v(\"here!\")]),_vm._v(\"I'm also a proud dad to my son, Leo  \")]),_c('p',[_vm._v(\" I'm interested in Software Engineering, Data Science & Machine Learning, and Web Development! You can contact me through\"),_c('a',{attrs:{\"href\":\"mailto: dylanrl97@gmail.com\"}},[_vm._v(\"email,\")]),_vm._v(\"add me on\"),_c('a',{attrs:{\"href\":\"https://www.linkedin.com/in/dyllew/\",\"target\":\"_blank\"}},[_vm._v(\"LinkedIn,\")]),_vm._v(\"or checkout my\"),_c('a',{attrs:{\"href\":\"https://github.com/dyllew/\",\"target\":\"_blank\"}},[_vm._v(\"GitHub!\")]),_vm._v(\" I'm currently looking for remote Data Science and Software Engineering positions! \")]),_c('p',[_vm._v(\" In my freetime I love to explore nature, play video games (Zelda/DMC/Soulsborne/Skyrim/Kingdom Hearts/Fallout), cook/bake something new, make and experiment with different forms of art, develop new skills, and go on adventures with my pup! \")])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div id=\"home-container\" class=\"row pt-3 pt-lg-5 justify-content-center align-items-center\">\n        <div class=\"col-6 col-md-5 col-lg-5 col-xl-3 mr-xl-5\">\n            <img\n              id=\"leo-and-dylan-pic\"\n              src=\"../../public/assets/leo_n_me.jpg\" \n              class=\"rounded img-fluid\"\n              alt=\"Leo and Dylan\" />\n        </div>\n        <div id=\"about-description\" class=\"col-10 col-md-6 col-lg-5 col-xl-5\">\n            <p id=\"intro-paragraph\">\n              Hey there! I'm a Masters grad from MIT where I studied\n              Computer Science, specifically Artificial Intelligence. My research focused on machine learning tools\n              for assisting crisis managers during climate crises using crowdsourced climate crisis data. You can learn more\n              about my research<a href=\"#/projects/ml-for-crowdsourced-crisis-data\">here!</a>I'm also a proud dad to my son, Leo \n            </p>\n            <p>\n              I'm interested in Software Engineering, Data Science & Machine Learning, and Web Development! \n              You can contact me through<a href=\"mailto: dylanrl97@gmail.com\">email,</a>add me on<a href=\"https://www.linkedin.com/in/dyllew/\" target=\"_blank\">LinkedIn,</a>or checkout my<a href=\"https://github.com/dyllew/\" target=\"_blank\">GitHub!</a>\n              I'm currently looking for remote Data Science and Software Engineering positions!\n            </p>\n            <p>\n              In my freetime I love to explore nature, play video games (Zelda/DMC/Soulsborne/Skyrim/Kingdom Hearts/Fallout), cook/bake something new, make and experiment with different forms of art,\n              develop new skills, and go on adventures with my pup!\n            </p> \n        </div>\n    </div>    \n</template>\n\n<script>\n\nexport default {\n  name: 'About'\n}\n</script>\n\n<style scoped>\na {\n    color: hotpink;\n    margin-left: 1vw;\n    margin-right: 1vw;\n}\n\na:hover {\n    color: white;\n}\n\n#leo-and-dylan-pic  {\n  max-height: 40vw;\n  border: 0.25vw solid #61DAFB;\n}\n\n#about-description {\n  font-size: 1.75vw;\n  text-align: left;\n}\n\n@media (min-width: 0px) and (max-width: 500px) {\n\n    #leo-and-dylan-pic {\n      max-height: 50vw;\n    }\n\n    #about-description p {\n      font-size: 3.5vw;\n    }\n\n    #intro-paragraph {\n      padding-top: 10vw;\n    }\n\n}\n\n@media (min-width: 500px) and (max-width: 900px) {\n\n    #leo-and-dylan-pic {\n      max-height: 50vw;\n    }\n\n    #about-description p {\n      font-size: 1.85vw;\n    }\n\n    #intro-paragraph {\n      padding-top: 5vw;\n    }\n\n}\n\n@media (min-width: 900px) and (max-width: 1200px) {\n\n    #leo-and-dylan-pic {\n      max-height: 40vw;\n    }\n\n    #about-description p {\n      font-size: 1.50vw;\n    }\n}\n\n@media (min-width: 1200px) {\n\n    #about-description p {\n      font-size: 1.35vw;\n    }\n}\n\n</style>\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./About.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./About.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./About.vue?vue&type=template&id=1634933c&scoped=true&\"\nimport script from \"./About.vue?vue&type=script&lang=js&\"\nexport * from \"./About.vue?vue&type=script&lang=js&\"\nimport style0 from \"./About.vue?vue&type=style&index=0&id=1634933c&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"1634933c\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},_vm._l((_vm.projects),function(project){return _c('div',{key:project.link,staticClass:\"col-12 col-md-4 col-lg-4 pt-3\"},[_c('ProjectCard',{attrs:{\"project\":project}})],1)}),0)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"card border-info bg-transparent align-items-center\"},[_c('h5',{staticClass:\"card-header\"},[_vm._v(_vm._s(_vm.project.title))]),_c('img',{staticClass:\"card-img-top\",class:_vm.project.src.sizeClass ? _vm.project.src.sizeClass : '',attrs:{\"id\":_vm.project.id,\"src\":_vm.getImgURL(_vm.project.src.imgFilename),\"alt\":\"Project Image\"}}),_c('div',{staticClass:\"card-body\"},[_c('p',{staticClass:\"card-text\"},[_vm._v(_vm._s(_vm.project.desc))]),(_vm.project.projectWebsite)?_c('div',{attrs:{\"id\":_vm.project.projectWebsite.id}},[_c('a',{staticClass:\"btn btn-light col-5\",attrs:{\"href\":_vm.project.projectWebsite.url,\"target\":\"_blank\"}},[_vm._v(_vm._s(_vm.project.projectWebsite.btnText))]),_c('span'),_c('a',{staticClass:\"btn btn-primary text-light col-5\",on:{\"click\":function($event){return _vm.goToProjectPage(_vm.project.link)}}},[_vm._v(_vm._s(_vm.projectBtnText))])]):_c('div',{attrs:{\"id\":\"button-holder\"}},[_c('a',{staticClass:\"btn btn-primary text-light\",on:{\"click\":function($event){return _vm.goToProjectPage(_vm.project.link)}}},[_vm._v(\"See Project Details\")])])])])}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","export const MAIN_PROJECTS = [\n    {   \n        id: \"ml-for-crowdsourced-crisis-data\",\n        link: \"/projects/ml-for-crowdsourced-crisis-data\", \n        src: {imgFilename: \"masters-thesis-overview.png\"},\n        title: \"Towards Automated Assessment of Crowdsourced Crisis Reporting for Enhanced Crisis Awareness and Response\", \n        desc: \"Masters thesis/Research project on constructing labeled crowdsourced crisis datasets and developing machine learning models to assist crisis managers in gaining situational awareness from crowdsourced crisis data for enhanced crisis response.\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"See Thesis Document\",\n            url: \"https://dspace.mit.edu/handle/1721.1/144911\"\n        }\n    },\n    {   \n        id: \"nlp-for-int-dev-gray-lit\",\n        link: \"/projects/nlp-for-int-dev-gray-lit\", \n        src: {imgFilename: \"int-dev-results.png\"},\n        title: \"Information Extraction and Unsupervised Methods for Streamlining Evidence Synthesis in International Development Gray Literature\", \n        desc: \"NLP project which investigates Named Entity Recognition (NER) and K-means Clustering on a corpus of 244 documents of International Development literature papers for streamlining evidence synthesis process on international development gray literature.\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"Presentation PDF\",\n            url: \"./assets/int-dev-gray-lit.pdf\"\n        }\n    },\n    {   \n        id: \"climate-change-news\",\n        link: \"/projects/climate-change-news\", \n        src: {imgFilename: \"final-project-overview.png\"},\n        title: \"Evolution of the U.S. TV News Narrative on Climate Change\", \n        desc: \"Data Science & NLP project in Python that investigated the evolution of climate change coverage frequency & content between popular U.S. TV News Networks CNN, Fox News, and MSNBC over July 2009-January 2020.\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"Poster PDF\",\n            url: \"./assets/IDS131_Poster.pdf\"\n        }\n    },\n    {   \n        id: \"taxi-pred-img\",\n        link: \"/projects/gnns-taxi-prediction\", \n        src: {imgFilename: \"fare-surge-graph-pred.png\"},\n        title: \"Graph Neural Networks for NYC Taxi Fare & Demand Surge Prediction\", \n        desc: \"Machine Learning project in Python which investigated graph neural networks (GNNs) for the tasks of NYC taxi fare and demand surge prediction.\"\n    },\n    {   \n        id: \"trump-img\",\n        link: \"/projects/trump-speech-analysis\", \n        src: {imgFilename: \"FrequencyPlot.png\", sizeClass: 'w-75'},\n        title: \"Trump Campaign Speech Analysis\", \n        desc: \"Data Science project in R which investigated how Donald Trump's 2016 campaign speeches may have influenced public sentiment on a regional level.\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"Poster PDF\",\n            url: \"./assets/17_835_Poster.pdf\"\n        }\n    },\n    {   \n        id: \"boomerang-img\",\n        link: \"/projects/boomerang\", \n        src: {imgFilename: \"boomerang-home.jpg\"},\n        title: \"Boomerang\",\n        desc: \"Boomerang is a full-stack web application where users can efficiently and reliably borrow items from others within their communities.\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"Go to the Boomerang website\",\n            url: \"https://team-aesthetech-boomerang.herokuapp.com/\"\n        }\n    },\n]\n\nexport const ML_MODULES = [\n    {   \n        id: \"image-module-img\",\n        link: \"/projects/ml-for-crowdsourced-crisis-data/image-analysis-module\", \n        src: {imgFilename: \"image-analysis-module-modified.png\"},\n        title: \"Image Analysis Module\", \n        desc: \"ML Module focused on Constructing human-annotated datasets and assessing the quality of the annotations, developing CNN models to classify the crowdsourced crisis image data for various classification tasks, and conducting image annotation workshops with crisis managers from various contexts.\",\n        projectBtnText: \"See Module Details\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"See Related Code\",\n            url: \"https://github.com/dyllew/towards-automated-assessment-of-crowdsourced-crisis-reporting/tree/main/Image%20Analysis%20Module\"\n        }\n    },\n    {   \n        id: \"text-module-img\",\n        link: \"/projects/ml-for-crowdsourced-crisis-data/text-analysis-module\", \n        src: {imgFilename: \"text-analysis-module.png\"},\n        title: \"Text Analysis Module\", \n        desc: \"ML Module focused on Classification of crowdsourced crisis text (in JA) for Human Risk informed from the identified information needs and priorities of crisis managers and Clustering of crisis text data for uncovering semantic categories in the data.\",\n        projectBtnText: \"See Module Details\",\n        projectWebsite: {\n            id: \"button-holder\",\n            btnText: \"See Related Code\",\n            url: \"https://github.com/dyllew/towards-automated-assessment-of-crowdsourced-crisis-reporting/tree/main/Text%20Analysis%20Module\"\n        }\n    }\n]\n\nexport function scrollUpFunc() {\n    window.scrollTo(0, 0);\n}","<template>\n    <div class=\"card border-info bg-transparent align-items-center\">\n        <h5 class=\"card-header\">{{project.title}}</h5>\n        <img :id=\"project.id\" \n            class=\"card-img-top\" \n            :class=\"project.src.sizeClass ? project.src.sizeClass : ''\" \n            :src=\"getImgURL(project.src.imgFilename)\" \n            alt=\"Project Image\">\n        <div class=\"card-body\">\n            <p class=\"card-text\">{{project.desc}}</p>\n            <div v-if=\"project.projectWebsite\" :id=\"project.projectWebsite.id\">\n                <a :href=\"project.projectWebsite.url\" target=\"_blank\" class=\"btn btn-light col-5\">{{project.projectWebsite.btnText}}</a>\n                <span></span>\n                <a v-on:click=\"goToProjectPage(project.link)\" class=\"btn btn-primary text-light col-5\">{{projectBtnText}}</a>\n            </div>\n            <div id=\"button-holder\" v-else>\n                <a v-on:click=\"goToProjectPage(project.link)\" class=\"btn btn-primary text-light\">See Project Details</a>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nimport { scrollUpFunc } from '../constants';\n\nexport default {\n    name: 'ProjectCard',\n    props: ['project'],\n    methods: {\n        goToProjectPage(projectURL) {\n            this.$router.push(projectURL);\n            scrollUpFunc();\n        },\n        getImgURL(imgFilename) {\n            return require('../../public/assets/' + imgFilename)\n        },\n    },\n    computed: {\n        projectBtnText() {\n           return this.project.projectBtnText ? this.project.projectBtnText : \"See Project Details\"\n        }\n    }\n}\n</script>\n\n<style scoped>\np {\n    text-align: left;\n}\n\nh5 {\n    color: white;\n}\n\n#button-holder {\n    display: flex;\n    justify-content: space-around;\n    align-items: center;\n}\n\n#image-module-img {\n    width: 40vh;\n    height: 40vh;\n}\n\n#text-module-img {\n    height: 40vh;\n}\n\n</style>","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ProjectCard.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ProjectCard.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./ProjectCard.vue?vue&type=template&id=a4e70f92&scoped=true&\"\nimport script from \"./ProjectCard.vue?vue&type=script&lang=js&\"\nexport * from \"./ProjectCard.vue?vue&type=script&lang=js&\"\nimport style0 from \"./ProjectCard.vue?vue&type=style&index=0&id=a4e70f92&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"a4e70f92\",\n  null\n  \n)\n\nexport default component.exports","<template>\n  <div class=\"row align-items-center justify-content-center\">\n    <div class=\"col-12 col-md-4 col-lg-4 pt-3\" v-for=\"project in projects\" :key=\"project.link\">\n        <ProjectCard :project=\"project\"></ProjectCard>\n    </div>\n  </div>    \n</template>\n\n<script>\nimport ProjectCard from './ProjectCard'\nimport { MAIN_PROJECTS } from '../constants';\n\nexport default {\n  name: 'Projects',\n  components: {\n    ProjectCard,\n  },\n  data() {\n      return { \n          projects: MAIN_PROJECTS\n      }\n  },\n}\n</script>\n\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Projects.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Projects.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Projects.vue?vue&type=template&id=085604dc&\"\nimport script from \"./Projects.vue?vue&type=script&lang=js&\"\nexport * from \"./Projects.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"artwork row align-items-center justify-content-center justify-content-xl-around\"},[_c('div',{staticClass:\"col-8 pt-3 pt-md-0 col-md-4\"},[_c('h4',{staticClass:\"header\"},[_vm._v(\"Ethereality\")]),_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../public/assets/portrait.jpg\")}})]),_c('div',{staticClass:\"col-8 pt-4 pt-md-2 col-md-4\"},[_c('h4',{staticClass:\"header\"},[_vm._v(\"Phantom Dragon\")]),_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../public/assets/reptile.png\")}})])])}]\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"artwork row align-items-center justify-content-center justify-content-xl-around\">\n    <div class=\"col-8 pt-3 pt-md-0 col-md-4\">\n      <h4 class=\"header\">Ethereality</h4>\n      <img\n        class=\"rounded img-fluid\"\n        src=\"../../public/assets/portrait.jpg\"\n      />\n    </div>\n    <div class=\"col-8 pt-4 pt-md-2 col-md-4\">\n        <h4 class=\"header\">Phantom Dragon</h4>\n        <img\n          class=\"rounded img-fluid\"\n          src=\"../../public/assets/reptile.png\"\n        />\n    </div>\n    <!-- <div class=\"col-8 pt-4 pt-md-2 col-md-3\">\n        <h4></h4>\n        <img\n          class=\"rounded img-fluid\"\n          src=\"../../public/assets/feelings.jpg\"\n        />\n    </div> -->\n  </div>    \n</template>\n\n<script>\n\nexport default {\n  name: 'Artwork'\n}\n</script>\n\n<style>\n\n.header {\n  color: white;\n}\n\n</style>\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Artwork.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Artwork.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Artwork.vue?vue&type=template&id=5ed9c197&\"\nimport script from \"./Artwork.vue?vue&type=script&lang=js&\"\nexport * from \"./Artwork.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Artwork.vue?vue&type=style&index=0&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"resume row align-items-center justify-content-center\"},[_c('div',{staticClass:\"col-12 mt-4\",attrs:{\"id\":\"sticky-btn\"}},[_c('a',{staticClass:\"btn btn-primary text-light\",attrs:{\"target\":\"_blank\",\"href\":\"./assets/Dylan_Lewis_Resume.pdf\"}},[_vm._v(\"View PDF in Tab\")])]),_c('div',{staticClass:\"col-12 mt-2\"},[_c('embed',{staticClass:\"pdf\",attrs:{\"src\":\"./assets/Dylan_Lewis_Resume.pdf\"}})])])}]\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"resume row align-items-center justify-content-center\">\n    <div id=\"sticky-btn\" class=\"col-12 mt-4\">\n      <a target=\"_blank\" class=\"btn btn-primary text-light\" href=\"./assets/Dylan_Lewis_Resume.pdf\">View PDF in Tab</a>\n    </div>\n    <div class=\"col-12 mt-2\">\n      <embed class=\"pdf\" src=\"./assets/Dylan_Lewis_Resume.pdf\"/>\n    </div>\n  </div>    \n</template>\n\n<script>\n\nexport default {\n  name: 'Resume'\n}\n</script>\n\n<style scoped>\n#sticky-btn {\n  position: -webkit-sticky;\n  position: sticky;\n  top: 0;\n}\n\na {\n  color: #61DAFB;\n  font-size: 30px;\n}\n\na:hover {\n  color: #61DAFB;\n}\n\n@media (max-width: 700px) {\n  .pdf {\n    display: none;\n  }\n}\n\n@media  (min-width: 700px) and (max-width: 1200px) {\n  .pdf {\n    width: 600px;\n    height: 600px;\n  }\n}\n\n@media (min-width: 1200px) {\n  .pdf {\n    width: 800px;\n    height: 800px;\n  }\n}\n\n</style>\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Resume.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Resume.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Resume.vue?vue&type=template&id=28d22fa6&scoped=true&\"\nimport script from \"./Resume.vue?vue&type=script&lang=js&\"\nexport * from \"./Resume.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Resume.vue?vue&type=style&index=0&id=28d22fa6&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"28d22fa6\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_vm._m(0),_c('div',{staticClass:\"col-md-10\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"ccCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"0\"},on:{\"click\":_vm.scrollUp}},[_vm._m(1)]),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"1\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"2\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"3\"},on:{\"click\":_vm.scrollUp}})]),_c('div',{staticClass:\"carousel-inner\"},[_vm._m(2),_vm._m(3),_vm._m(4),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('h5',[_vm._v(\"Machine Learning Methodology\")]),_vm._v(\" With crisis management partners in Fukuchiyama (FC), Japan, we present our framework through two ML modules:\"),_c('br'),_vm._v(\" Image Analysis Module & Text Analysis Module\"),_c('br'),_c('br'),_c('p',[_vm._v(\" We note that our findings from the Image Analysis Module influenced the design of the Text Analysis Module in order to meet our aim of developing machine learning systems for crisis management which iteratively incorporate the feedback received from crisis managers. \")]),_c('div',{staticClass:\"row align-items-center justify-content-center pb-5\"},_vm._l((_vm.modules),function(module){return _c('div',{key:module.link,staticClass:\"col-6 col-md-6 col-lg-6 pt-3\"},[_c('ProjectCard',{attrs:{\"project\":module}})],1)}),0)])])])])])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"col-8\"},[_c('h3',[_vm._v(\"Towards Automated Assessment of Crowdsourced Crisis Reporting for Enhanced Crisis Awareness and Response\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"tooltip\"},[_c('span',{staticClass:\"tooltiptext\"},[_vm._v(\"Thesis Document & Code\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"carousel-item active cc-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"id\":\"overview-pic\",\"src\":require(\"../../../../public/assets/masters-thesis-overview.png\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Thesis Document & Code and Related Open-source Python Packages\")]),_c('p',[_vm._v(\" Master of Engineering in Electrical Engineering and Computer Science thesis I wrote as a research assistant at the Urban Risk Lab (URL) at MIT which investigates the development of machine learning models to assist crisis managers in gaining situational awareness from crowdsourced crisis data for enhanced crisis response. This presentation introduces the motivation behind this work, explains how the investigation unfolded, and reports the main findings and implications from the research. \"),_c('br'),_c('br'),_vm._v(\" The published thesis document can be found \"),_c('a',{attrs:{\"href\":\"https://dspace.mit.edu/handle/1721.1/144911\",\"target\":\"_blank\"}},[_vm._v(\"here.\")]),_c('br'),_c('br'),_vm._v(\" The code for this thesis was written in Python using Jupyter Notebooks. \"),_c('a',{attrs:{\"href\":\"https://github.com/dyllew/towards-automated-assessment-of-crowdsourced-crisis-reporting\",\"target\":\"_blank\"}},[_vm._v(\"Here's the GitHub Repo.\")]),_c('br'),_vm._v(\" Relatedly, with this thesis, we produced two open-source Python packages to better enable readability, reusability, and reproducibility of the computational utilities derived for performing various experiments and analysis on crowdsourced crisis image and text data: \"),_c('ul',[_c('li',[_c('a',{attrs:{\"href\":\"https://pypi.org/project/url-image-module/0.27.0/\",\"target\":\"_blank\"}},[_vm._v(\"URL Image Module\")]),_vm._v(\" - Utilities for training, testing, and predicting with pretrained Convolutional Neural Networks for classifying crowdsourced crisis image data and constructing & analyzing annotated datasets\")]),_c('li',[_c('a',{attrs:{\"href\":\"https://pypi.org/project/url-text-module/0.6.1/\",\"target\":\"_blank\"}},[_vm._v(\"URL Text Module\")]),_vm._v(\" - Utilities for featurizing crisis text data, training and testing with a variety of classification machine learning models, and visualizing clusters of featurized text data\")])]),_c('br'),_vm._v(\" This research was supported by a grant from Google.org and the Tides Foundation. \")])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_c('strong',[_vm._v(\"Abstract\")])]),_c('p',[_vm._v(\" The availability of information during a climate crisis event is critical for crisis managers to assess and respond to crisis impact. During crisis events, affected residents post real-time crisis updates on platforms such as \"),_c('a',{attrs:{\"href\":\"https://riskmap.mit.edu/japan.html\",\"target\":\"_blank\"}},[_vm._v(\"RiskMap\")]),_vm._v(\" and \"),_c('a',{attrs:{\"href\":\"https://twitter.com/?lang=en\",\"target\":\"_blank\"}},[_vm._v(\"Twitter\")]),_vm._v(\". These updates provide localized information, which has the potential to enhance crisis awareness and response. However, with limited resources, crisis managers may endure information overload from the inundation of these updates. Prior work has demonstrated the potential of machine learning (ML) methodologies to mitigate this problem. We have identified limitations in the prior work including the lack of involvement of crisis managers in the development and evaluation of a ML methodology. \")]),_c('p',[_vm._v(\" To address these limitations, we propose a novel framework and ML methodology which investigate the efficacy of various ML methods in enhancing crisis awareness and response beyond model performance metrics. This framework aims to iteratively embed the information needs and priorities of crisis managers during crisis into the design of the ML methodology. We cooperated with crisis managers in Fukuchiyama City (FC), a city in Japan which is susceptible to flood events, and analyzed crowdsourced crisis image and text data from past FC flood events. We devised the Flood Presence image classification task, constructed Train/Dev/Test splits, and annotated images from FC. We report a weighted F1 score of 92.1% on the test split and 82.5% on the FC images. Using the results of our image analysis ML methodology and the insights we gained from crisis managers, we iterated on the design of our text analysis ML methodology. This led to the creation of the Human Risk text classification task which is tailored to a subset of the identified information needs of the crisis managers. To align with the priorities of crisis managers for this task, we determined the model evaluation metric to be the F2 score. We report an F2 score of 92.8% on an FC crisis text test dataset, which is a significant improvement over the baseline score of 43.4%. \")]),_c('h5',[_c('strong',[_vm._v(\"Research Question\")])]),_c('strong',{attrs:{\"id\":\"research-question\"}},[_vm._v(\" In collaborating with crisis managers, how can machine learning methods be utilized and evaluated to effectively reduce the information overload of crowdsourced data on crisis managers during flood events for enhanced crisis awareness and response? \")])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Main Research Aims\")]),_c('p',{attrs:{\"id\":\"research-aims\"}},[_c('ol',[_c('li',[_c('strong',[_vm._v(\"To reduce information overload during a crisis\")]),_vm._v(\" using accurate, efficient, automated image and text classification of crisis reports by machine learning (ML) models during crisis.\")]),_c('li',[_c('strong',[_vm._v(\"To embed tacit knowledge, information needs, and decision-making priorities of crisis managers\")]),_vm._v(\" into the designed ML methodology.\")]),_c('li',[_c('strong',[_vm._v(\"To evaluate methodology in collaboration with crisis managers\")]),_vm._v(\", e.g. crisis managers in Fukuchiyama, Japan.\")]),_c('li',[_c('strong',[_vm._v(\"To incorporate evaluation results and iterate on the ML methodology\")]),_vm._v(\" in order to better reach aim of using AI to assist crisis managers during crisis.\")])]),_vm._v(\" We investigate various ML techniques that can be applied to mitigate information overload for crisis managers during crisis events while also assessing if those techniques can satisfy the information needs and priorities of crisis managers through qualitative and quantitative evaluation. \")]),_c('h5',[_vm._v(\"Novel Framework\")]),_c('p',[_vm._v(\" To achieve the aims above we develop a novel framework in the crisis informatics community consisting of the following components: \"),_c('ul',[_c('li',[_c('strong',[_vm._v(\"Classification Task Creation\")]),_vm._v(\" - We develop new classification tasks using labels provided to us by crisis managers and labels present in open-source datasets\")]),_c('li',[_c('strong',[_vm._v(\"Data Annotation Procedure\")]),_vm._v(\" - We open-souce the annotation guide we develop for greater transparency into the procurement of human-annotated that is used to train and evaluate ML models\")]),_c('li',[_c('strong',[_vm._v(\"Interannotator Agreement/Data Reliability Analysis\")]),_vm._v(\" - After performing an annotation effort on data provided by crisis managers, we analyze the quality of the annotations through interannotator agreement analysis to demonstrate the importance of understanding data quality prior to using it for ML purposes\")]),_c('li',[_c('strong',[_vm._v(\"Model Development and Evaluation; Per-Class Performance Analysis\")]),_vm._v(\" - The metrics we used to evaluate models are derived either from metrics reported in the literature or, more notably, metrics determined from insights provided by crisis managers directly. Additionally, we consider issues of class imbalance and report per-class performance and confusion matrices to provide more granular insight into model performance. Finally, we establish baselines to compare against the models we develop to assess the degree to which the models we develop outperform the baseline\")]),_c('li',[_c('strong',[_vm._v(\"Qualitative Analysis through Workshops with Crisis Managers\")]),_vm._v(\" - We sought to cooperate with crisis managers with the intent of using this framework to iteratively design ML systems, such as the specific classification tasks performed by the models and their associated performance metric, by iteratively incorporating feedback and insights form crisis managers, so that the system better aligns with their information needs and decision-making priorities\")])]),_vm._v(\" This framework situates \"),_c('i',[_vm._v(\"Model Development and Evaluation\")]),_vm._v(\", which is commonplace in prior work, as part of a larger, contextualized analysis. On that note, we expand on the notion of \"),_c('i',[_vm._v(\"Model Development and Evaluation\")]),_vm._v(\" beyond what is typically seen in the prior work. \")])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-8\">  \n            <h3>Towards Automated Assessment of Crowdsourced Crisis Reporting for Enhanced Crisis Awareness and Response</h3>\n        </div>\n        <div class=\"col-md-10\">\n            <div id=\"ccCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"0\" class=\"active\" @click=\"scrollUp\"><div class=\"tooltip\"><span class=\"tooltiptext\">Thesis Document & Code</span></div></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"1\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"2\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"3\" @click=\"scrollUp\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active cc-carousel-item\">\n                        <img class=\"rounded img-fluid\" id=\"overview-pic\" src=\"../../../../public/assets/masters-thesis-overview.png\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Thesis Document & Code and Related Open-source Python Packages</h5>\n                            <p>\n                                Master of Engineering in Electrical Engineering and Computer Science thesis I wrote as a research assistant at the Urban Risk Lab (URL) at MIT which investigates \n                                the development of machine learning models to assist crisis managers in gaining situational awareness from crowdsourced crisis data for enhanced crisis response.\n                                This presentation introduces the motivation behind this work, explains how the investigation unfolded, and reports the main findings and implications from the research.\n                                <br>\n                                <br>\n                                The published thesis document can be found <a href=\"https://dspace.mit.edu/handle/1721.1/144911\" target=\"_blank\">here.</a>\n                                <br>\n                                <br>\n                                The code for this thesis was written in Python using Jupyter Notebooks. <a href=\"https://github.com/dyllew/towards-automated-assessment-of-crowdsourced-crisis-reporting\" target=\"_blank\">Here's the GitHub Repo.</a>\n                                <br>\n                                Relatedly, with this thesis, we produced two open-source Python packages to better enable readability, reusability, and reproducibility of the computational utilities derived \n                                for performing various experiments and analysis on crowdsourced crisis image and text data:\n                                <ul>\n                                    <li><a href=\"https://pypi.org/project/url-image-module/0.27.0/\" target=\"_blank\">URL Image Module</a> - Utilities for training, testing, and predicting with pretrained Convolutional Neural Networks for classifying\n                                        crowdsourced crisis image data and constructing & analyzing annotated datasets</li>\n                                    <li><a href=\"https://pypi.org/project/url-text-module/0.6.1/\" target=\"_blank\">URL Text Module</a> - Utilities for featurizing crisis text data, training and testing with a variety of classification machine learning models, \n                                        and visualizing clusters of featurized text data</li>\n                                </ul>\n                                <br>\n                                This research was supported by a grant from Google.org and the Tides Foundation.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5><strong>Abstract</strong></h5>\n                            <p>\n                               The availability of information during a climate crisis event is critical for crisis managers to assess and respond to crisis impact. \n                               During crisis events, affected residents post real-time crisis updates on platforms such as <a href=\"https://riskmap.mit.edu/japan.html\" target=\"_blank\">RiskMap</a> and <a href=\"https://twitter.com/?lang=en\" target=\"_blank\">Twitter</a>. \n                               These updates provide localized information, which has the potential to enhance crisis awareness and response. \n                               However, with limited resources, crisis managers may endure information overload from the inundation of these updates. \n                               Prior work has demonstrated the potential of machine learning (ML) methodologies to mitigate this problem. \n                               We have identified limitations in the prior work including the lack of involvement of crisis managers in the development and evaluation of a ML methodology.\n                            </p>\n                            <p>\n                                To address these limitations, we propose a novel framework and ML methodology which investigate the efficacy of various ML methods in enhancing crisis awareness \n                                and response beyond model performance metrics. This framework aims to iteratively embed the information needs and priorities of crisis managers during crisis \n                                into the design of the ML methodology. We cooperated with crisis managers in Fukuchiyama City (FC), a city in Japan which is susceptible to flood events, and \n                                analyzed crowdsourced crisis image and text data from past FC flood events. We devised the Flood Presence image classification task, constructed Train/Dev/Test splits, \n                                and annotated images from FC. We report a weighted F1 score of 92.1% on the test split and 82.5% on the FC images. Using the results of our image analysis \n                                ML methodology and the insights we gained from crisis managers, we iterated on the design of our text analysis ML methodology. This led to the creation of the \n                                Human Risk text classification task which is tailored to a subset of the identified information needs of the crisis managers. \n                                To align with the priorities of crisis managers for this task, we determined the model evaluation metric to be the F2 score. \n                                We report an F2 score of 92.8% on an FC crisis text test dataset, which is a significant improvement over the baseline score of 43.4%. \n                            </p>\n                            <h5><strong>Research Question</strong></h5>\n                            <strong id=\"research-question\">\n                                In collaborating with crisis managers, how can machine learning methods be utilized and evaluated to effectively reduce the information overload of crowdsourced data on\n                                crisis managers during flood events for enhanced crisis awareness and response?\n                            </strong>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Main Research Aims</h5>\n                            <p id=\"research-aims\">\n                                <ol>\n                                    <li><strong>To reduce information overload during a crisis</strong> using accurate, efficient, automated image and text classification of crisis reports by machine learning (ML) models during crisis.</li>\n                                    <li><strong>To embed tacit knowledge, information needs, and decision-making priorities of crisis managers</strong> into the designed ML methodology.</li>\n                                    <li><strong>To evaluate methodology in collaboration with crisis managers</strong>, e.g. crisis managers in Fukuchiyama, Japan.</li>\n                                    <li><strong>To incorporate evaluation results and iterate on the ML methodology</strong> in order to better reach aim of using AI to assist crisis managers during crisis.</li>\n                                </ol>\n                                We investigate various ML techniques\n                                that can be applied to mitigate information overload for crisis managers during crisis\n                                events while also assessing if those techniques can satisfy the information needs and\n                                priorities of crisis managers through qualitative and quantitative evaluation.\n                            </p>\n                            <h5>Novel Framework</h5>\n                            <p>\n                                To achieve the aims above we develop a novel framework in the crisis informatics community consisting of the following components:\n                                <ul>\n                                    <li><strong>Classification Task Creation</strong> - We develop new classification tasks using labels provided to us by crisis managers\n                                        and labels present in open-source datasets</li>\n                                    <li><strong>Data Annotation Procedure</strong> - We open-souce the annotation guide we develop for greater transparency into the procurement of human-annotated\n                                        that is used to train and evaluate ML models</li>\n                                    <li><strong>Interannotator Agreement/Data Reliability Analysis</strong> - After performing an annotation effort on data provided by crisis managers, we analyze the quality\n                                        of the annotations through interannotator agreement analysis to demonstrate the importance of understanding data quality prior to using it for ML purposes</li>\n                                    <li><strong>Model Development and Evaluation; Per-Class Performance Analysis</strong> - The metrics we used to evaluate models are derived either from metrics reported in the literature or, more notably, metrics determined from insights \n                                        provided by crisis managers directly. Additionally, we consider issues of class imbalance and report per-class performance and confusion matrices to provide more granular insight\n                                        into model performance. Finally, we establish baselines to compare against the models we develop to assess the degree to which the models we develop outperform the baseline</li>\n                                    <li><strong>Qualitative Analysis through Workshops with Crisis Managers</strong> - We sought to cooperate with crisis managers with the intent of using this framework to\n                                        iteratively design ML systems, such as the specific classification tasks performed by the models and their associated performance metric, by iteratively incorporating feedback and insights form\n                                        crisis managers, so that the system better aligns with their information needs and decision-making priorities</li>\n                                </ul>\n                                This framework situates <i>Model Development and Evaluation</i>, which is commonplace in prior work, as part of a larger, contextualized analysis. On that note, we\n                                expand on the notion of <i>Model Development and Evaluation</i> beyond what is typically seen in the prior work.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <h5>Machine Learning Methodology</h5>\n                            With crisis management partners in Fukuchiyama (FC), Japan, we present our framework through two ML modules:<br> Image Analysis Module & Text Analysis Module<br>\n                        <br>\n                        <p>\n                            We note that our findings from the Image Analysis Module influenced the design of the Text Analysis Module in order to meet our aim of\n                            developing machine learning systems for crisis management which iteratively incorporate the feedback received from crisis managers.\n                        </p>\n                        <div class=\"row align-items-center justify-content-center pb-5\">\n                            <div class=\"col-6 col-md-6 col-lg-6 pt-3\" v-for=\"module in modules\" :key=\"module.link\">\n                                <ProjectCard :project=\"module\"></ProjectCard>\n                            </div>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nimport ProjectCard from '../../ProjectCard.vue';\nimport { ML_MODULES, scrollUpFunc } from '../../../constants.js';\n\nexport default {\n  name: 'MLForCrowdsourcedCrisisData',\n  components: {\n    ProjectCard\n  },\n  data() {\n    return {\n        modules: ML_MODULES\n    }\n  },\n  methods: {\n    scrollUp() {\n        scrollUpFunc();\n    }\n  }\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\nh1, h3, h5, h6 {\n    color: white;\n}\n\na {\n    color: hotpink;\n}\n\na:hover {\n    color: white;\n}\n\nh1, h3, h5 {\n    color: white;\n}\n\n#overview-pic {\n    margin-top: 10px;\n    margin-bottom: 40px;\n    width: 90vh;\n    height: 40vh;\n}\n\n#research-question {\n    text-align: center;\n    color: white;\n}\n\n</style>","import mod from \"-!../../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../../node_modules/thread-loader/dist/cjs.js!../../../../node_modules/babel-loader/lib/index.js!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./MLForCrowdsourcedCrisisData.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../../node_modules/thread-loader/dist/cjs.js!../../../../node_modules/babel-loader/lib/index.js!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./MLForCrowdsourcedCrisisData.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./MLForCrowdsourcedCrisisData.vue?vue&type=template&id=b4bc0cd6&scoped=true&\"\nimport script from \"./MLForCrowdsourcedCrisisData.vue?vue&type=script&lang=js&\"\nexport * from \"./MLForCrowdsourcedCrisisData.vue?vue&type=script&lang=js&\"\nimport style0 from \"./MLForCrowdsourcedCrisisData.vue?vue&type=style&index=0&id=b4bc0cd6&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"b4bc0cd6\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_c('div',{staticClass:\"col-8\"},[_c('h3',[_vm._v(\"Image Analysis Module\")])]),_c('div',{staticClass:\"col-md-10\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"ccCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"0\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"1\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"2\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"3\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"4\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"5\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"6\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"7\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"8\"}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"9\"}})]),_c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item cc-carousel-item active\"},[_c('div',{staticClass:\"row align-items-center justify-content-around\"},[_c('div',{staticClass:\"col-6 pt-3 pb-5\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"id\":\"image-analysis-module\",\"src\":require(\"../../../../public/assets/image-analysis-module.png\"),\"alt\":\"Second slide\"}})]),_c('div',{staticClass:\"carousel-text col-6\"},[_c('h5',[_vm._v(\"Image Analysis Methodology Overview\")]),_c('p',[_vm._v(\" The goal of the Image Analysis Module is to utilize pretrained Convolutional Neural Network models to yield efficient and accurate predictions from image data in crowdsourced crisis reports. The classification tasks of Damage Severity (DS), Humanitarian Categories (HC), Informativeness (IN), and Flood Presence (FP) form a diverse suite of labels. In a fraction of a second, the model predictions made for these tasks provide a series of categorizations for an individual report. We leverage state-of-the-art CNNs, which strike a necessary balance between model complexity, memory and storage constraints, and model performance to provide these predictions. \"),_c('br'),_c('br'),_vm._v(\" To achieve this aim, we use large, labeled, open-source datasets for training and evaluating the models. We formulate a new crisis image classification task for detecting flood presence in an image and construct a new dataset altogether using flood images from various open-source datasets, which contained flood-adjacent labels. We additionally devise an annotation procedure and analyze the results of human-annotations on crisis images provided to us by crisis managers in Fukuchiyama. We held various image annotation workshops with crisis managers to identify the limitations in our approach and understand how we could iterate on the design of our ML methodology. This evaluation procedure thus enabled us to evaluate the use of image classification models in assisting crisis managers using quantitative metrics as well as qualitatively through the feedback we got through the image annotation workshops. This evaluation directly influenced our approach for devising the Text Analysis Module. \")])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Image Datasets & Train/Dev/Test Splits for Model Development & Evaluation\")]),_c('div',{staticClass:\"row justify-content-around\"},[_c('div',{staticClass:\"carousel-text col-9\"},[_c('p',[_vm._v(\" Since we used CNN models, specifically the EfficientNet-B1 architecture pretrained on ImageNet, we wanted to make use of large open-source image datasets for finetuning the models to perform the classification tasks of Damage Severity (DS), Humanitarian Categories (HC), Informativeness (IN), and Flood Presence (FP). \")]),_c('h6',[_vm._v(\"Open-source Consolidated Crisis Image Datasets\")]),_c('p',[_vm._v(\" For the DS, HC, and IN tasks, we made use of the open-source train/dev/test splits made available at \"),_c('a',{attrs:{\"href\":\"https://crisisnlp.qcri.org/crisis-image-datasets-asonam20\"}},[_vm._v(\"CrisisNLP\")]),_vm._v(\". We train the models which perform these tasks using the train and dev splits. For evaluation, we make use of the respective test splits for each task. \")]),_c('h6',[_vm._v(\"Flood Presence Task Creation and Dataset Formation\")]),_c('p',[_vm._v(\" In this work we focus on flood-crisis events, thus we used various open-source image datasets which have flood-adjacent labels and map them to the binary labels of \\\"Flood\\\"/\\\"Not Flood\\\". Using the resulting dataset, we create randomized, non-overlapping Train/Dev/Test splits. Similar to the above, we use the train & dev splits to develop the FP model, and the test split to evaluate the model. \")])])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('div',{staticClass:\"row align-items-center justify-content-around\"},[_c('div',{staticClass:\"col-8\"},[_c('h5',[_vm._v(\"Flood Presence Dataset Composition\")]),_vm._v(\" Composition of the Flood Presence dataset from the original datasets and the number of images for each label. \"),_c('table',{attrs:{\"id\":\"fp-table\"}},[_c('tr',[_c('th',[_c('strong',[_vm._v(\"Dataset\")])]),_c('th',[_c('strong',[_vm._v(\"Flood\")])]),_c('th',[_c('strong',[_vm._v(\"Not Flood\")])]),_c('th',[_c('strong',[_vm._v(\"Total\")])])]),_c('tr',[_c('td',[_c('i',[_c('strong',[_vm._v(\"Consolidated Disaster Types\")]),_c('br'),_vm._v(\" (\"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/2011.08916\",\"target\":\"_blank\"}},[_vm._v(\"Alam et al. 2020\")]),_vm._v(\") \")])]),_c('td',[_vm._v(\"3201\")]),_c('td',[_vm._v(\"14310\")]),_c('td',[_vm._v(\"17511\")])]),_c('tr',[_c('td',[_c('i',[_c('strong',[_vm._v(\"Central European Floods 2013\")]),_c('br'),_vm._v(\" (\"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/1908.03361\",\"target\":\"_blank\"}},[_vm._v(\"Barz et al. 2018\")]),_vm._v(\") \")])]),_c('td',[_vm._v(\"3151\")]),_c('td',[_vm._v(\"559\")]),_c('td',[_vm._v(\"3710\")])]),_c('tr',[_c('td',[_c('i',[_c('strong',[_vm._v(\"Harz Region Floods 2017\")]),_c('br'),_vm._v(\" (\"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/2011.05756\",\"target\":\"_blank\"}},[_vm._v(\"Barz et al. 2020\")]),_vm._v(\") \")])]),_c('td',[_vm._v(\"264\")]),_c('td',[_vm._v(\"405\")]),_c('td',[_vm._v(\"669\")])]),_c('tr',[_c('td',[_c('i',[_c('strong',[_vm._v(\"Rhine River Floods 2018\")]),_c('br'),_vm._v(\" (\"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/2011.05756\",\"target\":\"_blank\"}},[_vm._v(\"Barz et al. 2020\")]),_vm._v(\") \")])]),_c('td',[_vm._v(\"730\")]),_c('td',[_vm._v(\"1007\")]),_c('td',[_vm._v(\"1737\")])]),_c('tr',[_c('td',[_vm._v(\"Total\")]),_c('td',[_vm._v(\"7346\")]),_c('td',[_vm._v(\"16281\")]),_c('td',[_vm._v(\"23627\")])])])])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Image Training Sets\")]),_c('div',{staticClass:\"row align-items-center justify-content-between\"},[_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/ds-train.png\")}})]),_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/hc-train.png\")}})]),_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/in-train.png\")}})]),_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/fp-train.png\")}})])]),_c('p',[_vm._v(\" As part of the framework we developed, we investigated the class imbalance for each of the image classification training sets. We observed significant imbalance in the label distributions for the Damage Severity and the Humanitarian Categories tasks. We note that this imbalance could be problematic for the performance of the models on the minority classes for those tasks, e.g. the \\\"Mild\\\", \\\"Rescue, Volunteering, or Donation Effort\\\", and \\\"Affected, Injured, or Dead People\\\" classes. \")])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('div',{staticClass:\"row align-items-center justify-content-around\"},[_c('h5',[_vm._v(\"Model Evaluation on Test Splits & Flood Presence Benchmark Performance\")]),_c('div',{staticClass:\"col-8\"},[_vm._v(\" Performance of image classification models on their respective test splits. [1] as referred to in the table can be found in the footnote below.\"),_c('sup',[_c('a',{attrs:{\"href\":\"#fn1\",\"id\":\"ref1\"}},[_vm._v(\"1\")])]),_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/test-set-eval.png\")}})])]),_c('p',[_vm._v(\" Similar to the authors in [1]\"),_c('sup',[_c('a',{attrs:{\"href\":\"#fn1\",\"id\":\"ref1\"}},[_vm._v(\"1\")])]),_vm._v(\", we report overall model performance as weighted metrics in order to take into account class imbalance present in the test splits. From the table above, we observe that the models we finetuned achieve a weighted F1 score within a 1% difference compared to the model performances reported in [1]. \"),_c('strong',[_vm._v(\"We report a benchmark performance of 92.1% weighted F1 for the Flood Presence (FP) task.\")]),_vm._v(\" We postulate the comparatively higher performance of FP task to be due to the task being binary as well as being the most clear and objective task, thus being a comparatively simipler task for the model to learn. We explore this more through interannotator agreement analysis discussed in the next slides. \")]),_c('hr'),_c('p',[_c('sup',{attrs:{\"id\":\"fn1\"}},[_vm._v(\"1. Firoj Alam, Ferda Ofli, Muhammad Imran, Tanvirul Alam, Umair Qazi, \"),_c('a',{attrs:{\"href\":\"https://arxiv.org/pdf/2011.08916.pdf\",\"target\":\"_blank\"}},[_vm._v(\"Deep Learning Benchmarks and Datasets for Social Media Image Classification for Disaster Response\")]),_vm._v(\", In 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), 2020.\"),_c('a',{attrs:{\"href\":\"#ref1\",\"title\":\"Jump back to footnote 1 in the text.\"}},[_vm._v(\"\")])])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Annotating Fukuchiyama Crisis Images\")]),_c('p',[_vm._v(\" To evaluate our developed models and framework in a context which is susceptible to flood events, we cooperated with crisis managers in Fukuchiyama, Japan to attain \"),_c('strong',[_vm._v(\"658 images\")]),_vm._v(\" from previous flood events as well as non-crisis normal days in Fukuchiyama, which were collected on the ground, similar to RiskMap images. To form evaluation/test sets from this data, we needed to label the images for each of the four image classification tasks we've discussed. \")]),_c('p',[_c('ul',[_c('li',[_vm._v(\"The images were labeled independently by Urban Risk Lab researchers for each task. The researchers used \"),_c('a',{attrs:{\"href\":\"https://github.com/dyllew/towards-automated-assessment-of-crowdsourced-crisis-reporting/blob/main/Image%20Analysis%20Module/Annotation/Image%20Labeling%20Guide.docx\",\"target\":\"_blank\"}},[_vm._v(\"this guide\")]),_vm._v(\" to inform their decisions.\")]),_c('li',[_vm._v(\"Each image was independently provided a \"),_c('strong',[_vm._v(\"single label for each task\")]),_vm._v(\" by 3 annotators.\")]),_c('li',[_vm._v(\"We enforced independent labeling by hiding the labels given by the other labelers while someone was labeling.\")])])]),_c('p',[_vm._v(\" Since each image was given three labels for a task, we use the plurality, or most frequent label, given to the image as the ground-truth label for that image. We chose this method of ground-truthing to minimize any specific person's contributed bias towards the ground-truth label. If there was not a plurality label, we do not label the image and thus do not put that image in the test set for that task, but did make note of the disagreement for later analysis. \")])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('h5',[_vm._v(\"Inter-Annotator Agreement Analysis on Annotated Fukuchiyama Images\")]),_c('div',{staticClass:\"row align-items-center justify-content-around\"},[_c('div',{staticClass:\"col-6 pt-3 pb-5\"},[_c('h2',[_vm._v(\"... a computer cannot generally agree with annotators at a rate that is higher than the rate at which the annotators agree with each other.\\\"\"),_c('sup',[_c('a',{attrs:{\"href\":\"#fn2\",\"id\":\"ref2\"}},[_vm._v(\"2\")])])])]),_c('div',{staticClass:\"carousel-text col-6\"},[_c('p',[_vm._v(\" Since the data we have is \"),_c('strong',[_vm._v(\"human-annotated\")]),_vm._v(\" and thus introduces subjectivity, we aimed to assess and make transparent \"),_c('strong',[_vm._v(\"the quality of the annotated datasets\")]),_vm._v(\", thus we computed measures of inter-annotator agreement (IAA). \"),_c('br'),_c('br'),_vm._v(\" This IAA analysis enabled us to determine, for each task: \"),_c('ul',[_c('li',[_vm._v(\"How reproducible labeling for the task is\")]),_c('li',[_vm._v(\"How are annotation procedure can be improved:\")]),_c('ul',[_c('li',[_vm._v(\"Refinement of task label definitions\")]),_c('li',[_vm._v(\"Clarifying data points of disagreement between annotators\")]),_c('li',[_vm._v(\"Adding more examples for each class\")])])]),_vm._v(\" This analysis has the advantage of happening before any model development, focusing on \"),_c('strong',[_vm._v(\"improvement of classification task formulation itself rather than building a model which will likely perform poorly on an ill-formed task.\")])])])]),_c('hr'),_c('p',[_c('sup',{attrs:{\"id\":\"fn2\"}},[_vm._v(\"2. D. T. Nguyen, K. Al-Mannai, S. R. Joty, H. Sajjad, M. Imran, and P. Mitra, \"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/1608.03902\",\"target\":\"_blank\"}},[_vm._v(\"Rapid classification of crisis-related data on social networks using convolutional neural networks,\")]),_vm._v(\" CoRR, vol. abs/1608.03902, 2016.\"),_c('a',{attrs:{\"href\":\"#ref2\",\"title\":\"Jump back to footnote 2 in the text.\"}},[_vm._v(\"\")])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('div',{staticClass:\"row align-items-center justify-content-around\"},[_c('h5',[_vm._v(\"Inter-Annotator Agreement Analysis on Annotated Fukuchiyama Images\")]),_c('div',{staticClass:\"col-8\"},[_vm._v(\" Agreement Measures by Task for Labeled Fukuchiyama Images \"),_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/iaa.png\")}})])]),_c('br'),_c('p',[_c('strong',[_vm._v(\"Fleiss' Kappa\")]),_vm._v(\" score incorporates the level of agreement attained if the annotators did not look at the data when labeling, i.e. \"),_c('strong',[_vm._v(\"random chance agreement\")]),_vm._v(\", which is an advantage over the complete agreement percentage (\\\"Unanimous Agreement Percentage\\\" pictured above), in which all annotators agree on the same label for an image. \"),_c('ul',[_c('li',[_vm._v(\"By Fleiss' Kappa, we observe smaller improvements over random chance agreement for Damage Severity (0.413), Humanitarian Categories (0.304), and Informativeness (0.313) as compared to Flood Presence (0.829)\")]),_c('ul',[_c('li',[_vm._v(\" This suggests that further investigation should be conducted in refining the label definitions and the annotation guide for clarity by understanding potential causes for disagreement on the tasks with lower Fleiss' Kappa scores, in order to improve agreement and thus the quality of the dataset.\")])]),_c('li',[_vm._v(\"We use the plurality labels found for each task to form the ground-truth Fukuchiyama datasets for each of the tasks which we evaluate the trained CNN models on.\")])])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Annotated Fukuchiyama Image Test Sets\")]),_c('div',{staticClass:\"row align-items-center justify-content-between\"},[_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/ds-fc.png\")}})]),_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/hc-fc.png\")}})]),_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/in-fc.png\")}})]),_c('div',{staticClass:\"col-12 col-md-6 col-lg-3 pt-3\"},[_c('img',{staticClass:\"img-fluid\",attrs:{\"src\":require(\"../../../../public/assets/fp-fc.png\")}})])]),_c('p',[_vm._v(\" The ground-truth datasets are formed from the plurality labels found from the annotations given to the Fukuchiyama images. We again observe imbalance in the resulting datasets, albeit to varying degrees. Therefore, we again make use of weighted aggregate metrics for model evaluation, however, for a more granular insight into model performance, we also investigate the per-class performance of each model by precision, recall, and F1 score for each class and visualize the confusion matrix. Lastly, we establish a comparison to a baseline classifier using the Cohen's Kappa score. \")])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\" To be continued... \")]),_c('img',{attrs:{\"id\":\"pika-gif\",\"src\":require(\"../../../../public/assets/pika-gif.gif\")}})])])])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-8\">  \n            <h3>Image Analysis Module</h3>\n        </div>\n        <div class=\"col-md-10\">\n            <div id=\"ccCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"0\" class=\"active\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"1\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"2\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"3\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"4\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"5\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"6\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"7\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"8\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"9\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item cc-carousel-item active\">\n                        <div class=\"row align-items-center justify-content-around\">\n                            <div class=\"col-6 pt-3 pb-5\">\n                                <img id=\"image-analysis-module\" class=\"img-fluid\" src=\"../../../../public/assets/image-analysis-module.png\" alt=\"Second slide\">\n                            </div>\n                            <div class=\"carousel-text col-6\">\n                                <h5>Image Analysis Methodology Overview</h5>\n                                <p> \n                                    The goal of the Image Analysis Module is to utilize pretrained Convolutional Neural Network models to yield\n                                    efficient and accurate predictions from image data in crowdsourced crisis reports. The\n                                    classification tasks of Damage Severity (DS), Humanitarian Categories (HC), Informativeness (IN), and\n                                    Flood Presence (FP) form a diverse suite of labels. In a fraction of a second, the model\n                                    predictions made for these tasks provide a series of categorizations for an individual\n                                    report. We leverage state-of-the-art CNNs, which strike a necessary balance between\n                                    model complexity, memory and storage constraints, and model performance to provide\n                                    these predictions.\n                                    <br>\n                                    <br>\n                                    To achieve this aim, we use large, labeled, open-source datasets for training and\n                                    evaluating the models. We formulate a new crisis image classification task for detecting flood presence in an image and construct\n                                    a new dataset altogether using flood images from various open-source datasets, which contained\n                                    flood-adjacent labels. We additionally devise an annotation procedure and analyze the results of human-annotations on crisis images \n                                    provided to us by crisis managers in Fukuchiyama. We held various image annotation workshops with crisis managers to identify the limitations in our\n                                    approach and understand how we could iterate on the design of our ML methodology. This evaluation procedure thus enabled us to evaluate the use of image classification models in assisting crisis managers\n                                    using quantitative metrics as well as qualitatively through the feedback we got through the image annotation workshops. \n                                    This evaluation directly influenced our approach for devising the Text Analysis Module.\n                                </p>\n                            </div>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Image Datasets & Train/Dev/Test Splits for Model Development & Evaluation</h5>\n                            <div class=\"row justify-content-around\">\n                                <div class=\"carousel-text col-9\">\n                                    <p>\n                                        Since we used CNN models, specifically the EfficientNet-B1 architecture pretrained on ImageNet, we wanted to make use of large open-source image datasets\n                                        for finetuning the models to perform the classification tasks of Damage Severity (DS), Humanitarian Categories (HC), Informativeness (IN), and Flood Presence (FP).\n                                    </p>\n                                    <h6>Open-source Consolidated Crisis Image Datasets</h6>\n                                    <p>\n                                        For the DS, HC, and IN tasks, we made use of the open-source train/dev/test splits made available at \n                                        <a href=\"https://crisisnlp.qcri.org/crisis-image-datasets-asonam20\">CrisisNLP</a>. We train the models which perform these tasks using\n                                        the train and dev splits. For evaluation, we make use of the respective test splits for each task.\n                                    </p>\n                                    <h6>Flood Presence Task Creation and Dataset Formation</h6>\n                                    <p>\n                                        In this work we focus on flood-crisis events, thus we used various open-source image datasets which have flood-adjacent labels\n                                        and map them to the binary labels of \"Flood\"/\"Not Flood\". Using the resulting dataset, we create randomized, non-overlapping Train/Dev/Test splits.\n                                        Similar to the above, we use the train & dev splits to develop the FP model, and the test split to evaluate the model.\n                                    </p>\n                                </div>\n                            </div>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <div class=\"row align-items-center justify-content-around\">\n                                <div class=\"col-8\">\n                                    <h5>Flood Presence Dataset Composition</h5>\n                                    Composition of the Flood Presence dataset from the original datasets and the number of images for each label.\n                                    <table id=\"fp-table\">\n                                        <tr>\n                                            <th><strong>Dataset</strong></th>\n                                            <th><strong>Flood</strong></th>\n                                            <th><strong>Not Flood</strong></th>\n                                            <th><strong>Total</strong></th>\n                                        </tr>\n                                        <tr>\n                                            <td>\n                                                <i>\n                                                    <strong>Consolidated Disaster Types</strong>\n                                                    <br>\n                                                    (<a href=\"https://arxiv.org/abs/2011.08916\" target=\"_blank\">Alam et al. 2020</a>)\n                                                </i>\n                                            </td>\n                                            <td>3201</td>\n                                            <td>14310</td>\n                                            <td>17511</td>\n                                        </tr>\n                                        <tr>\n                                            <td>\n                                                <i>\n                                                    <strong>Central European Floods 2013</strong>\n                                                    <br>\n                                                    (<a href=\"https://arxiv.org/abs/1908.03361\" target=\"_blank\">Barz et al. 2018</a>)\n                                                </i>\n                                            </td>\n                                            <td>3151</td>\n                                            <td>559</td>\n                                            <td>3710</td>\n                                        </tr>\n                                        <tr>\n                                            <td>\n                                                <i>\n                                                    <strong>Harz Region Floods 2017</strong>\n                                                    <br>\n                                                    (<a href=\"https://arxiv.org/abs/2011.05756\" target=\"_blank\">Barz et al. 2020</a>)\n                                                </i>\n                                            </td>\n                                            <td>264</td>\n                                            <td>405</td>\n                                            <td>669</td>\n                                        </tr>\n                                        <tr>\n                                            <td>\n                                                <i>\n                                                    <strong>Rhine River Floods 2018</strong>\n                                                    <br>\n                                                    (<a href=\"https://arxiv.org/abs/2011.05756\" target=\"_blank\">Barz et al. 2020</a>)\n                                                </i>\n                                            </td>\n                                            <td>730</td>\n                                            <td>1007</td>\n                                            <td>1737</td>\n                                        </tr>\n                                        <tr>\n                                            <td>Total</td>\n                                            <td>7346</td>\n                                            <td>16281</td>\n                                            <td>23627</td>\n                                        </tr>\n                                    </table>\n                                </div>\n                            </div>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Image Training Sets</h5>\n                            <div class=\"row align-items-center justify-content-between\">\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/ds-train.png\" class=\"img-fluid\"/>\n                                </div>\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/hc-train.png\" class=\"img-fluid\"/>\n                                </div>\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/in-train.png\" class=\"img-fluid\"/>\n                                </div>\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/fp-train.png\" class=\"img-fluid\"/>\n                                </div>\n                            </div>\n                            <p>\n                                As part of the framework we developed, we investigated the class imbalance for each of the\n                                image classification training sets. We observed significant imbalance in the label distributions for the Damage Severity \n                                and the Humanitarian Categories tasks. We note that this imbalance could be problematic for the performance of the models on\n                                the minority classes for those tasks, e.g. the \"Mild\", \"Rescue, Volunteering, or Donation Effort\", and \"Affected, Injured, or Dead People\" classes.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <div class=\"row align-items-center justify-content-around\">\n                                <h5>Model Evaluation on Test Splits & Flood Presence Benchmark Performance</h5>\n                                <div class=\"col-8\">\n                                    Performance of image classification models on their respective test splits. [1] as referred to in the table can be found in the footnote below.<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup>\n                                    <img src=\"../../../../public/assets/test-set-eval.png\" class=\"img-fluid\">\n                                </div>\n                            </div>\n                            <p>\n                                    Similar to the authors in [1]<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup>, we report overall model performance as\n                                    weighted metrics in order to take into account class imbalance present in the test splits.\n                                    From the table above, we observe that the models we finetuned achieve a weighted F1 score within a 1% difference\n                                    compared to the model performances reported in [1]. <strong>We report a benchmark performance of 92.1% weighted F1 for the Flood Presence (FP) task.</strong>\n                                    We postulate the comparatively higher performance of FP task to be due to the task being binary as well as being the most clear and objective task, thus being a comparatively\n                                    simipler task for the model to learn. We explore this more through interannotator agreement analysis discussed in the next slides.\n                            </p>\n                            <hr>\n                            <p>\n                                <sup id=\"fn1\">1. Firoj Alam, Ferda Ofli, Muhammad Imran, Tanvirul Alam, Umair Qazi, \n                                    <a href=\"https://arxiv.org/pdf/2011.08916.pdf\" target=\"_blank\">Deep Learning Benchmarks and Datasets for Social Media Image Classification for Disaster Response</a>, \n                                    In 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), 2020.<a href=\"#ref1\" title=\"Jump back to footnote 1 in the text.\"></a>\n                                </sup>\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Annotating Fukuchiyama Crisis Images</h5>\n                            <p>\n                                To evaluate our developed models and framework in a context which is susceptible to flood events, we cooperated with crisis managers in \n                                Fukuchiyama, Japan to attain <strong>658 images</strong> from previous flood events as well as non-crisis normal days in Fukuchiyama, which were collected on the ground,\n                                similar to RiskMap images. To form evaluation/test sets from this data, we needed to label the images for each of the four image classification tasks we've discussed.\n                            </p>\n                            <p>\n                                <ul>\n                                    <li>The images were labeled independently by Urban Risk Lab researchers for each task. The researchers used <a href=\"https://github.com/dyllew/towards-automated-assessment-of-crowdsourced-crisis-reporting/blob/main/Image%20Analysis%20Module/Annotation/Image%20Labeling%20Guide.docx\" target=\"_blank\">this guide</a> to inform their decisions.</li>\n                                    <li>Each image was independently provided a <strong>single label for each task</strong> by 3 annotators.</li>\n                                    <li>We enforced independent labeling by hiding the labels given by the other labelers while someone was labeling.</li>\n                                </ul>\n                            </p>\n                            <p>\n                                Since each image was given three labels for a task, we use the plurality, or most frequent label, given to the image as the ground-truth label for that image. We chose this method of ground-truthing to minimize any specific person's contributed bias towards the ground-truth label.\n                                If there was not a plurality label, we do not label the image and thus do not put that image in the test set for that task, but did make note of the disagreement for later analysis.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <h5>Inter-Annotator Agreement Analysis on Annotated Fukuchiyama Images</h5>\n                        <div class=\"row align-items-center justify-content-around\">\n                                <div class=\"col-6 pt-3 pb-5\">\n                                    <h2>... a computer cannot generally agree with annotators at a rate that is higher than the rate at which the annotators agree with each other.\"<sup><a href=\"#fn2\" id=\"ref2\">2</a></sup></h2>\n                                </div>\n                                <div class=\"carousel-text col-6\">\n                                    <p> \n                                        Since the data we have is <strong>human-annotated</strong> and thus introduces subjectivity, we aimed to assess and make transparent <strong>the quality of the annotated datasets</strong>, thus we computed measures of inter-annotator agreement (IAA).\n                                        <br>\n                                        <br>\n                                        This IAA analysis enabled us to determine, for each task:\n                                        <ul>\n                                            <li>How reproducible labeling for the task is</li>\n                                            <li>How are annotation procedure can be improved:</li>\n                                                <ul>\n                                                    <li>Refinement of task label definitions</li>\n                                                    <li>Clarifying data points of disagreement between annotators</li>\n                                                    <li>Adding more examples for each class</li>\n                                                </ul>\n                                        </ul>\n                                        This analysis has the advantage of happening before any model development, focusing on <strong>improvement of classification task formulation itself rather than building a model which will likely perform poorly on an ill-formed task.</strong>\n                                    </p>\n                                </div>\n                        </div>\n                        <hr>\n                        <p>\n                            <sup id=\"fn2\">2. D. T. Nguyen, K. Al-Mannai, S. R. Joty, H. Sajjad, M. Imran, and P. Mitra, <a href=\"https://arxiv.org/abs/1608.03902\" target=\"_blank\">Rapid classification of crisis-related data on social networks using convolutional neural networks,</a> CoRR, vol. abs/1608.03902, 2016.<a href=\"#ref2\" title=\"Jump back to footnote 2 in the text.\"></a></sup>\n                        </p>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <div class=\"row align-items-center justify-content-around\">\n                                <h5>Inter-Annotator Agreement Analysis on Annotated Fukuchiyama Images</h5>\n                                <div class=\"col-8\">\n                                    Agreement Measures by Task for Labeled Fukuchiyama Images\n                                    <img src=\"../../../../public/assets/iaa.png\" class=\"img-fluid\">\n                                </div>\n                            </div>\n                            <br>\n                            <p>\n                                <strong>Fleiss' Kappa</strong> score incorporates the level of agreement attained if the annotators did not look at the data when labeling, i.e. \n                                <strong>random chance agreement</strong>, which is an advantage over the complete agreement percentage (\"Unanimous Agreement Percentage\" pictured above), in which all annotators\n                                agree on the same label for an image.\n                                <ul>\n                                    <li>By Fleiss' Kappa, we observe smaller improvements over random chance agreement for Damage Severity (0.413), Humanitarian Categories (0.304), and Informativeness (0.313) as compared to Flood Presence (0.829)</li>\n                                        <ul>\n                                            <li> This suggests that further investigation should be conducted in refining the label definitions and the annotation guide for clarity by understanding potential causes for disagreement on the tasks with lower Fleiss' Kappa scores,\n                                                in order to improve agreement and thus the quality of the dataset.</li>\n                                        </ul>\n                                    <li>We use the plurality labels found for each task to form the ground-truth Fukuchiyama datasets for each of the tasks which we evaluate the trained CNN models on.</li>\n                                </ul>\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Annotated Fukuchiyama Image Test Sets</h5>\n                            <div class=\"row align-items-center justify-content-between\">\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/ds-fc.png\" class=\"img-fluid\"/>\n                                </div>\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/hc-fc.png\" class=\"img-fluid\"/>\n                                </div>\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/in-fc.png\" class=\"img-fluid\"/>\n                                </div>\n                                <div class=\"col-12 col-md-6 col-lg-3 pt-3\">\n                                    <img src=\"../../../../public/assets/fp-fc.png\" class=\"img-fluid\"/>\n                                </div>\n                            </div>\n                            <p>\n                                The ground-truth datasets are formed from the plurality labels found from the annotations given to the Fukuchiyama images.\n\n                                We again observe imbalance in the resulting datasets, albeit to varying degrees. Therefore, we again make use of weighted aggregate metrics for model evaluation,\n                                however, for a more granular insight into model performance, we also investigate the per-class performance of each model by precision, recall, \n                                and F1 score for each class and visualize the confusion matrix. Lastly, we establish a comparison to a baseline classifier using the Cohen's Kappa score.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5> To be continued... </h5>\n                            <img id=\"pika-gif\" src=\"../../../../public/assets/pika-gif.gif\">\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nexport default {\n  name: 'ImageAnalysisCarousel'\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\nh1, h3, h5, h6 {\n    color: white;\n}\n\na {\n    color: hotpink;\n}\n\na:hover {\n    color: white;\n}\n\nh1, h3, h5 {\n    color: white;\n}\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n#overview-pic {\n    margin-top: 10px;\n    margin-bottom: 40px;\n    width: 90vh;\n    height: 40vh;\n}\n\n#research-question {\n    text-align: center;\n    color: white;\n}\n\n#image-analysis-module {\n    width: 70vh;\n    height: 80vh;\n}\n\n#pika-gif {\n    margin-top: 10px;\n    margin-bottom: 40px;\n    width: 60vh;\n    height: 40vh;\n}\n\n@media (max-width: 800px) {\n    .cc-carousel-item img {\n        max-height: 80vw;\n    }\n}\n\n#fp-table {\n  font-family: Arial, Helvetica, sans-serif;\n  border-collapse: collapse;\n  color: black;\n  width: 100%;\n}\n\n#fp-table td, #fp-table th {\n  border: 1px solid #ddd;\n  padding: 8px;\n}\n\n#fp-table tr:nth-child(even){background-color: #f2f2f2;}\n#fp-table tr:hover{background-color: #ddd;}\n#fp-table tr:nth-child(odd) {background-color: #ddd;}\n\n#fp-table th {\n  padding-top: 12px;\n  padding-bottom: 12px;\n  text-align: center;\n  background-color: darkturquoise;\n  color: white\n}\n\n</style>","import mod from \"-!../../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../../node_modules/thread-loader/dist/cjs.js!../../../../node_modules/babel-loader/lib/index.js!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ImageAnalysisCarousel.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../../node_modules/thread-loader/dist/cjs.js!../../../../node_modules/babel-loader/lib/index.js!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ImageAnalysisCarousel.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./ImageAnalysisCarousel.vue?vue&type=template&id=d010bdf8&scoped=true&\"\nimport script from \"./ImageAnalysisCarousel.vue?vue&type=script&lang=js&\"\nexport * from \"./ImageAnalysisCarousel.vue?vue&type=script&lang=js&\"\nimport style0 from \"./ImageAnalysisCarousel.vue?vue&type=style&index=0&id=d010bdf8&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"d010bdf8\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_c('div',{staticClass:\"col-8\"},[_c('h3',[_vm._v(\"Text Analysis Module\")])]),_c('div',{staticClass:\"col-md-10\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"ccCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"0\"}})]),_c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item active cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('img',{attrs:{\"id\":\"pika-gif\",\"src\":require(\"../../../../public/assets/pika-gif.gif\"),\"alt\":\"First slide\"}})])])])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-8\">  \n            <h3>Text Analysis Module</h3>\n        </div>\n        <div class=\"col-md-10\">\n            <div id=\"ccCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"0\" class=\"active\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <img id=\"pika-gif\" src=\"../../../../public/assets/pika-gif.gif\" alt=\"First slide\">\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n\n<script>\n\nexport default {\n  name: 'TextAnalysisCarousel'\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\nh1, h3, h5, h6 {\n    color: white;\n}\n\na {\n    color: hotpink;\n}\n\na:hover {\n    color: white;\n}\n\nh1, h3, h5 {\n    color: white;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n#pika-gif {\n    margin-top: 10px;\n    margin-bottom: 40px;\n    width: 60vh;\n    height: 40vh;\n}\n\n@media (max-width: 800px) {\n    .cc-carousel-item img {\n        max-height: 80vw;\n    }\n}\n\n</style>","import mod from \"-!../../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../../node_modules/thread-loader/dist/cjs.js!../../../../node_modules/babel-loader/lib/index.js!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TextAnalysisCarousel.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../../node_modules/thread-loader/dist/cjs.js!../../../../node_modules/babel-loader/lib/index.js!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TextAnalysisCarousel.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./TextAnalysisCarousel.vue?vue&type=template&id=4dc6ec22&scoped=true&\"\nimport script from \"./TextAnalysisCarousel.vue?vue&type=script&lang=js&\"\nexport * from \"./TextAnalysisCarousel.vue?vue&type=script&lang=js&\"\nimport style0 from \"./TextAnalysisCarousel.vue?vue&type=style&index=0&id=4dc6ec22&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"4dc6ec22\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_vm._m(0),_c('div',{staticClass:\"col-md-8\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"NLPIntLitDevCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#NLPIntLitDevCarousel\",\"data-slide-to\":\"0\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#NLPIntLitDevCarousel\",\"data-slide-to\":\"1\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#NLPIntLitDevCarousel\",\"data-slide-to\":\"2\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#NLPIntLitDevCarousel\",\"data-slide-to\":\"3\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#NLPIntLitDevCarousel\",\"data-slide-to\":\"4\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#NLPIntLitDevCarousel\",\"data-slide-to\":\"5\"},on:{\"click\":_vm.scrollUp}})]),_vm._m(1)])])])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"col-8\"},[_c('h3',[_vm._v(\"Information Extraction and Unsupervised Methods for Streamlining Evidence Synthesis in International Development Gray Literature\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item active int-dev-lit-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/int-dev-results.png\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Project Presentation, Report, and Code\")]),_c('p',[_vm._v(\" This was a final project for 6.864: Advanced Natural Language Processing. This presentation focuses on introducing the project, the specific parts I worked on, and the main results from our analysis. \"),_c('br'),_vm._v(\" A brief overview of the motivation, methods, and results is available in this \"),_c('a',{attrs:{\"href\":\"./assets/int-dev-gray-lit.pdf\",\"target\":\"_blank\"}},[_vm._v(\"presentation PDF.\")]),_c('br'),_vm._v(\" The more thorough report of our methodology, visualizations, and findings \"),_c('a',{attrs:{\"href\":\"./assets/6_864_Project.pdf\",\"target\":\"_blank\"}},[_vm._v(\"here.\")]),_c('br'),_vm._v(\" The code for this project was written in Python. \"),_c('a',{attrs:{\"href\":\"https://github.com/dyllew/6.864-fp\",\"target\":\"_blank\"}},[_vm._v(\"Here's the GitHub Repo.\")])]),_c('p',[_vm._v(\" For this project, my main contributions were the supervised methodology/Named Entity Recognition stream discussed in the following slides \")])])]),_c('div',{staticClass:\"carousel-item int-dev-lit-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Abstract\")]),_c('p',[_vm._v(\" In fields like international development, decision-makers prioritize making evidence-based decisions for funding and implementing future projects. This aim is made difficult because of the plethora of information being published each year, and the nature of the research corpus as unstructured text or grey literature. To make informed decisions and understand the growing corpus of research available, researchers have turned to evidence synthesis - the process of compiling information and knowledge from many sources and disciplines to inform decisions. However, the manual evidence synthesis process takes extensive time (often 18 months to 3 years) and effort, and may soon be impossible at the worlds increasing rate of research output. To address these problems, we employ natural language processing techniques on a international development literature corpus of 244 documents to extract information from the title and abstract of international development documents, and to automatically cluster documents based on their content. We classify documents by Country of Study using a pretrained transformer Named Entity Recognition model and achieve an accuracy of 91.0%. Using K-Means clustering, we uncover informative and distinctive groupings of the documents which share similar semantic content. These methods reduce the time it takes for manual evidence synthesis for international development grey literature by enabling country of study filtering and clustering documents by semantic similarity. \")])])]),_c('div',{staticClass:\"carousel-item int-dev-lit-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Named Entity Recognition (NER) for Country of Study (CoS) Classification - Models\")]),_c('p',[_vm._v(\" The country of study (CoS) associated with each paper is quite pertinent to the international development domain. Our dataset is labeled with the CoS of each paper in our corpus. However, since our dataset is rather small (244 documents), we sought to evaluate whether pretrained NER models which extract a variety of entity types from text, could accurately extract the CoS for the papers in our corpus, which have a variety of text fields. \")]),_c('h6',[_vm._v(\"Country of Study Extraction and Classification\")]),_c('p',[_vm._v(\" We create a lower-cased, alphabetically-ordered, list of countries, which we construct using countryinfo \"),_c('a',{attrs:{\"href\":\"https://pypi.org/project/countryinfo/\",\"target\":\"_blank\"}},[_vm._v(\"(Link to CountryInfo PyPI page)\")]),_vm._v(\", a Python package which contains a large dictionary of countries, their alternative names, and ISO information. We ensure the strings of the countries present in our corpus match their respective string in the alphabetically-sorted list of countries. We note that Myanmar and Kosovo are countries present in our corpus, but are not present in the countryinfo dictionary, so we add them to the final list of alphabetically-sorted countries. Since nationality is a type of named entity that NER models typically extract in addition to countries, using a comprehensive, open-source nationality-country mapping \"),_c('a',{attrs:{\"href\":\"https://github.com/knowitall/chunkedextractor/blob/master/src/main/resources/edu/knowitall/chunkedextractor/demonyms.csv\",\"target\":\"_blank\"}},[_vm._v(\"(Demonym-Country Mapping Link)\")]),_vm._v(\", we construct a lower-cased, alphabetically-ordered list of nationalities as well as a dictionary mapping nationality to country. We note that we use the words nationality and demonym interchangeably. These lists and dictionary are useful for performing the country of study (CoS) classification using extracted entities from input text or determining if a nationality or country is a substring contained in the input text string. \")]),_c('h6',[_vm._v(\"Simple Substring Matcher (SSM) Algorithm Baseline & CoS Extraction & Classification\")]),_c('p',[_vm._v(\" As a baseline to our CoS prediction task, we devise a simple, non-ML, deterministic algorithm, called the Simple Substring Matcher (SSM) Algorithm. This method begins by making the input text lower-cased. To predict a CoS, it then scans through the alphabetically-sorted list of countries and classifies the first country which is a substring in the input text as the CoS. If no country is found as a substring in the text, the method then scans the alphabetically-sorted list of nationalities. If a nationality is found as a substring of the input, the method maps the nationality to the corresponding country and classifies the paper as having that country as the CoS. If neither country nor nationality is found as a substring in the text, the method classifies the paper's CoS as a \"),_c('i',[_vm._v(\"None\")]),_vm._v(\" value. We refer to this classification model as the Simple Substring Matcher (SSM) model. \")]),_c('h6',[_vm._v(\"CoS Extraction & Classification by Pretrained NER Models\")]),_c('p',[_vm._v(\" Although we utilize different pretrained NER models in our experiments as shown in the next slide, the process for classifying CoS using predicted entities is the same. Each model takes the raw text as input, predicts various non-overlapping entities present in the text into one of several entity categories. For the CoS classification task, we only consider the predicted \"),_c('b',[_vm._v(\"NORP\")]),_vm._v(\" (nationalities, or religious, or political groups) entities and the \"),_c('b',[_vm._v(\"GPE\")]),_vm._v(\" (countries, cities, states) entities as we assume that these categories are the only ones which would contain the country or relevant demonym associated with the CoS. We now begin our discussion of the classification procedure for the pretrained NER models. First, we make all NORP and GPE entities lower-cased. Next, we map any demonyms present among the NORP entities to their corresponding country. We then combine the resulting unique NORP and GPE entities into an alphabetically-ordered list. We scan this list of NORP and GPE entities checking if any of them exist in the countries list mentioned above, classifying the CoS as the first entity-country match found. If no match is found, we make a final attempt to determine the CoS by providing each of the entities as input to the GeoPy Geocoder \"),_c('a',{attrs:{\"href\":\"https://geopy.readthedocs.io/en/stable/\",\"target\":\"_blank\"}},[_vm._v(\"(Link to GeoPy API)\")]),_vm._v(\" object, which provides an address-location object if a location is found for the provided entity or no value otherwise. We do this for each entity, and if a location is found for a particular entity, we classify the paper's CoS as the country associated with the found address-location. If no country is found for all the entities, we classify the paper's CoS as \"),_c('i',[_vm._v(\"None\")]),_vm._v(\". \")])])]),_c('div',{staticClass:\"carousel-item int-dev-lit-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/ner-results.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"NER for Country of Study Classification - Results\")]),_c('p',[_vm._v(\" In addition to testing different classification models, I experimented with different input strings to see how results change with various text fields and concatenations between them. These various inputs to the models include the title, abstract, intervention description, outcome description, and various concatenations of these text fields. \")]),_c('p',[_vm._v(\" All of the pretrained spaCy NER models have 0.0% accuracy when using the just the intervention description, however the SSM model achieves 13.9% accuracy on the intervention description. All models attain an accuracy of 2.9% when using just the outcome description. The title and abstract individually appear to be good input fields for predicting the CoS, however the concatenation of title and abstract appears to be the most informative input, as this is the input that yields the highest performance across all of the models. Overall, we observe that the baseline simple substring checker is a fairly competitive model against the pretrained ML models, outperforming all the ML models on intervention description, performing the same as the ML models on outcome description, and only falling a few percentage points below even the best ML model on the other inputs. With the exception of the title, intervention description, and outcome description, the ML models in increasing order of complexity, do increasingly better on the CoS extraction task, in the following order from least performant to most performant: ESMS, ESMM, ESML, and ESMT. With the exception of the intervention description and output description inputs, we observe that the ESMT model performs best across all other inputs. Furthermore, we see that the concatenated title and abstract input and the ESMT model combination performs the best across all input-model combinations with 91.0% accuracy. We use this top-performing model by accuracy to construct AI-assisted tools which could assist researcher in the evidence in the following slide. \")])])]),_c('div',{staticClass:\"carousel-item int-dev-lit-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/ner-res-tools.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Predictions by Pretrained Transformer NER Model for International Development Gray Literature Map and Filter Function\")]),_c('h6',[_vm._v(\"Map of International Development Literature Gray Corpus\")]),_c('p',[_vm._v(\" Using the CoS predictions from the pretrained NER transformer model on the concatenated title and abstract input, we construct a geographical map of the corpus as shown in the left image. For each paper, which had a non-null prediction by the ESMT model, we place a tooltip at location coordinate associated with the predicted CoS. These location coordinates were pulled using the GeoPy Geocoder object from the GeoPy Python package. We added slight, uniform random jitter to each of the coordinates, so papers with the same predicted CoS don't directly overlap. When a user hovers over the tooltip, they will see the title of the paper associated with that tooltip. The webpage for this map can be downloaded \"),_c('a',{attrs:{\"href\":\"https://drive.google.com/file/d/1Q2P6ouwcDWrnXsq8LMpa4YqCuD7qsbtO/view?usp=sharing\",\"target\":\"_blank\"}},[_vm._v(\"here\")]),_vm._v(\" for view in a browser. \")]),_c('h6',[_vm._v(\"Filtering by Predicted CoS\")]),_c('p',[_vm._v(\" For large corpora of International Development Gray Literature, the utility of the CoS prediction task is most evident by the robust filtering capability it enables. For instance, by concatenating only the title and abstract of papers in the corpus, and using them as input to generate CoS predictions by the pretrained transformer model used in this study, this enables the ability for unlabeled papers in the corpus to be accurately filtered to identify studies which had a specific CoS. This method would greatly reduce the time necessary for manual CoS annotation while also yielding higher accuracy than a simple substring matcher, simplifying a step in the international literature review process with high accuracy. An example of this filtering functionality is shown in the right image for papers in the corpus, which were predicted as having Guatemala as the CoS. The CoS was predicted using the pretrained transformer NER model with the concatenated title and abstract as input. We display the corresponding title and abstract for quick scanning of results for relevancy to research topic. Additionally, we provide the option to filter the corpus for papers which had a predicted CoS as \"),_c('i',[_vm._v(\"None\")]),_vm._v(\". \")])])]),_c('div',{staticClass:\"carousel-item int-dev-lit-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/int-dev-results.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Conclusion\")]),_c('p',[_vm._v(\" The manual evidence synthesis for international development gray literature is a time-consuming process. We have demonstrated that certain components of the evidence synthesis process in international development gray literature such as filtering corpora for papers which have a specific country of study or grouping similar documents together can benefit greatly from the use of methods of information extraction and unsupervised learning. More specifically, we have utilized a pretrained transformer NER model to accurately predict the country of study for the papers present in the corpus used in this study, thus enabling accurate filtering of the corpus for papers with a specific predicted country of study. After tuning to find the optimal number of clusters in K-Means clustering, we uncovered informative and distinctive clusters of documents with similar content in the corpus. The automation of these components in the evidence synthesis process for international development grey literature mitigates the effort and time that is required for manual evidence synthesis. \")])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-8\">  \n            <h3>Information Extraction and Unsupervised Methods for Streamlining Evidence Synthesis in International Development Gray Literature</h3>\n        </div>\n        <div class=\"col-md-8\">\n            <div id=\"NLPIntLitDevCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#NLPIntLitDevCarousel\" data-slide-to=\"0\" class=\"active\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#NLPIntLitDevCarousel\" data-slide-to=\"1\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#NLPIntLitDevCarousel\" data-slide-to=\"2\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#NLPIntLitDevCarousel\" data-slide-to=\"3\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#NLPIntLitDevCarousel\" data-slide-to=\"4\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#NLPIntLitDevCarousel\" data-slide-to=\"5\" @click=\"scrollUp\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active int-dev-lit-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/int-dev-results.png\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Project Presentation, Report, and Code</h5>\n                            <p>\n                                This was a final project for 6.864: Advanced Natural Language Processing. This presentation focuses on\n                                introducing the project, the specific parts I worked on, and the main results from our analysis.\n                                <br>\n                                A brief overview of the motivation, methods,\n                                and results is available in this <a href=\"./assets/int-dev-gray-lit.pdf\" target=\"_blank\">presentation PDF.</a>\n                                <br>\n                                The more thorough report of our methodology, visualizations, and findings <a href=\"./assets/6_864_Project.pdf\" target=\"_blank\">here.</a>\n                                <br>\n                                The code for this project was written in Python. <a href=\"https://github.com/dyllew/6.864-fp\" target=\"_blank\">Here's the GitHub Repo.</a>\n                            </p>\n                            <p>\n                                For this project, my main contributions were the supervised methodology/Named Entity Recognition stream discussed in the following slides\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item int-dev-lit-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Abstract</h5>\n                            <p>\n                                In fields like international development, decision-makers prioritize making evidence-based decisions for funding and implementing future projects. \n                                This aim is made difficult because of the plethora of information being published each year, and the nature of the research corpus as unstructured \n                                text or grey literature. To make informed decisions and understand the growing corpus of research available, researchers have turned to evidence \n                                synthesis - the process of compiling information and knowledge from many sources and disciplines to inform decisions. However, the manual evidence \n                                synthesis process takes extensive time (often 18 months to 3 years) and effort, and may soon be impossible at the worlds increasing rate of research \n                                output. To address these problems, we employ natural language processing techniques on a international development literature corpus of 244 documents \n                                to extract information from the title and abstract of international development documents, and to automatically cluster documents based on their content. \n                                We classify documents by Country of Study using a pretrained transformer Named Entity Recognition model and achieve an accuracy of 91.0%. Using K-Means clustering, \n                                we uncover informative and distinctive groupings of the documents which share similar semantic content. These methods reduce the time it takes for manual evidence \n                                synthesis for international development grey literature by enabling country of study filtering and clustering documents by semantic similarity.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item int-dev-lit-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5>Named Entity Recognition (NER) for Country of Study (CoS) Classification - Models</h5>\n                            <p> \n                                The country of study (CoS) associated \n                                with each paper is quite pertinent to the international development domain. Our dataset is labeled \n                                with the CoS of each paper in our corpus. However, since our dataset is rather small (244 documents),\n                                 we sought to evaluate whether pretrained NER models which extract a variety of entity types from text, \n                                 could accurately extract the CoS for the papers in our corpus, which have a variety of text fields.\n                            </p>\n                            <h6>Country of Study Extraction and Classification</h6>\n                            <p> \n                                We create a lower-cased, alphabetically-ordered, list of countries, which we construct using countryinfo\n                                <a href=\"https://pypi.org/project/countryinfo/\" target=\"_blank\">(Link to CountryInfo PyPI page)</a>, a Python package \n                                which contains a large dictionary of countries, their alternative names, and ISO information. We ensure \n                                the strings of the countries present in our corpus match their respective string in the alphabetically-sorted list of countries. \n                                We note that Myanmar and Kosovo are countries present in our corpus, but are not present in the countryinfo dictionary, so we add \n                                them to the final list of alphabetically-sorted countries. Since nationality is a type of named entity that NER models typically \n                                extract in addition to countries, using a comprehensive, open-source nationality-country mapping <a href=\"https://github.com/knowitall/chunkedextractor/blob/master/src/main/resources/edu/knowitall/chunkedextractor/demonyms.csv\" target=\"_blank\">(Demonym-Country Mapping Link)</a>, \n                                we construct a lower-cased, alphabetically-ordered list of nationalities as well as a dictionary mapping nationality to country. \n                                We note that we use the words nationality and demonym interchangeably. These lists and dictionary are useful for performing the country of study (CoS) \n                                classification using extracted entities from input text or determining if a nationality or country is a substring contained in the input text string.\n                            </p>\n                            <h6>Simple Substring Matcher (SSM) Algorithm Baseline & CoS Extraction & Classification</h6>\n                            <p> \n                                As a baseline to our CoS prediction task, we devise a simple, non-ML, deterministic algorithm, called the Simple Substring Matcher (SSM) Algorithm. This \n                                method begins by making the input text lower-cased. To predict a CoS, it then scans through the alphabetically-sorted list of countries and classifies \n                                the first country which is a substring in the input text as the CoS. If no country is found as a substring in the text, the method then scans the alphabetically-sorted \n                                list of nationalities. If a nationality is found as a substring of the input, the method maps the nationality to the corresponding country and classifies the paper as \n                                having that country as the CoS. If neither country nor nationality is found as a substring in the text, the method classifies the paper's CoS as a <i>None</i> value. \n                                We refer to this classification model as the Simple Substring Matcher (SSM) model.\n                            </p>\n                            <h6>CoS Extraction & Classification by Pretrained NER Models</h6>\n                            <p> \n                                Although we utilize different pretrained NER models in our experiments as shown in the next slide, the process for classifying CoS using predicted entities is the same. \n                                Each model takes the raw text as input, predicts various non-overlapping entities present in the text into one of several entity categories. For the CoS classification task, \n                                we only consider the predicted <b>NORP</b> (nationalities, or religious, or political groups) entities and the <b>GPE</b> (countries, cities, states) entities as we assume \n                                that these categories are the only ones which would contain the country or relevant demonym associated with the CoS. We now begin our discussion of the classification procedure \n                                for the pretrained NER models.\n\n                                First, we make all NORP and GPE entities lower-cased. Next, we map any demonyms present among the NORP entities to their corresponding country. We then combine the resulting unique \n                                NORP and GPE entities into an alphabetically-ordered list. We scan this list of NORP and GPE entities checking if any of them exist in the countries list mentioned above, \n                                classifying the CoS as the first entity-country match found. If no match is found, we make a final attempt to determine the CoS by providing each of the entities as input to the GeoPy Geocoder <a href=\"https://geopy.readthedocs.io/en/stable/\" target=\"_blank\">(Link to GeoPy API)</a>\n                                object, which provides an address-location object if a location is found for the provided entity or no value otherwise. We do this for each entity, and if a location is found for a particular entity, \n                                we classify the paper's CoS as the country associated with the found address-location. If no country is found for all the entities, we classify the paper's CoS as <i>None</i>.  \n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item int-dev-lit-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/ner-results.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>NER for Country of Study Classification - Results</h5>\n                            <p>\n                                In addition to testing different classification models, \n                                I experimented with different input strings to see how results change with various text fields and concatenations between them. \n                                These various inputs to the models include the title, abstract, intervention description, outcome description, and various concatenations of these text fields.\n                                \n                            </p>\n                            <p> \n                                All of the pretrained spaCy NER models have 0.0% accuracy when using the just the intervention description, \n                                however the SSM model achieves 13.9% accuracy on the intervention description. All models attain an accuracy of \n                                2.9% when using just the outcome description. The title and abstract individually appear to be good input fields \n                                for predicting the CoS, however the concatenation of title and abstract appears to be the most informative input, \n                                as this is the input that yields the highest performance across all of the models. Overall, we observe that the baseline \n                                simple substring checker is a fairly competitive model against the pretrained ML models, outperforming all the ML models\n                                on intervention description, performing the same as the ML models on outcome description, and only falling a few percentage \n                                points below even the best ML model on the other inputs. With the exception of the title, intervention description, \n                                and outcome description, the ML models in increasing order of complexity, do increasingly better on the CoS extraction task, \n                                in the following order from least performant to most performant: ESMS, ESMM, ESML, and ESMT. With the exception of the \n                                intervention description and output description inputs, we observe that the ESMT model performs best across all other inputs. \n                                Furthermore, we see that the concatenated title and abstract input and the ESMT model combination performs the best across \n                                all input-model combinations with 91.0% accuracy. We use this top-performing model by accuracy to construct\n                                AI-assisted tools which could assist researcher in the evidence in the following slide.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item int-dev-lit-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/ner-res-tools.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Predictions by Pretrained Transformer NER Model for International Development Gray Literature Map and Filter Function</h5>\n                            <h6>Map of International Development Literature Gray Corpus</h6>\n                            <p> \n                                Using the CoS predictions from the pretrained NER transformer model on the concatenated title and abstract input,  \n                                we construct a geographical map of the corpus as shown in the left image. For each paper, which had a non-null prediction \n                                by the ESMT model, we place a tooltip at location coordinate associated with the predicted CoS. These location coordinates \n                                were pulled using the GeoPy Geocoder object from the GeoPy Python package. We added slight, uniform random jitter to each of the coordinates, \n                                so papers with the same predicted CoS don't directly overlap. When a user hovers over the tooltip, they will see the title of the paper associated with that tooltip.\n                                The webpage for this map can be downloaded <a href=\"https://drive.google.com/file/d/1Q2P6ouwcDWrnXsq8LMpa4YqCuD7qsbtO/view?usp=sharing\" target=\"_blank\">here</a> for view in a browser.\n                            </p>\n                            <h6>Filtering by Predicted CoS</h6>\n                            <p> \n                                For large corpora of International Development Gray Literature, the utility of the CoS prediction task is most evident by the robust filtering capability it enables. For instance, by \n                                concatenating only the title and abstract of papers in the corpus, and using them as input to generate CoS predictions by the pretrained transformer model used in this study, this \n                                enables the ability for unlabeled papers in the corpus to be accurately filtered to identify studies which had a specific CoS. This method would greatly reduce the time necessary for \n                                manual CoS annotation while also yielding higher accuracy than a simple substring matcher, simplifying a step in the international literature review process with high accuracy. An example \n                                of this filtering functionality is shown in the right image for papers in the corpus, which were predicted as having Guatemala as the CoS. The CoS was predicted using the pretrained transformer \n                                NER model with the concatenated title and abstract as input. We display the corresponding title and abstract for quick scanning of results for relevancy to research topic. Additionally, we provide \n                                the option to filter the corpus for papers which had a predicted CoS as <i>None</i>.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item int-dev-lit-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/int-dev-results.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Conclusion</h5>\n                            <p> \n                                The manual evidence synthesis for international development gray literature is a time-consuming process. \n                                We have demonstrated that certain components of the evidence synthesis process in international development gray \n                                literature such as filtering corpora for papers which have a specific country of study or grouping similar documents \n                                together can benefit greatly from the use of methods of information extraction and unsupervised learning. More specifically, \n                                we have utilized a pretrained transformer NER model to accurately predict the country of study for the papers present in the corpus \n                                used in this study, thus enabling accurate filtering of the corpus for papers with a specific predicted country of study. After tuning \n                                to find the optimal number of clusters in K-Means clustering, we uncovered informative and distinctive clusters of documents with similar \n                                content in the corpus. The automation of these components in the evidence synthesis process for international development grey literature \n                                mitigates the effort and time that is required for manual evidence synthesis. \n                            </p>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nimport { scrollUpFunc } from '../../constants';\nexport default {\n  name: 'NLPIntDevGrayLit',\n  methods: {\n    scrollUp() {\n        scrollUpFunc();\n    }\n  }\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\na {\n    color: hotpink;\n}\n\na:hover {\n    color: white;\n}\n\nh1, h3, h5, h6 {\n    color: white;\n}\n\nh6 {\n    font-weight: bold;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n.int-dev-lit-carousel-item img {\n  height: 40vh;\n  max-height: 500px;\n}\n\n@media (max-width: 800px) {\n    .int-dev-lit-carousel-item img {\n        height: 450px;\n        max-height: 200px;\n    }\n}\n\n</style>\n","import mod from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NLPIntDevGrayLit.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NLPIntDevGrayLit.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./NLPIntDevGrayLit.vue?vue&type=template&id=a2cea640&scoped=true&\"\nimport script from \"./NLPIntDevGrayLit.vue?vue&type=script&lang=js&\"\nexport * from \"./NLPIntDevGrayLit.vue?vue&type=script&lang=js&\"\nimport style0 from \"./NLPIntDevGrayLit.vue?vue&type=style&index=0&id=a2cea640&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"a2cea640\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_c('div',{staticClass:\"col-12\"},[_c('h3',[_vm._v(\"Graph Neural Networks for NYC Taxi Fare & Demand Surge Prediction\")])]),_c('div',{staticClass:\"col-md-8\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"taxiCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#taxiCarousel\",\"data-slide-to\":\"0\"}}),_c('li',{attrs:{\"data-target\":\"#taxiCarousel\",\"data-slide-to\":\"1\"}}),_c('li',{attrs:{\"data-target\":\"#taxiCarousel\",\"data-slide-to\":\"2\"}})]),_c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item active taxi-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/taxi-fare-and-surge-pred.png\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Motivation\")]),_c('p',[_vm._v(\" With the advent of ridesharing apps, the New York City taxi industry must provide accurate predictions for taxi fares and demand surges in order to remain competitive. It is important that it provides riders with accurate estimates for the price of trip fare for quality customer service. It is beneficial for the taxi industry to accurately predict locations that will experience increased demand or surges in taxi demand to effectively allocate drivers and cabs to these areas in a timely manner. In this project, we used a large public dataset provided by the NYC Taxi & Limousine Commission containing yellow taxi trips records for every month from 2015-Present. We specifically utilized data from January 2019-June 2019. \")])])]),_c('div',{staticClass:\"carousel-item taxi-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/fare-surge-graph-pred.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Graph Neural Networks for Taxi Fare and Surge Prediction\")]),_c('p',[_vm._v(\" The Yellow Taxi Trip Records contain data about taxi trips including pickup and dropoff locations, date and time of pickup and dropoff, distance traveled, and the associated fare of the trip. This data has inherent graph structure in which the nodes are the different pickup/dropoff locations and the edges are the directed trips between them. Due to the increasing advances of Graph Neural Networks (GNNs) in recent years and the advent of efficient frameworks like Deep Graph Library (DGL), we evaluated the performance of GNNs against other classical machine learning methods to assess the viability of GNNs as an accurate model which leverages the inherent graph structure in the data used for these tasks. \")])])]),_c('div',{staticClass:\"carousel-item taxi-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/fare-surge-graph-pred.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Results\")]),_c('p',[_vm._v(\" Using the raw yellow taxi trip data from January 2019-June 2019, we contrived two datasets to pose node and regression problems for graphical methods. Using GraphSage GNNs, we explored and benchmarked a new application of GNNs to taxi data against classical ML approaches. For fare prediction, the GNN model performed slightly worse than Linear Regression, Random Forests, and a Fully-Connected Neural Network (FC NN), with the FC NN performing the best, however, it is highly-parameterized. For surge prediction, the GNN performed slightly better than a FC NN. For both taxi prediction tasks, we demonstrated that a less complex GNN model can perform comparably to a highly-parameterized FC NN. \")])])])])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-12\">  \n            <h3>Graph Neural Networks for NYC Taxi Fare & Demand Surge Prediction</h3>\n        </div>\n        <div class=\"col-md-8\">\n            <div id=\"taxiCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#taxiCarousel\" data-slide-to=\"0\" class=\"active\"></li>\n                    <li data-target=\"#taxiCarousel\" data-slide-to=\"1\"></li>\n                    <li data-target=\"#taxiCarousel\" data-slide-to=\"2\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active taxi-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/taxi-fare-and-surge-pred.png\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Motivation</h5>\n                            <p>\n                                With the advent of ridesharing apps, the New York City taxi industry must provide accurate predictions for taxi fares and demand surges in order to remain competitive.\n                                It is important that it provides riders with accurate estimates for the price of trip fare for quality customer service.\n                                It is beneficial for the taxi industry to accurately predict locations that will experience increased demand or surges in taxi demand to effectively allocate\n                                drivers and cabs to these areas in a timely manner. In this project, we used a large public dataset provided by the \n                                NYC Taxi & Limousine Commission containing yellow taxi trips records for every month from 2015-Present. \n                                We specifically utilized data from January 2019-June 2019.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item taxi-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/fare-surge-graph-pred.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Graph Neural Networks for Taxi Fare and Surge Prediction</h5>\n                            <p> \n                                The Yellow Taxi Trip Records contain data about taxi trips including pickup and dropoff locations, date and time of pickup and dropoff,\n                                distance traveled, and the associated fare of the trip.  This data has inherent graph structure in which the nodes are the different pickup/dropoff locations\n                                and the edges are the directed trips between them. Due to the increasing advances of Graph Neural Networks (GNNs) in recent years and the advent of efficient frameworks like Deep Graph Library (DGL),\n                                we evaluated the performance of GNNs against other classical machine learning methods to assess the viability of GNNs as an accurate model which leverages the inherent graph structure in the data used for these tasks.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item taxi-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/fare-surge-graph-pred.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Results</h5>\n                            <p> \n                                Using the raw yellow taxi trip data from January 2019-June 2019, we contrived two datasets\n                                to pose node and regression problems for graphical methods. Using GraphSage GNNs, we explored and benchmarked\n                                a new application of GNNs to taxi data against classical ML approaches. For fare prediction, the GNN model performed slightly worse\n                                than Linear Regression, Random Forests, and a Fully-Connected Neural Network (FC NN), with the FC NN performing the best, however, it is highly-parameterized. For surge prediction, the GNN performed slightly better than a FC NN.\n                                For both taxi prediction tasks, we demonstrated that a less complex GNN model can perform comparably to a highly-parameterized FC NN.\n                            </p>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\n\nexport default {\n  name: 'Taxi'\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\nh1, h3, h5 {\n    color: white;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n.taxi-carousel-item img {\n  height: 450px;\n  max-height: 500px;\n}\n\n@media (max-width: 800px) {\n    .taxi-carousel-item img {\n        height: 450px;\n        max-height: 200px;\n    }\n}\n\n</style>\n","import mod from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./GNNsTaxiPrediction.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./GNNsTaxiPrediction.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./GNNsTaxiPrediction.vue?vue&type=template&id=2ba5834e&scoped=true&\"\nimport script from \"./GNNsTaxiPrediction.vue?vue&type=script&lang=js&\"\nexport * from \"./GNNsTaxiPrediction.vue?vue&type=script&lang=js&\"\nimport style0 from \"./GNNsTaxiPrediction.vue?vue&type=style&index=0&id=2ba5834e&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"2ba5834e\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_c('div',{staticClass:\"col-12\"},[_c('h1',[_vm._v(\"Trump Campaign Speech Analysis\")])]),_c('div',{staticClass:\"col-md-8\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"trumpCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#trumpCarousel\",\"data-slide-to\":\"0\"}}),_c('li',{attrs:{\"data-target\":\"#trumpCarousel\",\"data-slide-to\":\"1\"}}),_c('li',{attrs:{\"data-target\":\"#trumpCarousel\",\"data-slide-to\":\"2\"}})]),_c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item active trump-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/trump-campaign.png\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Main Puzzle\")]),_c('p',[_vm._v(\" There have been concerns that nationalist, right-wing sentiments have gained momentum over the years of the Trump presidency. Our group wanted to investigate how Donald Trumps rhetoric may have influenced public sentiment on a regional level. To this end, we analyzed Trump's campaign speeches and the tweets by locals from 4 cities he visited on his campaign and Florida, a swing state. \")])])]),_c('div',{staticClass:\"carousel-item trump-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/negative-positive.jpg\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Most Frequent Negative and Positive Words in Trump's Campaign Speeches\")]),_c('p',[_vm._v(\" Trump's positive sentiment words tend to be adjectives with \\\"great\\\" far exceeding the rest. Among words with negative sentiment, there are more meaningful words related to his speech topics such as \\\"investigation\\\", \\\"defense\\\", \\\"deficit\\\", & \\\"press\\\". \")])])]),_c('div',{staticClass:\"carousel-item trump-carousel-item\"},[_c('img',{staticClass:\"col-12 rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/RelativeWordFrequencyDiff.png\")}}),_c('img',{staticClass:\"col-12 rounded img-fluid pt-4\",attrs:{\"src\":require(\"../../../public/assets/RelativeWordFreqDiffFlorida.png\")}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Trump's Most Frequently Used Words Across his Entire Campaign & Across Florida Campaign\")]),_c('p',[_vm._v(\" In Trump's speeches across the entire campaign, his most frequent words, normalized on Romney's campaign speeches, include \\\"Hillary\\\", \\\"don't\\\" \\\"great\\\", \\\"deal\\\", as well as words related to his election platform such as \\\"border\\\", \\\"wall\\\", \\\"Mexico\\\", \\\"ISIS\\\", \\\"trade\\\", and \\\"China\\\". Words used to thwart Hillary Clinton's campaign such as \\\"Hillary\\\", \\\"email\\\", \\\"lies\\\", \\\"corrupt\\\", \\\"crook\\\", and \\\"FBI\\\" in regards to Clinton's email scandal appear more frequently in Trump's Florida campaign speeches than across all of his campaign speeches, showing that in swing states, Trump strategizes to mention the scandal more frequently to win voters to tip the scale. \")])])])])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-12\">  \n            <h1>Trump Campaign Speech Analysis</h1>\n        </div>\n        <div class=\"col-md-8\">\n            <div id=\"trumpCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#trumpCarousel\" data-slide-to=\"0\" class=\"active\"></li>\n                    <li data-target=\"#trumpCarousel\" data-slide-to=\"1\"></li>\n                    <li data-target=\"#trumpCarousel\" data-slide-to=\"2\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active trump-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/trump-campaign.png\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Main Puzzle</h5>\n                            <p>\n                                There have been concerns that nationalist, right-wing sentiments have gained momentum over the years of the Trump presidency. \n                                Our group wanted to investigate how Donald Trumps rhetoric may have influenced public sentiment on a regional level. \n                                To this end, we analyzed Trump's campaign speeches and the tweets by locals from 4 cities he visited on his campaign and Florida,\n                                a swing state.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item trump-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/negative-positive.jpg\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Most Frequent Negative and Positive Words in Trump's Campaign Speeches</h5>\n                            <p> \n                                Trump's positive sentiment words tend to be adjectives with \"great\" far exceeding the rest. Among words with negative sentiment, \n                                there are more meaningful words related to his speech topics such as \"investigation\", \"defense\", \"deficit\", & \"press\". \n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item trump-carousel-item\">\n                        <img class=\"col-12 rounded img-fluid\" src=\"../../../public/assets/RelativeWordFrequencyDiff.png\">\n                        <img class=\"col-12 rounded img-fluid pt-4\" src=\"../../../public/assets/RelativeWordFreqDiffFlorida.png\">\n                        <div class=\"carousel-text\">\n                            <h5>Trump's Most Frequently Used Words Across his Entire Campaign & Across Florida Campaign</h5>\n                            <p> \n                                In Trump's speeches across the entire campaign, his most frequent words, normalized on Romney's campaign speeches, include\n                                \"Hillary\", \"don't\" \"great\", \"deal\", as well as words related to his election platform such as \"border\", \"wall\", \"Mexico\", \"ISIS\", \"trade\", \n                                and \"China\". Words used to thwart Hillary Clinton's campaign such as \"Hillary\", \"email\", \"lies\", \"corrupt\", \"crook\", and \"FBI\" in regards to Clinton's email scandal \n                                appear more frequently in Trump's Florida campaign speeches than across all of his campaign speeches, showing that in swing states, \n                                Trump strategizes to mention the scandal more frequently to win voters to tip the scale.\n                            </p>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\n\nexport default {\n  name: 'Trump'\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\nh1 {\n    color: white;\n}\n\nh5 {\n    color: white;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n.trump-carousel-item img {\n  height: 450px;\n  max-height: 500px;\n}\n\n@media (max-width: 800px) {\n    .trump-carousel-item img {\n        height: 450px;\n        max-height: 200px;\n    }\n}\n\n</style>\n","import mod from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TrumpSpeechAnalysis.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./TrumpSpeechAnalysis.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./TrumpSpeechAnalysis.vue?vue&type=template&id=3213d2e9&scoped=true&\"\nimport script from \"./TrumpSpeechAnalysis.vue?vue&type=script&lang=js&\"\nexport * from \"./TrumpSpeechAnalysis.vue?vue&type=script&lang=js&\"\nimport style0 from \"./TrumpSpeechAnalysis.vue?vue&type=style&index=0&id=3213d2e9&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"3213d2e9\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_vm._m(0),_c('div',{staticClass:\"col-md-8\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"ccCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"0\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"1\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"2\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"3\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#ccCarousel\",\"data-slide-to\":\"4\"},on:{\"click\":_vm.scrollUp}})]),_vm._m(1)])])])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"col-12\"},[_c('h3',[_vm._v(\"Evolution of the U.S. TV News Narrative on Climate Change\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item active cc-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/final-project-overview.png\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Project Code, Poster, and Report\")]),_c('p',[_vm._v(\" This was a final project for IDS.131: Statistics, Computation, and Applications. This presentation focuses on introducing the project, the specific parts I worked on, and the main findings from our analysis. \"),_c('br'),_vm._v(\" A brief overview of the methods, visualizations, and results is available in this \"),_c('a',{attrs:{\"href\":\"./assets/IDS131_Poster.pdf\",\"target\":\"_blank\"}},[_vm._v(\"poster PDF.\")]),_c('br'),_vm._v(\" The more thorough report of our findings with all visualizations is \"),_c('a',{attrs:{\"href\":\"./assets/IDS131_Final_Report.pdf\",\"target\":\"_blank\"}},[_vm._v(\"here.\")]),_c('br'),_vm._v(\" The code for this project was written in Python. \"),_c('a',{attrs:{\"href\":\"https://github.com/dyllew/ids.131-fp\",\"target\":\"_blank\"}},[_vm._v(\"Here's the GitHub Repo.\")])])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_c('strong',[_vm._v(\"Motivation & Research Question\")])]),_c('p',[_vm._v(\" Print and televised media reporting on climate change influences the public perception of climate change, which in turn affects support for systemic policies to reduce greenhouse gas emissions and for individual actions to mitigate climate change. Over two thirds of Americans get their news often or sometimes from television. In this analysis, we looked at ten years of data from three television stations: CNN, Fox News, and MSNBC to address the following research question: \")]),_c('br'),_c('strong',{attrs:{\"id\":\"research-question\"}},[_vm._v(\" How has the frequency and content of top American English-speaking news media coverage of climate change evolved in the past ten years (July 2009-January 2020)-and what environmental and political factors have influenced the trends? \")])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/network_tfidf_wordclouds.png\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Dataset, Exploration, and Preprocessing\")]),_c('p',[_vm._v(\" The data used for this analysis includes text snippets of 15-seconds of TV news audio transcripts of climate change mentions on CNN, MSNBC, and Fox News from July 2009-January 2020, provided by the \"),_c('a',{attrs:{\"href\":\"https://blog.gdeltproject.org/a-new-dataset-for-exploring-climate-change-narratives-on-television-news-2009-2020/\",\"target\":\"_blank\"}},[_vm._v(\"GDELT Project.\")]),_vm._v(\" The features of the data points include time of day and date of the mention, the TV news network, the show, and the text snippet of the transcribed audio. This dataset provides the ability to compare the TV networks over time on the subject of climate change in order to answer the research question posed. We followed standard Natural Language Processing (NLP) text preprocessing by removing punctuation and numbers, converting all letters to lower-case (the data was already provided as lowercase), lemmatizing, removing standard English stopwords & corpus-specific stopwords, and tokenizing the data into words. We conducted our analysis with two distinct analysis streams: Frequency Analysis and Content Analysis. Our Frequency Analysis entailed methods of time-series analysis of climate change mentions by the different TV networks over time and dynamic time-warping & STL decomposition. Content Analysis used methods of TF-IDF document embeddings, Cosine Similarity as a proxy for content similarity between documents, and Topic Modeling & Change-Point Detection. The above figure was created as part of an exploratory component of the TF-IDF Embedding analysis, in which we wished to extract the most important words to each of the networks across the entire corpus. \")])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/networks_and_years_cosine_similarity.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Content Analysis: TF-IDF Document Embedding & Cosine Similarity\")]),_c('p',[_vm._v(\" My contribution to this project was primarly focused in the Content Analysis stream, specifically TF-IDF document embeddings & Cosine Similarity between documents. To conduct our content analysis, we needed to featurize the news snippets, or collections of snippets, which form the documents in our corpus. I first formed a document for each TV network in our dataset (e.g. all snippets for CNN), and transformed the documents into a L2-normalized unit vector TF-IDF vector embedding. From this featurization, I formed a document-term matrix, where the rows correspond to the TF-IDF embedding of a document and the column represents a unique word in the corpus (~34,000 words). Thus, entry i, j corresponds to the normalized TF-IDF score of word j in document i (i.e. word j's relative importance for the ith document). I also constructed document-term matrices for documents representing each year of our dataset (e.g. all snippets in 2009) as well as for documents constructed from networks in specific years (e.g. all CNN snippets in 2015). Finally, for each of the document-term matrices mentioned above, I calculated the pairwise cosine similarity between the document embeddings to yield a measure of content similarity between the documents. A heatmap constructed from the computed cosine similarities between the network & year documents is shown above. The main findings from my analysis were that the content of climate mentions in the latter years of the dataset, 2016-2020, are most dissimilar to earlier years in the dataset, 2009-2012. Additionally, in the years 2010 & 2018, the content of MSNBC differed greatly from the other news networks in those years and with other networks and itself in other years. This similarly occurred for CNN in 2012 & 2013. Lastly, with the exception of these years, the similarity of content of climate mentions between CNN and MSNBC, the liberal-leaning networks, has been increasing over the years, although the pairwise content similarity between all of the networks is fairly high over time. \")])])]),_c('div',{staticClass:\"carousel-item cc-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/final-project-overview.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Results\")]),_c('p',[_vm._v(\" Climate change TV news media coverage frequency and content appears to be significantly driven by political events more so than environmental factors. The frequency of climate change mentions follow similar patterns by network, with clear influence of political events such as the 2009 UNCCC, 2015 Paris Agreement, and 2019 Democratic primary debates driving climate news coverage. This is reflected in the content of the climate mentions over time as words describing the political events occurring at the time tend to be the most important words for each of the networks in that specific year coupled with the tendency of different networks in the same year to have high content similarity. Topic analysis also finds that the majority of 15 topics found in topic analysis had significant changes in mean on some of the topics at the time of Donald Trump's inauguration. \")])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div class=\"col-12\">  \n            <h3>Evolution of the U.S. TV News Narrative on Climate Change</h3>\n        </div>\n        <div class=\"col-md-8\">\n            <div id=\"ccCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"0\" class=\"active\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"1\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"2\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"3\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#ccCarousel\" data-slide-to=\"4\" @click=\"scrollUp\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active cc-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/final-project-overview.png\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Project Code, Poster, and Report</h5>\n                            <p>\n                                This was a final project for IDS.131: Statistics, Computation, and Applications. This presentation focuses on\n                                introducing the project, the specific parts I worked on, and the main findings from our analysis.\n                                <br>\n                                A brief overview of the methods, visualizations, \n                                and results is available in this <a href=\"./assets/IDS131_Poster.pdf\" target=\"_blank\">poster PDF.</a>\n                                <br>\n                                The more thorough report of our findings with all visualizations is <a href=\"./assets/IDS131_Final_Report.pdf\" target=\"_blank\">here.</a>\n                                <br>\n                                The code for this project was written in Python. <a href=\"https://github.com/dyllew/ids.131-fp\" target=\"_blank\">Here's the GitHub Repo.</a>\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <div class=\"carousel-text\">\n                            <h5><strong>Motivation & Research Question</strong></h5>\n                            <p>\n                                Print and televised media reporting on climate change influences \n                                the public perception of climate change, which in turn affects support for \n                                systemic policies to reduce greenhouse gas emissions and for individual actions to \n                                mitigate climate change. Over two thirds of Americans get their news often or \n                                sometimes from television. In this analysis, we looked at ten years of \n                                data from three television stations: CNN, Fox News, and MSNBC to address the \n                                following research question:\n                            </p>\n                            <br>\n                            <strong id='research-question'>\n                                How has the frequency and content of \n                                top American English-speaking news media coverage of climate change \n                                evolved in the past ten years (July 2009-January 2020)-and what environmental and political factors \n                                have influenced the trends?\n                            </strong>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/network_tfidf_wordclouds.png\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Dataset, Exploration, and Preprocessing</h5>\n                            <p>\n                                The data used for this analysis includes text snippets of 15-seconds of TV news audio transcripts\n                                of climate change mentions on CNN, MSNBC, and Fox News from \n                                July 2009-January 2020, provided by the <a href=\"https://blog.gdeltproject.org/a-new-dataset-for-exploring-climate-change-narratives-on-television-news-2009-2020/\" target=\"_blank\">GDELT Project.</a>\n                                The features of the data points include time of day and date of the mention, \n                                the TV news network, the show, and the text snippet of the transcribed audio. \n                                This dataset provides the ability to compare the TV networks over time on the subject of \n                                climate change in order to answer the research question posed. \n                                We followed standard Natural Language Processing (NLP) text preprocessing by removing punctuation and numbers, \n                                converting all letters to lower-case (the data was already provided as lowercase), lemmatizing, removing standard English stopwords & \n                                corpus-specific stopwords, and tokenizing the data into words. We conducted our analysis with two distinct\n                                analysis streams: Frequency Analysis and Content Analysis. Our Frequency Analysis entailed methods of time-series analysis of climate change mentions\n                                by the different TV networks over time and dynamic time-warping & STL decomposition. Content Analysis used methods of TF-IDF document embeddings,\n                                Cosine Similarity as a proxy for content similarity between documents, and Topic Modeling & Change-Point Detection. The above figure was created as part of \n                                an exploratory component of the TF-IDF Embedding analysis, in which we wished to extract the most important words to each of the networks across the entire corpus.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/networks_and_years_cosine_similarity.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Content Analysis: TF-IDF Document Embedding & Cosine Similarity</h5>\n                            <p> \n                                My contribution to this project was primarly focused in the Content Analysis stream, specifically TF-IDF document embeddings & \n                                Cosine Similarity between documents. To conduct our content analysis, we needed to featurize the news snippets, or collections of snippets, \n                                which form the documents in our corpus. I first formed a document for each TV network in our dataset\n                                (e.g. all snippets for CNN), and transformed the documents into a L2-normalized unit vector TF-IDF vector embedding. \n                                From this featurization, I formed a document-term matrix, where the rows correspond to the TF-IDF embedding of a document and the column \n                                represents a unique word in the corpus (~34,000 words). Thus, entry i, j corresponds to the normalized \n                                TF-IDF score of word j in document i (i.e. word j's relative importance for the ith document). I also constructed document-term matrices for documents representing each year of our dataset\n                                (e.g. all snippets in 2009) as well as for documents constructed from networks in specific years (e.g. all CNN snippets in 2015). Finally, for each of the document-term matrices mentioned above, \n                                I calculated the pairwise cosine similarity between the document embeddings to yield a measure of content similarity between the documents. \n                                A heatmap constructed from the computed cosine similarities between the network & year documents is shown above. The main findings from my analysis were \n                                that the content of climate mentions in the latter years of the dataset, 2016-2020, are most dissimilar to earlier years in the dataset, 2009-2012. \n                                Additionally, in the years 2010 & 2018, the content of MSNBC differed greatly from the other news networks in those years and with other networks and itself in other years. \n                                This similarly occurred for CNN in 2012 & 2013. Lastly, with the exception of these years, the similarity of content of climate mentions between CNN and MSNBC, \n                                the liberal-leaning networks, has been increasing over the years, although the pairwise content similarity between all of the networks is fairly high over time.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item cc-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/final-project-overview.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Results</h5>\n                            <p> \n                                Climate change TV news media coverage frequency and \n                                content appears to be significantly driven by political events\n                                 more so than environmental factors. The frequency of climate change mentions \n                                 follow similar patterns by network, with clear influence of political events such as \n                                 the 2009 UNCCC, 2015 Paris Agreement, and 2019 Democratic primary debates driving \n                                 climate news coverage. This is reflected in the content of the \n                                 climate mentions over time as words describing the political events \n                                 occurring at the time tend to be the most important words for each of the networks \n                                 in that specific year coupled with the tendency of different networks in the same \n                                 year to have high content similarity. Topic analysis also finds that the majority of 15 topics \n                                 found in topic analysis had significant changes in mean on some of the topics at the time of \n                                 Donald Trump's inauguration.\n                            </p>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nimport { scrollUpFunc } from '../../constants';\nexport default {\n  name: 'ClimateChangeNews',\n  methods: {\n    scrollUp() {\n        scrollUpFunc();\n    }\n  }\n}\n</script>\n\n<style scoped>\n\np {\n    text-align: left;\n}\n\n#research-question {\n    text-align: center;\n    color: white;\n}\n\na {\n    color: hotpink;\n}\n\na:hover {\n    color: white;\n}\n\n\nh1, h3, h5 {\n    color: white;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n.cc-carousel-item img {\n  max-height: 30vw;\n}\n\n@media (max-width: 800px) {\n    .cc-carousel-item img {\n        max-height: 80vw;\n    }\n}\n\n</style>\n","import mod from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ClimateChangeNews.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./ClimateChangeNews.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./ClimateChangeNews.vue?vue&type=template&id=506aa114&scoped=true&\"\nimport script from \"./ClimateChangeNews.vue?vue&type=script&lang=js&\"\nexport * from \"./ClimateChangeNews.vue?vue&type=script&lang=js&\"\nimport style0 from \"./ClimateChangeNews.vue?vue&type=style&index=0&id=506aa114&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"506aa114\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"row align-items-center justify-content-center\"},[_vm._m(0),_c('div',{staticClass:\"col-md-8\"},[_c('div',{staticClass:\"carousel slide\",attrs:{\"id\":\"boomerangCarousel\",\"data-ride\":\"carousel\",\"data-interval\":\"false\"}},[_c('ol',{staticClass:\"carousel-indicators\"},[_c('li',{staticClass:\"active\",attrs:{\"data-target\":\"#boomerangCarousel\",\"data-slide-to\":\"0\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#boomerangCarousel\",\"data-slide-to\":\"1\"},on:{\"click\":_vm.scrollUp}}),_c('li',{attrs:{\"data-target\":\"#boomerangCarousel\",\"data-slide-to\":\"2\"},on:{\"click\":_vm.scrollUp}})]),_vm._m(1)])])])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"col-12\",attrs:{\"id\":\"title\"}},[_c('h1',[_vm._v(\"Boomerang\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"carousel-inner\"},[_c('div',{staticClass:\"carousel-item active boomerang-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/boomerang-home.jpg\"),\"alt\":\"First slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Sign Up/Login Page\")]),_c('p',[_vm._v(\"When my group decided on how we wanted to split up the tasks for Boomerang, I decided to design & create the sign up/login page & the create account flow. I thought this would be a good section of the application to practice and enhance my visual design skills and to create a UI that was intuitive. \")])])]),_c('div',{staticClass:\"carousel-item boomerang-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/create-account.png\"),\"alt\":\"Second slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Create Account Part I\")]),_c('p',[_vm._v(\" In the sections of Boomerang I built, I created the front-end using Vue.js which is the same front-end framework I used to build this website. The backend was built using Express.js. The fields above checked for user input to ensure that the account username was not already taken and that the each of the fields was in the correct format, notifying the user instantly on submission if their input was invalid. \")])])]),_c('div',{staticClass:\"carousel-item boomerang-carousel-item\"},[_c('img',{staticClass:\"rounded img-fluid\",attrs:{\"src\":require(\"../../../public/assets/join-communities.png\"),\"alt\":\"Third slide\"}}),_c('div',{staticClass:\"carousel-text\"},[_c('h5',[_vm._v(\"Create Account Part II\")]),_c('p',[_vm._v(\" Account creation for any app is an important user flow as it lets the user understand both the purpose of an app & how they can engage with it completely. For these reasons, I decided to include descriptions of the main concepts of the application (Communities, Channels, etc.) as this would reduce the time it would take for a user to get immersed in the app. \")])])])])}]\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"row align-items-center justify-content-center\">\n        <div id=\"title\" class=\"col-12\">  \n            <h1>Boomerang</h1>\n        </div>\n        <div class=\"col-md-8\">\n            <div id=\"boomerangCarousel\" class=\"carousel slide\" data-ride=\"carousel\" data-interval=\"false\">\n                <ol class=\"carousel-indicators\">\n                    <li data-target=\"#boomerangCarousel\" data-slide-to=\"0\" class=\"active\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#boomerangCarousel\" data-slide-to=\"1\" @click=\"scrollUp\"></li>\n                    <li data-target=\"#boomerangCarousel\" data-slide-to=\"2\" @click=\"scrollUp\"></li>\n                </ol>\n                <div class=\"carousel-inner\">\n                    <div class=\"carousel-item active boomerang-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/boomerang-home.jpg\" alt=\"First slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Sign Up/Login Page</h5>\n                            <p>When my group decided on how we wanted to split up the tasks for Boomerang,\n                                I decided to design & create the sign up/login page & the create account flow. \n                                I thought this would be a good section of the application to practice and enhance my visual design skills\n                                and to create a UI that was intuitive.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item boomerang-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/create-account.png\" alt=\"Second slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Create Account Part I</h5>\n                            <p> \n                                In the sections of Boomerang I built, I created the front-end using \n                                Vue.js which is the same front-end framework I used to build this website. \n                                The backend was built using Express.js. The fields above checked for user input\n                                to ensure that the account username was not already taken and that the each of the fields was\n                                in the correct format, notifying the user instantly on submission if their input was invalid.\n                            </p>\n                        </div>\n                    </div>\n                    <div class=\"carousel-item boomerang-carousel-item\">\n                        <img class=\"rounded img-fluid\" src=\"../../../public/assets/join-communities.png\" alt=\"Third slide\">\n                        <div class=\"carousel-text\">\n                            <h5>Create Account Part II</h5>\n                            <p> \n                                Account creation for any app is an important user flow as it\n                                lets the user understand both the purpose of an app & how they can engage with it completely.\n                                For these reasons, I decided to include descriptions of the main concepts of the application (Communities, Channels, etc.)\n                                as this would reduce the time it would take for a user to get immersed in the app.\n                            </p>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nimport { scrollUpFunc } from '../../constants';\nexport default {\n  name: 'Boomerang',\n  methods: {\n    scrollUp() {\n        scrollUpFunc();\n    }\n  }\n}\n</script>\n\n<style scoped>\n\nh1, h5 {\n    color: white;\n}\n\n.carousel-text {\n    margin-top: 10px;\n    margin-bottom: 40px;\n}\n\n.boomerang-carousel-item img {\n  height: 450px;\n  max-height: 500px;\n}\n\n@media (max-width: 800px) {\n    .boomerang-carousel-item img {\n        height: 450px;\n        max-height: 200px;\n    }\n}\n\n</style>\n","import mod from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Boomerang.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../../node_modules/thread-loader/dist/cjs.js!../../../node_modules/babel-loader/lib/index.js!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Boomerang.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Boomerang.vue?vue&type=template&id=84374a92&scoped=true&\"\nimport script from \"./Boomerang.vue?vue&type=script&lang=js&\"\nexport * from \"./Boomerang.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Boomerang.vue?vue&type=style&index=0&id=84374a92&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"84374a92\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"col pt-5 justify-content-center\"},[_c('h2',[_vm._v(\"Uh Oh! Looks like you went to a page that doesn't exist on dyllew.github.io\")]),_c('router-link',{staticClass:\"router-link\",attrs:{\"to\":\"/\"}},[_vm._v(\"Click this link to go home.\")])],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\n    <div class=\"col pt-5 justify-content-center\">\n      <h2>Uh Oh! Looks like you went to a page that doesn't exist on dyllew.github.io</h2>\n      <router-link class=\"router-link\" to=\"/\">Click this link to go home.</router-link>\n    </div>  \n</template>\n\n<script>\nexport default {\n  name: 'NotFoundComponent'\n}\n</script>\n\n<style scoped>\n\n.router-link {\n  color: #61DAFB;\n  font-size: 30px;\n}\n\n.router-link:hover {\n  color: whitesmoke;\n}\n\n.router-link-active {\n  color: white;\n  text-decoration: underline;\n}\n\n\n</style>","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NotFoundComponent.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NotFoundComponent.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./NotFoundComponent.vue?vue&type=template&id=4ffa6c61&scoped=true&\"\nimport script from \"./NotFoundComponent.vue?vue&type=script&lang=js&\"\nexport * from \"./NotFoundComponent.vue?vue&type=script&lang=js&\"\nimport style0 from \"./NotFoundComponent.vue?vue&type=style&index=0&id=4ffa6c61&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"4ffa6c61\",\n  null\n  \n)\n\nexport default component.exports","import Vue from 'vue';\nimport VueRouter from 'vue-router';\n\nVue.use(VueRouter);\n\n// import components below\nimport Home from './components/Home'\nimport About from './components/About';\nimport Projects from './components/Projects';\nimport Artwork from './components/Artwork';\nimport Resume from './components/Resume';\nimport MLForCrowdsourcedCrisisData from './components/project-pages/ml-for-crowdsourced-crisis-data/MLForCrowdsourcedCrisisData';\nimport ImageAnalysisCarousel from './components/project-pages/ml-for-crowdsourced-crisis-data/ImageAnalysisCarousel';\nimport TextAnalysisCarousel from './components/project-pages/ml-for-crowdsourced-crisis-data/TextAnalysisCarousel';\nimport NLPIntDevGrayLit from './components/project-pages/NLPIntDevGrayLit';\nimport GNNsTaxiPrediction from './components/project-pages/GNNsTaxiPrediction';\nimport TrumpSpeechAnalysis from './components/project-pages/TrumpSpeechAnalysis';\nimport ClimateChangeNews from './components/project-pages/ClimateChangeNews';\nimport Boomerang from './components/project-pages/Boomerang';\nimport NotFoundComponent from './components/NotFoundComponent';\n\n// store router -> components mappings\nconst router = [\n    {\n        path: '/',\n        component: Home\n    },\n    {\n        path: '/about',\n        component: About\n    },\n    {\n        path: '/projects',\n        component: Projects\n    },\n    {\n        path: '/projects/boomerang',\n        component: Boomerang\n    },\n    {\n        path: '/projects/ml-for-crowdsourced-crisis-data',\n        component: MLForCrowdsourcedCrisisData\n    },\n    {\n        path: '/projects/ml-for-crowdsourced-crisis-data/image-analysis-module',\n        component: ImageAnalysisCarousel\n    },\n    {\n        path: '/projects/ml-for-crowdsourced-crisis-data/text-analysis-module',\n        component: TextAnalysisCarousel\n    },\n    {\n        path: '/projects/nlp-for-int-dev-gray-lit',\n        component: NLPIntDevGrayLit\n    },\n    {\n        path: '/projects/trump-speech-analysis',\n        component: TrumpSpeechAnalysis\n    },\n    {\n        path: '/projects/gnns-taxi-prediction',\n        component: GNNsTaxiPrediction\n    },\n    {\n        path: '/projects/climate-change-news',\n        component: ClimateChangeNews\n    },\n    {\n        path: '/artwork',\n        component: Artwork\n    },\n    {\n        path: '/resume',\n        component: Resume\n    },\n    { \n        path: '/404', \n        component: NotFoundComponent\n    },  \n    {\n        path: '*',\n        redirect: '/404'\n    }\n\n];\n\nconst vueRouter = new VueRouter({\n    mode: 'hash',\n    routes: router\n});\n\nexport default vueRouter;","import Vue from 'vue';\nimport { BootstrapVue, IconsPlugin } from 'bootstrap-vue';\nimport App from './App.vue';\n\nimport router from './router';\nimport 'bootstrap/dist/css/bootstrap.css';\nimport 'bootstrap-vue/dist/bootstrap-vue.css';\n\nVue.config.productionTip = false;\nVue.use(BootstrapVue);\nVue.use(IconsPlugin);\n\nnew Vue({\n  router,\n  render: h => h(App)\n}).$mount('#app')\n","module.exports = __webpack_public_path__ + \"img/iaa.ec440fef.png\";","module.exports = __webpack_public_path__ + \"img/boomerang-home.2b52b305.jpg\";","module.exports = __webpack_public_path__ + \"img/test-set-eval.d9e2b629.png\";","module.exports = __webpack_public_path__ + \"img/network_tfidf_wordclouds.295ee901.png\";","module.exports = __webpack_public_path__ + \"img/in-fc.af1ca061.png\";","module.exports = __webpack_public_path__ + \"img/image-analysis-module-modified.2f3d5731.png\";","module.exports = __webpack_public_path__ + \"img/NER.042f94f2.png\";","module.exports = __webpack_public_path__ + \"01fbdfc68fb18b120d93f81bebddbbe3.pdf\";","module.exports = __webpack_public_path__ + \"img/fare-surge-graph-pred.16940831.png\";","module.exports = __webpack_public_path__ + \"img/years_cosine_similarity.1e4e7357.png\";","module.exports = __webpack_public_path__ + \"img/trump-campaign.81aaea0e.png\";","module.exports = __webpack_public_path__ + \"img/project-collage.6966ef19.png\";","module.exports = __webpack_public_path__ + \"img/tfidf-networks.c48a6bce.png\";","module.exports = __webpack_public_path__ + \"img/hc-fc.f248f6e2.png\";","module.exports = __webpack_public_path__ + \"img/ds-train.fff83a4a.png\";","module.exports = __webpack_public_path__ + \"img/pika-gif.6999dd5c.gif\";","module.exports = __webpack_public_path__ + \"img/join-communities.392bb659.png\";","module.exports = __webpack_public_path__ + \"img/resume.851be6c2.png\";","module.exports = __webpack_public_path__ + \"img/reptile.b479d166.png\";","module.exports = __webpack_public_path__ + \"img/masters-thesis-overview.b92e2d31.png\";","module.exports = __webpack_public_path__ + \"img/network_cosine_similarity.0a83a38c.png\";","module.exports = __webpack_public_path__ + \"57c143e9704cb3120e7e05eaf2a3a1a6.pdf\";","module.exports = __webpack_public_path__ + \"img/in-train.cce4b41a.png\";","import mod from \"-!../../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./MLForCrowdsourcedCrisisData.vue?vue&type=style&index=0&id=b4bc0cd6&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./MLForCrowdsourcedCrisisData.vue?vue&type=style&index=0&id=b4bc0cd6&scoped=true&lang=css&\"","module.exports = __webpack_public_path__ + \"img/hc-train.314e090e.png\";","module.exports = __webpack_public_path__ + \"img/feelings.7216f530.jpg\";","module.exports = __webpack_public_path__ + \"img/dylan-n-leo.621aa4fc.jpg\";","module.exports = __webpack_public_path__ + \"img/networks_and_years_cosine_similarity.3eaf2c24.png\";","module.exports = __webpack_public_path__ + \"img/linkedin-profpic.00cde042.jpg\";","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./About.vue?vue&type=style&index=0&id=1634933c&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./About.vue?vue&type=style&index=0&id=1634933c&scoped=true&lang=css&\"","import mod from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Boomerang.vue?vue&type=style&index=0&id=84374a92&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Boomerang.vue?vue&type=style&index=0&id=84374a92&scoped=true&lang=css&\"","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NavBar.vue?vue&type=style&index=0&id=d904e86c&scoped=true&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NavBar.vue?vue&type=style&index=0&id=d904e86c&scoped=true&lang=css&\"","module.exports = __webpack_public_path__ + \"img/image-analysis-module.c12d2c01.png\";","module.exports = __webpack_public_path__ + \"img/final-project-overview.13f71d33.png\";","module.exports = __webpack_public_path__ + \"img/create-account.b25be796.png\";","module.exports = __webpack_public_path__ + \"img/taxi-proj-thumbnail.6dd3b85f.png\";","import mod from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NLPIntDevGrayLit.vue?vue&type=style&index=0&id=a2cea640&scoped=true&lang=css&\"; export default mod; export * from \"-!../../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../../node_modules/vue-loader/lib/index.js??vue-loader-options!./NLPIntDevGrayLit.vue?vue&type=style&index=0&id=a2cea640&scoped=true&lang=css&\"","module.exports = __webpack_public_path__ + \"img/leo_n_me.2868644e.jpg\";","module.exports = __webpack_public_path__ + \"img/RelativeWordFreqDiffFlorida.80584f3b.png\";","module.exports = __webpack_public_path__ + \"img/taxi-fare-and-surge-pred.064e07ad.png\";","import mod from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Artwork.vue?vue&type=style&index=0&lang=css&\"; export default mod; export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Artwork.vue?vue&type=style&index=0&lang=css&\""],"sourceRoot":""}